<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2014-12-15T22:19:44+01:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[99 Bottles of Beer]]></title>
    <link href="http://jsteemann.github.io/blog/2014/12/14/99-bottles-of-beer/"/>
    <updated>2014-12-14T13:14:28+01:00</updated>
    <id>http://jsteemann.github.io/blog/2014/12/14/99-bottles-of-beer</id>
    <content type="html"><![CDATA[<p><a href="http://www.99-bottles-of-beer.net/">99 bottles of beer</a> in AQL:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FOR quant IN 99..0 
</span><span class='line'>  LET toPrint = (
</span><span class='line'>    quant &gt; 1 ? 
</span><span class='line'>      CONCAT(TO_STRING(quant), " bottles of beer on the wall, ", TO_STRING(quant), " bottles of beer.") : 
</span><span class='line'>      (quant == 1 ? 
</span><span class='line'>        "1 bottle of beer on the wall, 1 bottle of beer." :
</span><span class='line'>        "No more bottles of beer on the wall, no more bottles of beer."
</span><span class='line'>      )
</span><span class='line'>  )
</span><span class='line'> 
</span><span class='line'>  LET suffix = (
</span><span class='line'>    quant &gt; 2 ? 
</span><span class='line'>      CONCAT(TO_STRING(quant - 1), " bottles of beer on the wall.") :
</span><span class='line'>      (quant == 2 ? 
</span><span class='line'>        "1 bottle of beer on the wall." :
</span><span class='line'>        "no more bottles of beer on the wall."
</span><span class='line'>      )
</span><span class='line'>  )
</span><span class='line'> 
</span><span class='line'>  LET result = (
</span><span class='line'>    quant &gt; 0 ? 
</span><span class='line'>      CONCAT(toPrint, "\nTake one down, pass it around, ", suffix) : 
</span><span class='line'>      CONCAT(toPrint, "\nGo to the store and buy some more, 99 bottles of beer on the wall.")
</span><span class='line'>  )
</span><span class='line'>
</span><span class='line'>  RETURN result</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AQL Improvements for 2.4]]></title>
    <link href="http://jsteemann.github.io/blog/2014/12/12/aql-improvements-for-24/"/>
    <updated>2014-12-12T23:35:08+01:00</updated>
    <id>http://jsteemann.github.io/blog/2014/12/12/aql-improvements-for-24</id>
    <content type="html"><![CDATA[<p>While on a retreat in Belgium, we found some spare time to
work on improvements for AQL. These will be shipped with
ArangoDB version 2.4, and are already available in the devel
version for testing from now on.</p>

<p>Here&rsquo;s a short overview of the improvements:</p>

<!-- more -->


<h1>COLLECT WITH COUNT</h1>

<p>A common use case in query languages is to count the number of
documents returned by a query. The AQL solution for this has been
to use the <code>LENGTH</code> function and a subquery:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>RETURN LENGTH((
</span><span class='line'>  FOR doc IN collection 
</span><span class='line'>    FILTER doc.someAttribute == someValue
</span><span class='line'>    RETURN doc
</span><span class='line'>  ))</span></code></pre></td></tr></table></div></figure>


<p>This is quite long and probably unintuitive for people which have
used SQL for years.</p>

<p>We therefore now allow using the following alternative version:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FOR doc IN collection
</span><span class='line'>  FILTER doc.someAttribute == someValue
</span><span class='line'>  COLLECT WITH COUNT INTO length
</span><span class='line'>  RETURN length</span></code></pre></td></tr></table></div></figure>


<p>This query returns just the total number of matches, but not the
matches themselves. As this query is made for counting only, it
enables the optimizer to execute this query more efficiently.
The documents found by the filter can be discarded
instantly after the filter condition is evaluated, and do not need
to shipped around inside the query.</p>

<p>As a bonus, there is no need to use a subquery anymore, though the
former variant is still fully supported and will be.</p>

<p><code>COLLECT WITH COUNT</code> also works with groups:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FOR doc IN collection
</span><span class='line'>  COLLECT value = doc.someAttribute WITH COUNT INTO length
</span><span class='line'>  RETURN { value: value, length : length }</span></code></pre></td></tr></table></div></figure>


<p>This returns the number of matches for each distinct <code>value</code>.</p>

<p>A quick unscientific benchmark reveals that the specialized
<code>WITH COUNT</code> clause seems to be faster than the old variant.
The following results show the differences for a collection with
500,000 small documents:</p>

<p>The old variant that counts the number of documents by age runs
in 4.75 seconds on my laptop:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FOR doc IN collection
</span><span class='line'>  FILTER doc.age &lt; 20 
</span><span class='line'>  COLLECT age = doc.age INTO g 
</span><span class='line'>  RETURN { age: age, length: LENGTH(g) }</span></code></pre></td></tr></table></div></figure>


<p>The new variant does the same, but runs in 0.6 seconds locally:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FOR doc IN collection 
</span><span class='line'>  COLLECT age = doc.age WITH COUNT INTO length 
</span><span class='line'>  RETURN { age: age, length: length }
</span><span class='line'>0.6001598834991455</span></code></pre></td></tr></table></div></figure>


<p>A notable speedup can also be observed if only a fraction of the
groups is built (here: 1/8). The old variant for this runs in 0.6
seconds:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FOR doc IN collection
</span><span class='line'>  FILTER doc.age &lt; 20 
</span><span class='line'>  COLLECT age = doc.age INTO g 
</span><span class='line'>  RETURN { age: age, length: LENGTH(g) }</span></code></pre></td></tr></table></div></figure>


<p>The new variants runs in 0.12 seconds:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FOR doc IN collection 
</span><span class='line'>  FILTER doc.age &lt; 20 
</span><span class='line'>  COLLECT age = doc.age WITH COUNT INTO length 
</span><span class='line'>  RETURN { age: age, length: length }</span></code></pre></td></tr></table></div></figure>


<p>The absolute times may vary greatly depending on the documents and
the hardware used, but in general the new variant should provide a
speedup.</p>

<h1>Removing filters covered by indexes</h1>

<p><code>FILTER</code> conditions which are completely covered by indexes will
now be removed from the execution plan if it is safe to do so.
Dropping the <code>FILTER</code> statements allows the optimizer to get rid
of not only the <em>FilterNode</em>, but also its corresponding <em>CalculationNode</em>.
This will save a lot of computation if many documents match the
<code>FILTER</code> condition.</p>

<p>For example, imagine the following query:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FOR doc IN collection
</span><span class='line'>  FILTER doc.value &lt; 10 
</span><span class='line'>  RETURN doc</span></code></pre></td></tr></table></div></figure>


<p>If there is a (skiplist) index on <code>doc.value</code>, the optimizer may
decide to use this index. It will insert an <em>IndexRangeNode</em> instead
of a full collection scan. The <em>IndexRangeNode</em> will scan the index
on <code>doc.value</code> for the range [-inf, 10).</p>

<p>Following that, the optimizer rule <code>remove-filter-covered-by-index</code>
should fire and detect that the <code>FILTER</code> condition is already covered
by the <em>IndexRangeNode</em>, and remove the <em>FilterNode</em>. This makes the
<em>CalculationNode</em> of the <em>FilterNode</em> obsolete, so these two nodes will
be removed.</p>

<h1>Removing brackets for subquery function call parameters</h1>

<p>Since the beginning of AQL, the parser required the user the put
subqueries that were used as function parameters inside two pairs of
brackets.</p>

<p>For example, the following query did not parse in 2.3 and before:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>RETURN LENGTH(FOR doc IN collection RETURN doc)</span></code></pre></td></tr></table></div></figure>


<p>Instead, it needed to be written as:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>RETURN LENGTH((FOR doc IN collection RETURN doc))</span></code></pre></td></tr></table></div></figure>


<p>This has caused several support questions over time, and I have to
admit the double brackets were not intuitive. In fact, they were an
artifact required by the AQL parser in order to parse the query
correctly.</p>

<p>For 2.4, the AQL grammar has now been cleaned up in this respect.
Double brackets are still allowed in 2.4 but are not required anymore.
This should make the first steps with AQL a bit easier.</p>

<p>We&rsquo;re 1.5 days into our retreat now. Maybe there&rsquo;ll be some more
AQL-related improvements in the end. Let&rsquo;s see.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Tour Around the New AQL Query Optimizer]]></title>
    <link href="http://jsteemann.github.io/blog/2014/11/07/a-tour-around-the-aql-query-optimizer/"/>
    <updated>2014-11-07T22:30:10+01:00</updated>
    <id>http://jsteemann.github.io/blog/2014/11/07/a-tour-around-the-aql-query-optimizer</id>
    <content type="html"><![CDATA[<p>The major new feature in ArangoDB 2.3 is the shiny new
AQL query optimizer and executor. These parts of ArangoDB have been
rewritten in 2.3 to make AQL much better for our end users.</p>

<!-- more -->


<p>Since one of the initial releases, ArangoDB has been shipped with
AQL, the <em>ArangoDB Query Language</em>. AQL has since then been ArangoDB&rsquo;s
most versatile way of executing simple and also the not-so-simple
queries.</p>

<p>I&rsquo;ll start with an overview of query execution in previous versions
of ArangoDB, and then explain the new engine and explain the differences.</p>

<h2>History: query execution in pre-2.3</h2>

<p>Previous versions of ArangoDB executed any AQL query in the following
steps:</p>

<ul>
<li>tokenize and parse query string into an abstract syntax tree (AST)</li>
<li>perform simple AST optimizations</li>
<li>collect filter conditions in AST and look for index usage opportunities</li>
<li>generate code</li>
<li>execute code</li>
</ul>


<p>This approach was simple and has worked for a lot of queries, but it also
had a few quirks:</p>

<p>First of all, most of the steps were carried out directly on the
abstract syntax tree, with the AST nodes being modified in place.
There was also just the one AST per query, so the old AQL executor
could not generate multiple, potentially very different execution
plan candidates for a given query.</p>

<p>The &ldquo;old&rdquo; optimizer was able to move AST nodes around during optimization
and it was already able to consider multiple index candidates for a query,
but it would not compare multiple plans and make a cost-based decision.
It was also limited in the amount and scope of transformations it
could safely apply to the AST.</p>

<p>When it came to code generation and execution, the &ldquo;old&rdquo; executor
fully relied on V8 to execute the queries. Result sets were created
using V8&rsquo;s value objects. Documents from collections that queries
needed to iterate over had to be made available to V8. While some
optimization was used for this, the conversions could have summed up
to significant overhead for certain kinds of queries.</p>

<p>The representation of queries via an AST also made it hard to generate
code that supported lazy evaluation during query execution.</p>

<p>Finally, the AQL optimizer so far did not provide much support for
queries that were to be executed in a distributed fashion inside a cluster
of servers.</p>

<h2>Query execution in ArangoDB 2.3</h2>

<p>We wanted to address all these issues with a rewrite of the AQL
infrastructure. Starting with ArangoDB 2.3, AQL queries are executed
in these steps:</p>

<ul>
<li>tokenize and parse query string into an abstract syntax tree (AST)</li>
<li>perform simple AST optimizations</li>
<li>transform AST into execution plan</li>
<li>optimize and permute execution plans</li>
<li>estimate costs for execution plans and pick optimal plan</li>
<li>instanciate execution engine from optimal plan</li>
<li>(in cluster only) send execution plan parts to cluster nodes</li>
<li>execute query</li>
</ul>


<p>Tokenization and parsing of AQL queries hasn&rsquo;t changed much in 2.3:
query strings are still parsed using a Bison/Flex-based parser and
lexer combo. The AST structure has proven to be good during the parsing
stage, so the parser creates an initial AST from the query string first.</p>

<p>After that, simple optimizations are performed directly on the AST,
such as constant folding and constant propagation. Deterministic functions
with constant operands will be executed already in this stage and the
results be injected into the AST.</p>

<p>A major change in 2.3 is that no further transformations will be
carried out on the AST. Instead, the AST will be transformed into
an initial <em>execution plan</em>.</p>

<p>This execution plan is the starting point for the <em>query optimizer</em>.
It will take the initial execution plan and apply transformations to
it. Transformations will either update the existing plan in place or
create a new, modified plan. The result of the transformations carried
out will form the input for further transformations that can be carried
out by query optimizer.</p>

<p>The result of the query optimization stage is one or many execution
plans. For each plan, the optimizer will estimate a cost value, and
then finally pick the plan with the lowest total estimated cost.
This plan is considered to be the <em>optimal plan</em>. All other execution
plans will be discarded by the optimizer as it has considered them non-optimal.</p>

<p>The optimal execution plan is then executed by the <em>execution engine</em>.
For a single-server AQL query, this is straightforward: for each step
in the execution plan, a C++ object is created that is supposed to
execute the particular step. Query execution is then started by asking
the first of these objects for its results.</p>

<p>The objects for multiple processing steps are linked in a pipelined fashion
with lazy evaluation. Pulling data from the first object will eventually
trigger pulling data from the second object etc., until there are no more
results to produce.</p>

<p>For a distributed query, this is a bit more complicated. The different
execution steps will likely be shipped to different servers in the
cluster, and the objects need to be instanciated in different servers, too.
The different parts of the query may pull data from each other via HTTP
calls between cluster nodes.</p>

<h2>How execution plans work</h2>

<p>An execution plan is a sequence of query execution steps. Let&rsquo;s
start with a very simple example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FOR doc IN mycollection
</span><span class='line'>  RETURN doc._key</span></code></pre></td></tr></table></div></figure>


<p>This query will be transformed into the following execution plan:</p>

<ul>
<li><em>SingletonNode</em>: passes a single empty value to the following steps</li>
<li><em>EnumerateCollectionNode</em>: iterates over all documents of a collection
and provides the current document in an output variable. In our example,
it will iterate over collection <code>mycollection</code> and provide each
document in variable <code>doc</code></li>
<li><em>CalculationNode</em>: evaluates an expression and returns its result.
In the example, it will calculate <code>doc._key</code></li>
<li><em>ReturnNode</em>: returns results to the caller</li>
</ul>


<p>If this plan is going to be executed, the execution engine will start
pulling data from the node at the bottom, that is, the <em>ReturnNode</em>. The
<em>ReturnNode</em> at this stage cannot provide any data, so it will ask its
predecessor node, which in the example is the <em>CalculationNode</em>. The
<em>CalculationNode</em> again does not have own data yet, so it must ask the
node in front of it. The <em>EnumerateCollectionNode</em> will first ask the
<em>SingletonNode</em> for input data. So the execution flow has bubbled up from
the bottom of the sequence to the top.</p>

<p>The <em>SingletonNode</em> will now produce a single empty return value. It will
also internally set its processing status to <em>done</em>, so it will not produce
any more values if asked again. This is all a <em>SingletonNode</em> will ever do.
We&rsquo;ll see later why such a node may still be useful.</p>

<p>The single empty value will be provided as input to the <em>EnumerateCollectionNode</em>.
This node will now go through all the documents in the underlying collection,
and return them once for each input value its got. As its input value was
the singleton, it will return the documents of the collection just once.</p>

<p>Processing is executed in blocks of size 1000 by default. The
<em>EnumerateCollectionNode</em> will thus not return all documents to its successor
node, but just 1,000. The return value will be a vector with 1,000 documents,
stored under variable name <code>doc</code>.</p>

<p>The <em>CalculationNode</em>, still waiting for input data, can now execute its
expression <code>doc._key</code> on this input value. It will execute this expression
1,000 times, once for each input value. The expression results will be
stored in another variable. This variable is anonymous, as it hasn&rsquo;t been
named explicitly in the original query. The vector of results produced by
the <em>CalculationNode</em> is then returned to the <em>ReturnNode</em>, which will then
return it to the caller.</p>

<p>If the caller requests more documents, the procedure will repeat. Whenever
a processing step cannot produce any more data, it will ask its predecessor
step for more data. If the predecessor step already has status <em>done</em>, the
current step will set itself to <em>done</em> as well, so a query will actually
come to an end if there are no more results.</p>

<p>As can be seen, steps are executed with batches of values. We thought this
would be a good way to improve efficiency and reduce the number of hops
between steps.</p>

<h2>Joins</h2>

<p>Let&rsquo;s say we want to join documents from two collections, based on common
attribute values. Let&rsquo;s use <code>users</code> and <code>logins</code>, joined by their <code>id</code> and
<code>userId</code> attributes:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FOR user IN users
</span><span class='line'>  FOR login IN logins
</span><span class='line'>    FILTER user.id == login.userId
</span><span class='line'>    RETURN { user: user, login: login }</span></code></pre></td></tr></table></div></figure>


<p>Provided that there are no indexes, the query may be turned into this
execution plan by the optimizer:</p>

<ul>
<li><em>SingletonNode</em>: passes a single empty value to the following steps</li>
<li><em>EnumerateCollectionNode</em>: will iterate over all documents in collection
<code>users</code> and produce a variable named <code>user</code></li>
<li><em>EnumerateCollectionNode</em>: will iterate over all documents in collection
<code>logins</code> and produce a variable named <code>login</code></li>
<li><em>CalculationNode</em>: will calculate the result of the expression
<code>user.id == login.userId</code></li>
<li><em>FilterNode</em>: will let only documents pass that match the filter condition
(calculated by the <em>CalculationNode</em> above it)</li>
<li><em>CalculationNode</em>: will calculate the result of the expression
<code>{ user: user, login: login }</code></li>
<li><em>ReturnNode</em>: returns results to the caller</li>
</ul>


<p>Now we can see why the <em>SingletonNode</em> is useful: it can be used as an
input to another node, telling this node to execute just once. Having the
<em>SingletonNode</em> will ensure that the outermost <em>EnumerateCollection</em>
will only iterate once over the documents in its underlying collection <code>users</code>.</p>

<p>The inner <em>EnumerateCollectionNode</em> for collection <code>logins</code> is now fed by
the outer <em>EnumerateCollectionNode</em> on <code>users</code>. Thus these two nodes will
produce a cartesian product. This will be done lazily, as producing results
will normally happen in chunks of 1,000 values each.</p>

<p>The results of the cartesian product are then post-filtered by the <code>FilterNode</code>,
which will only let those documents pass that match the filter condition of
the query. The <code>FilterNode</code> employs its predecessor, the <code>CalculationNode</code>,
to determine which values satisfy the condition.</p>

<h2>Using indexes</h2>

<p>Obviously creating cartesian products is not ideal. The optimizer will try
to avoid generating such plans if it can, but it has no choice if there are
no indexes present.</p>

<p>If there are indexes on attributes that are used in <code>FILTER</code> conditions of
a query, the optimizer will try to turn <code>EnumerateCollectionNode</code>s into
<code>IndexRangeNode</code>s. The purpose of an <code>IndexRangeNode</code> is to iterate over a
specific range in an index. This is normally more efficient than iterating
over all documents of a collection.</p>

<p>Let&rsquo;s assume there is an index on <code>logins.userId</code>. Then the optimizer might
be able to generate a plan like this:</p>

<ul>
<li><em>SingletonNode</em>: passes a single empty value to the following steps</li>
<li><em>EnumerateCollectionNode</em>: will iterate over all documents in collection
<code>users</code> and produce a variable named <code>user</code></li>
<li><em>IndexRangeNode</em>: will iterate over the values in index <code>logins.userId</code> that
match the value of <code>users.id</code> and produce a variable named <code>login</code></li>
<li><em>CalculationNode</em>: will calculate the result of the expression
<code>user.id == login.userId</code></li>
<li><em>FilterNode</em>: will let only documents pass that match the filter condition
(calculated by the <em>CalculationNode</em> above it)</li>
<li><em>CalculationNode</em>: will calculate the result of the expression
<code>{ user: user, login: login }</code></li>
<li><em>ReturnNode</em>: returns results to the caller</li>
</ul>


<p>To run this query, the execution engine must still iterate over all documents
in collection <code>users</code>, but for each of those, it only needs to find the documents
in <code>logins</code> that match the join condition. This most likely means a lot less
lookups and thus much faster execution.</p>

<h2>Permutation of loops</h2>

<p>Now consider adding an extra <code>FILTER</code> statement to the original query so we
end up with this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FOR user IN users
</span><span class='line'>  FOR login IN logins
</span><span class='line'>    FILTER user.id == login.userId
</span><span class='line'>    FILTER login.ts == 1415402319       /* added this one! */
</span><span class='line'>    RETURN { user: user, login: login }</span></code></pre></td></tr></table></div></figure>


<p>The optimizer is free to permute the order of <code>FOR</code> loops as long as this
won&rsquo;t change the results of a query. In our case, permutation of the two
<code>FOR</code> loops is allowed (the query does not contain a <code>SORT</code> instruction so
the order of results is not guaranteed).</p>

<p>If the optimizer exchanges the two loops, it can also pull out the <code>FILTER</code>
statement on <code>login.ts</code> out of the inner loop, and move up into the outer loop.
It might come up with a plan like this, which may be more efficient if a
lot of documents from <code>logins</code> can be filtered out early:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FOR login IN logins
</span><span class='line'>  FILTER login.ts == 1415402319
</span><span class='line'>  FOR user IN users
</span><span class='line'>    FILTER user.id == login.userId
</span><span class='line'>    RETURN { user: user, login: login }</span></code></pre></td></tr></table></div></figure>


<p>Exchanging the order of <code>FOR</code> loops may also allow the optimizer to use
additional indexes.</p>

<p>A last note on indexes: the optimizer in 2.3 is able to use (sorted)
skiplist indexes to eliminate extra <code>SORT</code> operations. For example, if
there is a skiplist index on <code>login.ts</code>, the <code>SORT</code> in the following
query can be removed by the optimizer:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FOR login IN logins
</span><span class='line'>  FILTER login.ts &gt; 1415402319
</span><span class='line'>  SORT login.ts
</span><span class='line'>  RETURN login</span></code></pre></td></tr></table></div></figure>


<p>The AQL optimizer in 2.3 can optimize away a <code>SORT</code> even if the sort
order is backwards or if no <code>FILTER</code> statement is used in the query at
all.</p>

<h2>Analyzing plans</h2>

<p>One particular improvement over 2.2 is that in ArangoDB 2.3 the optimizer
provides functionality for retrieving full execution plan information for
queries <strong>without</strong> executing them. The execution plan information can be
inspected by developers or DBAs, and, as it is JSON-encoded, can also be
analyzed programmatically.</p>

<p>Retrieving the execution plan for a query is straight-forward:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>arangosh&gt; db._createStatement({ query: &lt;query&gt; }).explain();</span></code></pre></td></tr></table></div></figure>


<p>By default, the optimizer will return just the <em>optimal plan</em>, containing
all the plan&rsquo;s execution nodes with lots of extra information plus cost estimates.</p>

<p>The optimizer is also able to return the alternative plans it produced but
considered to be non-optimal:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>arangosh&gt; db._createStatement({ query: &lt;query&gt; }).explain({ allPlans: true });</span></code></pre></td></tr></table></div></figure>


<p>This will hopefully allow developers and DBAs to get a better idea of how an
AQL query will be executed internally.</p>

<p>Additionally, simple execution statistics are returned by default when executing
a query. This statistics can also be used to get an idea of the runtime costs of
a query <strong>after</strong> execution.</p>

<h2>Writing optimizer rules</h2>

<p>The AQL optimizer itself is dumb. It will simply try to apply all transformations
from its rulebook to each input execution plan it is feeded with. This
will produce output execution plans, on which further transformations
may or may not be applied.</p>

<p>The more interesting part of the AQL optimizer stage is thus the rulebook.
Each rule in the rulebook is a C++ function that is executed for an input plan.</p>

<p>Adding a new optimizer rule to the rulebook is intentionally simple. One of
the design goals of the new AQL optimizer was to keep it flexible and extensible.
All that&rsquo;s need to be to add an optimizer rule is to implement a C++ function
with the following signature:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='cpp'><span class='line'><span class="p">(</span><span class="n">Optimizer</span><span class="o">*</span><span class="p">,</span> <span class="n">ExecutionPlan</span><span class="o">*</span><span class="p">,</span> <span class="n">Optimizer</span><span class="o">::</span><span class="n">Rule</span> <span class="k">const</span><span class="o">*</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kt">int</span>
</span></code></pre></td></tr></table></div></figure>


<p>and register it once in the Optimizer&rsquo;s rulebook.</p>

<p>An optimizer rule function is called with an instance of the query optimizer
(it can use it to register a new plan), the current execution plan and some
information about the rule itself (this is the information about the rule from
the rulebook).</p>

<p>The optimizer rule function can then analyze the input execution plan, modifiy
it in place, and/or create additional plans. It must return a status code to
the optimizer to indicate if something went wrong.</p>

<h2>Outlook</h2>

<p>The AQL optimizer features described here are available in ArangoDB 2.3, which
is currently in <a href="https://www.arangodb.com/install-beta-version">beta stage</a>.</p>

<p>Writing a perfect query optimizer is a never-ending endeavour. Other databases
provide new optimizer features and fixes even decades after the initial version.</p>

<p>Our plan is to ship 2.3 with several essential and useful optimizer rules. We
will likely add more in future releases. We&rsquo;re also open to contributions.
If you can think of rules that are missing but you would like to see in ArangoDB,
please let us know. If you would like to contribute to the optimizer and write some
rule code, consider sending a pull request or an email to
<a href="hackers@arangodb.org">hackers@arangodb.org</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improved Non-unique Hash Indexes in 2.3]]></title>
    <link href="http://jsteemann.github.io/blog/2014/11/07/improved-non-unique-hash-indexes/"/>
    <updated>2014-11-07T20:51:12+01:00</updated>
    <id>http://jsteemann.github.io/blog/2014/11/07/improved-non-unique-hash-indexes</id>
    <content type="html"><![CDATA[<p>With ArangoDB 2.3 now getting into the <a href="https://www.arangodb.com/install-beta-version">beta stage</a>,
it&rsquo;s time to spread the word about new features and improvements.</p>

<p>Today&rsquo;s post will be about the changes made to non-unique hash
indexes.</p>

<!-- more -->


<p>Hash indexes allow looking up documents quickly if the indexed
attributes are all provided in a search query. They are not
suitable for range queries, but are the perfect choice if equality
comparisons are all that&rsquo;s needed.</p>

<p>Hash indexes have been available in ArangoDB ever since. There
have always been two variants of them:</p>

<ul>
<li>unique hash indexes</li>
<li>non-unique hash indexes</li>
</ul>


<p>There wasn&rsquo;t much to be done for unique hash indexes, and so there
haven&rsquo;t been any changes to them in 2.3. However, the non-unique
hash indexes were improved significantly in the new version.</p>

<p>The non-unique indexes already performed quite well if most of the
indexed values were unique and only few repetitions occurred. But their
performance suffered severly if the indexed attribute values repeated
a lot &ndash; that is, when the indexed value had a <strong>low cardinality</strong> and thus
the index had a <strong>low selectivity</strong>.</p>

<p>This was a problem because it slowed down inserting new documents into
a collection with such an index. And it also slowed down loading collections
with low cardinality hash indexes.</p>

<p>I am happy to state that in ArangoDB 2.3 this has been fixed, and the insert
performance of non-unique hash indexes has been improved significantly.
The index insertion time now scales quite well with the number
of indexed documents regardless of the cardinality of the indexed
attribute.</p>

<p>Following are a few measurements of non-unique hash index insertion
times from ArangoDB 2.3, for different cardinalities of the indexed
attribute.</p>

<p>The times reported are the net non-unique hash index
insertion times (the documents were present already, just the index
was created on them and index creation time was measured).</p>

<p>Let&rsquo;s start with a not too challenging case: indexing documents in
a collection with 100,000 different index values (<em>cardinality 100,000</em>):</p>

<figure class='code'><figcaption><span>index insertion times for cardinality 100,000</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>number of documents:    128,000    =&gt;    time:   0.144 s
</span><span class='line'>number of documents:    256,000    =&gt;    time:   0.231 s
</span><span class='line'>number of documents:    512,000    =&gt;    time:   0.347 s
</span><span class='line'>number of documents:  1,024,000    =&gt;    time:   0.694 s
</span><span class='line'>number of documents:  2,048,000    =&gt;    time:   1.379 s
</span></code></pre></td></tr></table></div></figure>


<p>The picture doesn&rsquo;t change much when reducing the cardinality
by a factor or 10 (i.e. <em>cardinality 10,000</em>):</p>

<figure class='code'><figcaption><span>index insertion times for cardinality 10,000</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>number of documents:    128,000    =&gt;    time:   0.169 s
</span><span class='line'>number of documents:    256,000    =&gt;    time:   0.194 s
</span><span class='line'>number of documents:    512,000    =&gt;    time:   0.355 s
</span><span class='line'>number of documents:  1,024,000    =&gt;    time:   0.668 s
</span><span class='line'>number of documents:  2,048,000    =&gt;    time:   1.325 s
</span></code></pre></td></tr></table></div></figure>


<p>Let&rsquo;s again divide cardinality by 10 (now <em>cardinality 1,000</em>):</p>

<figure class='code'><figcaption><span>index insertion times for cardinality 1,000</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>number of documents:    128,000    =&gt;    time:   0.130 s
</span><span class='line'>number of documents:    256,000    =&gt;    time:   0.152 s
</span><span class='line'>number of documents:    512,000    =&gt;    time:   0.261 s
</span><span class='line'>number of documents:  1,024,000    =&gt;    time:   0.524 s
</span><span class='line'>number of documents:  2,048,000    =&gt;    time:   0.934 s
</span></code></pre></td></tr></table></div></figure>


<p><em>Cardinality 100</em>:</p>

<figure class='code'><figcaption><span>index insertion times for cardinality 100</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>number of documents:    128,000    =&gt;    time:   0.114 s
</span><span class='line'>number of documents:    256,000    =&gt;    time:   0.148 s
</span><span class='line'>number of documents:    512,000    =&gt;    time:   0.337 s
</span><span class='line'>number of documents:  1,024,000    =&gt;    time:   0.452 s
</span><span class='line'>number of documents:  2,048,000    =&gt;    time:   0.907 s
</span></code></pre></td></tr></table></div></figure>


<p><em>Cardinality 10</em>:</p>

<figure class='code'><figcaption><span>index insertion times for cardinality 10</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>number of documents:    128,000    =&gt;    time:   0.130 s
</span><span class='line'>number of documents:    256,000    =&gt;    time:   0.327 s
</span><span class='line'>number of documents:    512,000    =&gt;    time:   0.239 s
</span><span class='line'>number of documents:  1,024,000    =&gt;    time:   0.442 s
</span><span class='line'>number of documents:  2,048,000    =&gt;    time:   0.827 s
</span></code></pre></td></tr></table></div></figure>


<p>Finally we get to <em>cardinality 1</em>, the definitive indicator
for the index being absolutely useless. Let&rsquo;s create it anyway,
for the sake of completeness of this post:</p>

<figure class='code'><figcaption><span>index insertion times for cardinality 1</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>number of documents:    128,000    =&gt;    time:   0.130 s
</span><span class='line'>number of documents:    128,000    =&gt;    time:   0.095 s
</span><span class='line'>number of documents:    256,000    =&gt;    time:   0.146 s
</span><span class='line'>number of documents:    512,000    =&gt;    time:   0.246 s
</span><span class='line'>number of documents:  1,024,000    =&gt;    time:   0.445 s
</span><span class='line'>number of documents:  2,048,000    =&gt;    time:   0.925 s
</span></code></pre></td></tr></table></div></figure>


<p>On a side note: all indexed values were numeric. In absolute terms,
indexing string values will be slower than indexing numbers, but insertion
should still scale nicely with the number of documents as long as everything
fits in RAM.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setting Up Test Data]]></title>
    <link href="http://jsteemann.github.io/blog/2014/11/04/setting-up-test-data/"/>
    <updated>2014-11-04T22:14:21+01:00</updated>
    <id>http://jsteemann.github.io/blog/2014/11/04/setting-up-test-data</id>
    <content type="html"><![CDATA[<p>Today I was asked to look at code that was supposed to read data
from a MySQL data source, process it and then import it into ArangoDB.</p>

<p>To run and debug the code I had to have some MySQL data source. So I
thought I&rsquo;d quickly set up a simple example table with a few rows.
It turned out that this took more time than what I had expected.</p>

<p>Maybe I&rsquo;m spoilt by JavaScript-enabled, schema-free databases where
creating such test setups is so much easier.</p>

<!-- more -->


<p>I worked with MySQL databases in production for 10+ years and spent
much time working with the mysql client. I always liked MySQL, but in
the past few years, I was driven away from it and lost contact.
Instead, I got sucked into the NoSQL landscape and enjoy it pretty much.</p>

<p>Getting back to the original problem: I needed some MySQL table with a
few thousand rows for a test. It turned out I didn&rsquo;t even have MySQL
installed on my computer, so I needed to install it first.</p>

<p>After setting up the MySQL server, I created a table <code>examples</code> for
storing my test data:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sql'><span class='line'><span class="k">CREATE</span> <span class="k">DATABASE</span> <span class="n">test</span><span class="p">;</span>
</span><span class='line'><span class="n">USE</span> <span class="n">test</span><span class="p">;</span>
</span><span class='line'><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">examples</span> <span class="p">(</span><span class="n">attribute1</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span> <span class="n">attribute2</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">20</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure>


<p>Not really the black belt of schema design, but good enough for a quick
test.</p>

<p>Now the table needed some rows. 100,000 rows should be enough. I wrote
some bash script to create them as there is no sane way to do this with
the MySQL client alone:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="k">for </span>i in <span class="sb">`</span>seq 1 100000<span class="sb">`</span>
</span><span class='line'>  <span class="k">do </span>
</span><span class='line'><span class="k">    </span><span class="nb">echo</span> <span class="s2">&quot;INSERT INTO examples VALUES (\&quot;test$i\&quot;, \&quot;test$i\&quot;);&quot;</span> &gt;&gt; import.sql
</span><span class='line'>  <span class="k">done</span>
</span></code></pre></td></tr></table></div></figure>


<p>Time to import the data!</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>mysql -u user <span class="nb">test</span> &lt; import.sql
</span></code></pre></td></tr></table></div></figure>


<p>At first I was a bit surprised this command did not return instantly. I let it
run for about a minute, and then began checking the import progress with a second mysql
client. It turned out only very few records had been imported, and the import
script continued to create only around 30-35 records per second.</p>

<p>Seems I had forgotten that I am working with a No-NoSQL database, with full
ACID semantics for everything. My import file contained 100,000 <code>INSERT</code>
statements, so I was asking to perform 100,000 transactions and fsync operations.
That import would have taken forever with my slow HDD!</p>

<p>I quickly changed the InnoDB setting to make it commit only about once per second:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>mysql&gt; SET GLOBAL <span class="nv">innodb_flush_log_at_trx_commit</span> <span class="o">=</span> 2;
</span><span class='line'>Query OK, 0 rows affected <span class="o">(</span>0.00 sec<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now the import finished in 7 seconds.</p>

<p>I finally got the data in MySQL, but overall it took me about 10 minutes to get
it done. Probably a bit less if I still were an active user of MySQL and had
remembered the default behavior right from the start.</p>

<p>Still, my feeling is that it takes too much time to get something so simple
done.</p>

<p>I don&rsquo;t blame the database for trying to commit all 100,000 single-row
<code>INSERT</code> operations and fsync them to disk. It simply cannot know if the data
are important or just throw-away test records.</p>

<p>But there are other reasons: I had to write a bash script to produce the
test data, as there is no sane way to do this with the MySQL client alone.
Writing bash scripts is fine, and in general I like it, but I don&rsquo;t want to
do it for a dead-simple test setup.</p>

<p>And by the way, what if it turns out that I need to generate slightly more
complex test data? In the MySQL case I probably would have resorted to sed
or awk or would have thrown away my bash script and had rewritten it in some
other language. So I would have wasted even more time.</p>

<p>I personally prefer the ability to use a scripting language for such tasks.
JavaScript is ubiquituous these days, and I want to use it in a database&rsquo;s
command-line client.</p>

<p>For example, here&rsquo;s how the test setup would look like in the ArangoShell:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">_create</span><span class="p">(</span><span class="s2">&quot;examples&quot;</span><span class="p">);</span>
</span><span class='line'><span class="k">for</span> <span class="p">(</span><span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">;</span> <span class="o">++</span><span class="nx">i</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">db</span><span class="p">.</span><span class="nx">examples</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">attribute1</span><span class="o">:</span> <span class="s2">&quot;test&quot;</span> <span class="o">+</span> <span class="nx">i</span><span class="p">,</span> <span class="nx">attribute2</span><span class="o">:</span> <span class="s2">&quot;test&quot;</span> <span class="o">+</span> <span class="nx">i</span> <span class="p">});</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>I find this much easier to use: it allows to do everything in one place,
removing the need to write another script that prepares a data file or an
SQL file first.</p>

<p>As a bonus, using a programming language is much more flexible and powerful.
If I needed to generate slightly more complex test data, I can just do it,
adjust the JavaScript code and re-run it.</p>

<p>Even more annoying to me is that I needed to provide a schema for the
table first. I could have got away with declaring all text fields as
<code>VARCHAR(255)</code> or <code>TEXT</code> so I can at least ignore string
length restrictions. But I still need to type in the table schema
once, even if it feels completely useless for this particular use case.</p>

<p>It would get even more annoying if during my test I noticed I needed more
or other columns. Then I would need to adjust the table schema using <code>ALTER TABLE</code>
or adjust the <code>CREATE TABLE</code> statement and run it again, keeping me
away from the original task.</p>

<p>Maybe using schema-free databases for too long has spoilt me, but I much
more prefer starting quickly and without a schema. I know the data that
I am going to load will have a structure and will be somewhat self-describing,
so the database can still figure out what the individual parts of a record are.</p>

<p><em>On a side-note: should you be a fan of using query languages, the same
test setup can also be achieved by running the following AQL query from
the ArangoShell</em>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">_query</span><span class="p">(</span><span class="s2">&quot;FOR i IN 1..100000 LET value = CONCAT(&#39;test&#39;, i) &quot;</span> <span class="o">+</span>
</span><span class='line'>          <span class="s2">&quot;INSERT { attribute1: value, attribute2: value } INTO examples&quot;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Core Dumps of Failed TravisCI Builds]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/30/getting-core-dumps-of-failed-travisci-builds/"/>
    <updated>2014-10-30T23:05:48+01:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/30/getting-core-dumps-of-failed-travisci-builds</id>
    <content type="html"><![CDATA[<p>I recently wrote about <a href="http://jsteemann.github.io/blog/2014/10/17/using-travis-ci-for-a-c-plus-plus-11-project/">using TravisCI for continuously testing C++11 projects</a>.</p>

<p><strong>Now, what if a build fails?</strong></p>

<p>Especially for C and C++ projects, build failures may mean crashed
programs. In a local setup, the usual way to analyze program crashes
is to manually inspect the core files that are written on crash.</p>

<p>With TravisCI, there is no way to log in to a build machine and
inspect a core dump interactively. There is no SSH access to
the build machines. TravisCI does not even persist any state of
builds but the result and the log output.</p>

<p>There is a way to get to the core dumps, but it was fiddly to find
out and set up.</p>

<!-- more -->


<p>The basic idea is to run <code>gdb</code> on the TravisCI build machine
automatically when a build fails. <code>gdb</code> can be scripted, so all
we need to do is to make it print a backtrace in all threads at
the time of the crash.</p>

<p>By default, no core dumps will be produced on TravisCI. To turn them
on, an appropriate ulimit value must be set. We also need to install
<code>gdb</code> so we can actually run it. Here is the <code>.travis.yml</code> adjustment
for these prerequisites:</p>

<figure class='code'><figcaption><span>adjustments for install and before_script hooks</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">install</span><span class="p-Indicator">:</span>
</span><span class='line'><span class="p-Indicator">-</span> <span class="l-Scalar-Plain">sudo apt-get install -y gdb</span>  <span class="c1"># install gdb</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">before_script</span><span class="p-Indicator">:</span>
</span><span class='line'><span class="p-Indicator">-</span> <span class="l-Scalar-Plain">ulimit -c unlimited -S</span>       <span class="c1"># enable core dumps</span>
</span></code></pre></td></tr></table></div></figure>


<p>To get an idea of where the program crashed, we can finally install
an <code>after_failure</code> hook. This hook can check for a core file and use
<code>gdb</code> to print a nice backtrace.</p>

<p>The core file pattern on TravisCI seems to be <code>core-%p</code>, so core
filenames will include the executable&rsquo;s process id and change on
every run. We can use <code>find</code> to look for files named <code>core*</code> in the
cwd and pick the first one as there should only be at most one core
file per build:</p>

<figure class='code'><figcaption><span>adjustments for after_failure hook</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">after_failure</span><span class="p-Indicator">:</span>
</span><span class='line'><span class="p-Indicator">-</span> <span class="l-Scalar-Plain">COREFILE=$(find . -maxdepth 1 -name &quot;core*&quot; | head -n 1)</span> <span class="c1"># find core file</span>
</span><span class='line'><span class="p-Indicator">-</span> <span class="l-Scalar-Plain">if [[ -f &quot;$COREFILE&quot; ]]; then gdb -c &quot;$COREFILE&quot; example -ex &quot;thread apply all bt&quot; -ex &quot;set pagination 0&quot; -batch; fi</span>
</span></code></pre></td></tr></table></div></figure>


<p>A failed build might produce output like this:</p>

<p><img src="http://jsteemann.github.io/downloads/screenshots/travis-ci-gdb.png"></p>

<p>I recommend compiling the executable to test with debug symbols on and
with all optimizations turned off (i.e. compiler options <code>-g -O0</code>).
Otherwise backtraces might reveal less useful information for debugging.</p>

<p>On a side note: the <a href="http://lint.travis-ci.org/">Travis WebLint</a> is a
handy tool for validating <code>.travis.yml</code> files <em>before</em> pushing them.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What I Most Like About C++11]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/23/what-i-most-like-about-c-plus-plus-11/"/>
    <updated>2014-10-23T23:02:12+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/23/what-i-most-like-about-c-plus-plus-11</id>
    <content type="html"><![CDATA[<p>About half a year ago we started compiling our code with <code>-std=c++11</code>.</p>

<p>We had to fix a few, but not too many code parts for this. That was
the easy part.</p>

<p>Getting C++11 to work on all supported platforms, build and testing
environments was a bit more challenging, but we finally managed to do it.</p>

<p>Having used C++11 for some time now, I think it&rsquo;s time to share a few
of improvements in C++11 that solve common problems.</p>

<!-- more -->


<p>First of all, I don&rsquo;t regret we changed to it. In my opinion,
<strong>C++11 makes coding easier and safer.</strong> I will try to demonstrate that
with a few examples in a second.</p>

<p>Before I go into details, just let me state that I will only show a few
of my personal favorites here. There are so many more improvements in C++11
that are all worth having a look. If you haven&rsquo;t looked into C++11 much,
I recommend getting started at the <a href="http://en.wikipedia.org/wiki/C%2B%2B11">Wikipedia page about C++11</a>.</p>

<h2>Auto</h2>

<p>From a developer perspective, one of the most compelling features of
C++11 is the revamped <code>auto</code> keyword. Consider the following C++98/C++03 code:</p>

<figure class='code'><figcaption><span>C++03 version</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;::</span><span class="n">iterator</span> <span class="n">it</span> <span class="o">=</span> <span class="n">resultHeaders</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">value</span><span class="p">);</span>
</span><span class='line'><span class="k">if</span> <span class="p">(</span><span class="n">it</span> <span class="o">!=</span> <span class="n">resultHeaders</span><span class="p">.</span><span class="n">end</span><span class="p">())</span> <span class="p">{</span>
</span><span class='line'>  <span class="c1">// do something with value</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>In C++11 this code can be simplified to:</p>

<figure class='code'><figcaption><span>C++11 version with auto</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="k">auto</span> <span class="n">it</span> <span class="o">=</span> <span class="n">resultHeaders</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">value</span><span class="p">);</span>
</span><span class='line'><span class="k">if</span> <span class="p">(</span><span class="n">it</span> <span class="o">!=</span> <span class="n">resultHeaders</span><span class="p">.</span><span class="n">end</span><span class="p">())</span> <span class="p">{</span>
</span><span class='line'>  <span class="c1">// do something with value</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>In the C++11 version of the code, the compiler can figure out the type of
variable <code>it</code> all by itself. This allows writing less (i.e. better) code.</p>

<p>The more complex the types are, the more helpful this gets. Compare the
following two lines and check for yourself which one you prefer:</p>

<figure class='code'><figcaption><span>C++03 version</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">CollectionID</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;</span> <span class="o">&gt;</span> <span class="o">&gt;::</span><span class="n">iterator</span> <span class="n">it</span> <span class="o">=</span> <span class="n">shards</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">collectionID</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>C++11 version with auto</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="k">auto</span> <span class="n">it</span> <span class="o">=</span> <span class="n">shards</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">collectionID</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>auto</code> provides an <em>extra benefit</em>:
when using <code>auto</code> it is not necessary to repeat the type information
throughout the code. This is helpful when types need to be changed and the
change needs to be reflected everywhere. With <code>auto</code>, chances are that less
code needs to be adjusted. And it is not necessary to set up extra
typedefs for this.</p>

<p>If you think <code>auto</code> obfuscates the meaning too much, you can be a bit more
expressive, e.g.</p>

<figure class='code'><figcaption><span>C++11 version with auto, const reference</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="k">auto</span> <span class="k">const</span><span class="o">&amp;</span> <span class="n">it</span> <span class="o">=</span> <span class="n">resultHeaders</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">value</span><span class="p">);</span>
</span><span class='line'><span class="k">if</span> <span class="p">(</span><span class="n">it</span> <span class="o">!=</span> <span class="n">resultHeaders</span><span class="p">.</span><span class="n">end</span><span class="p">())</span> <span class="p">{</span>
</span><span class='line'>  <span class="c1">// do something with value</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Range-based loops</h2>

<p>We all have written a lot of code that iterates over a ranges, like this:</p>

<figure class='code'><figcaption><span>C++03: iterating over a range</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">string</span><span class="p">,</span> <span class="n">AgencyCommResultEntry</span><span class="o">&gt;::</span><span class="n">iterator</span> <span class="n">it</span><span class="p">;</span>
</span><span class='line'><span class="k">for</span> <span class="p">(</span><span class="n">it</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span> <span class="n">it</span> <span class="o">!=</span> <span class="n">result</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="n">end</span><span class="p">();</span> <span class="o">++</span><span class="n">it</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="c1">// do something with it</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>C++11 provides a special range-based syntax for <code>for</code> loops, which makes
this a lot easier and compact:</p>

<figure class='code'><figcaption><span>C++11: iterating over a range</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="n">it</span> <span class="o">:</span> <span class="n">result</span><span class="p">.</span><span class="n">values</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="c1">// do something with it</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Decltype</h2>

<p>As we have seen, the compiler can deduce the type of expressions
automatically. C++11 also allows using this type information with the
<code>decltype</code> keyword. This allows to write more generic and maintainable code.</p>

<p>In the following code, the type of variable <code>document</code> is a pointer to a
<code>Document</code>. Variable <code>myDocument</code> has the same type:</p>

<figure class='code'><figcaption><span>C++03 explicit type specification </span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="n">Document</span><span class="o">*</span> <span class="n">document</span> <span class="o">=</span> <span class="n">res</span><span class="o">-&gt;</span><span class="n">getDocumentCollection</span><span class="p">(</span><span class="n">registerId</span><span class="p">);</span>
</span><span class='line'><span class="n">Document</span><span class="o">*</span> <span class="n">myDocument</span> <span class="o">=</span> <span class="n">document</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>In C++03, we couldn&rsquo;t tell the compiler that the two variables should
always have the same types. In C++11, we can explicitly give <code>myDocument</code>
the same type as <code>document</code>, without any typedefs:</p>

<figure class='code'><figcaption><span>C++11 automatic type deduction</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="err">```</span><span class="n">c</span><span class="o">++</span> <span class="n">C</span><span class="o">++</span><span class="mi">11</span> <span class="n">automatic</span> <span class="n">type</span> <span class="n">deduction</span>
</span><span class='line'><span class="k">auto</span><span class="o">*</span> <span class="n">document</span> <span class="o">=</span> <span class="n">res</span><span class="o">-&gt;</span><span class="n">getDocumentCollection</span><span class="p">(</span><span class="n">registerId</span><span class="p">);</span>
</span><span class='line'><span class="n">decltype</span><span class="p">(</span><span class="n">document</span><span class="p">)</span> <span class="n">myDocument</span> <span class="o">=</span> <span class="n">document</span><span class="p">;</span>  <span class="c1">// myDocument has same type as document</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>decltype</code> can also be used to deduce the type of expressions.</p>

<h2>Lambdas / Closures</h2>

<p>Lambdas are available in most other mainstream languages today, and they
are available in C++11, too.</p>

<p>Probably one of the most common use cases for a lambda is a custom
comparator function for sorting:</p>

<figure class='code'><figcaption><span>custom comparator function using a lambda </span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="n">std</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span><span class="n">operations</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span>
</span><span class='line'>          <span class="n">operations</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span>
</span><span class='line'>          <span class="p">[]</span> <span class="p">(</span><span class="n">Operation</span> <span class="k">const</span><span class="o">*</span> <span class="n">left</span><span class="p">,</span> <span class="n">Operation</span> <span class="k">const</span><span class="o">*</span> <span class="n">right</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="k">return</span> <span class="p">(</span><span class="n">left</span><span class="o">-&gt;</span><span class="n">id</span> <span class="o">&lt;</span> <span class="n">right</span><span class="o">-&gt;</span><span class="n">id</span><span class="p">);</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>In the above example, the lambda has two input parameters and produces a
boolean result. Note that the type of the result was not explicitly specified.
Again the compiler is able to figure it out automatically.</p>

<p>A lambda can be assigned to a variable, and it can be passed as a parameter
to another function/method. Lambdas can optionally have access to the
variables of the scope they were created in.</p>

<p>The following code defines a struct <code>ScopeGuard</code> that executes a lambda
in its constructor and another lambda in its destructor:</p>

<figure class='code'><figcaption><span>lambdas as function parameters</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="c1">// define ScopeGuard struct</span>
</span><span class='line'><span class="k">struct</span> <span class="n">ScopeGuard</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">ScopeGuard</span> <span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">function</span><span class="o">&lt;</span><span class="kt">void</span><span class="p">()</span><span class="o">&gt;</span> <span class="n">onEnter</span><span class="p">,</span>
</span><span class='line'>              <span class="n">std</span><span class="o">::</span><span class="n">function</span><span class="o">&lt;</span><span class="kt">void</span><span class="p">()</span><span class="o">&gt;</span> <span class="n">onExit</span><span class="p">)</span>
</span><span class='line'>    <span class="o">:</span> <span class="n">onExit</span><span class="p">(</span><span class="n">onExit</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>      <span class="n">onEnter</span><span class="p">();</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="o">~</span><span class="n">ScopeGuard</span> <span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">onExit</span><span class="p">();</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">std</span><span class="o">::</span><span class="n">function</span><span class="o">&lt;</span><span class="kt">void</span><span class="p">()</span><span class="o">&gt;</span> <span class="n">onExit</span><span class="p">;</span>
</span><span class='line'><span class="p">};</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// lambda to be executed in constructor</span>
</span><span class='line'><span class="k">auto</span> <span class="n">onEnter</span> <span class="o">=</span> <span class="p">[</span><span class="o">&amp;</span><span class="n">engine</span><span class="p">]()</span> <span class="o">-&gt;</span> <span class="kt">void</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">engine</span><span class="o">-&gt;</span><span class="n">getQuery</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">enterContext</span><span class="p">();</span>
</span><span class='line'><span class="p">};</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// lambda to be executed in destructor</span>
</span><span class='line'><span class="k">auto</span> <span class="n">onExit</span> <span class="o">=</span> <span class="p">[</span><span class="o">&amp;</span><span class="p">]()</span> <span class="o">-&gt;</span> <span class="kt">void</span> <span class="p">{</span>
</span><span class='line'>  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="n">expression</span> <span class="o">:</span> <span class="n">allVariableBoundExpressions</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="n">expression</span><span class="o">-&gt;</span><span class="n">invalidate</span><span class="p">();</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>  <span class="n">engine</span><span class="o">-&gt;</span><span class="n">getQuery</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">exitContext</span><span class="p">();</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// create guard object with the lambdas </span>
</span><span class='line'><span class="c1">// this will instantly execute `onEnter`</span>
</span><span class='line'><span class="n">ScopeGuard</span> <span class="n">guard</span><span class="p">(</span><span class="n">onEnter</span><span class="p">,</span> <span class="n">onExit</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// do something...</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// when scope is left, `onExit` will be executed</span>
</span></code></pre></td></tr></table></div></figure>


<p>As mentioned before, <code>decltype</code> can be used to determine the
return type of a function automatically. Here&rsquo;s an example:</p>

<figure class='code'><figcaption><span>function with automatic return type deduction</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="k">auto</span> <span class="n">add</span> <span class="o">=</span> <span class="p">[](</span><span class="kt">int</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="n">b</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">decltype</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">;</span>
</span><span class='line'><span class="p">};</span>
</span></code></pre></td></tr></table></div></figure>


<p>As can be seen in the examples above, C++11 has introduced an
alternative function declaration syntax, with the type of the
function result following a <code>-&gt;</code>. The return type can be omitted
if it can be unambiguously determined by the compiler. The new
function declaration syntax is mainly useful for lambdas, but
it can be used for regular functions, too.</p>

<h2>Enum class</h2>

<p>Enums in C++ are useful but just <em>don&rsquo;t feel right</em>: persisting a
struct that contains an enum value is not portable as the
underlying data type for the enum is implementation-dependent.</p>

<p>Additionally, enum values can be compared to almost any other values,
which in most cases doesn&rsquo;t make sense but obfuscates coding errors.
There were also <em>scoping issues</em> with enum values.</p>

<p>C++11 enum classes fix these problems. First of all, the underlying
data type for an enum can be specified. For example, this creates
an enum based with its value stored in an <code>std::uint8_t</code>:</p>

<figure class='code'><figcaption><span>enum class with specified data type</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="k">enum</span> <span class="k">class</span> <span class="nc">StatusType</span> <span class="o">:</span> <span class="n">std</span><span class="o">::</span><span class="n">uint8_t</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">UNINITIALIZED</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span class='line'>  <span class="n">STARTING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">RUNNING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">STOPPING</span><span class="p">,</span>
</span><span class='line'>  <span class="n">STOPPED</span>
</span><span class='line'><span class="p">};</span>
</span><span class='line'>
</span><span class='line'><span class="n">StatusType</span> <span class="n">status</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Regarding the comparison of enum values to other values, C++11
enum classes are much stronger typed than regular enums.
Comparing the <code>status</code> variable from the above example to anything
but a value from its enum class won&rsquo;t even compile.</p>

<p>This provides much greater type safety than when using the old,
implicitly converting enums:</p>

<figure class='code'><figcaption><span>invalid usage of enums</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="k">if</span> <span class="p">(</span><span class="n">status</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// won&#39;t compile in C++11</span>
</span><span class='line'>  <span class="c1">// ...</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'><span class="k">if</span> <span class="p">(</span><span class="n">status</span> <span class="o">==</span> <span class="n">StatusType</span><span class="o">::</span><span class="n">UNINITIALIZED</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// this would work</span>
</span><span class='line'>  <span class="c1">// ...</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Finally, enum classes fix the scoping problems of regular enums.
In C++03, the following code did not complile because two enums
contained the same member name:</p>

<figure class='code'><figcaption><span>two enums with same member name</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="k">enum</span> <span class="n">DirectionType</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">LEFT</span><span class="p">,</span>
</span><span class='line'>  <span class="n">RIGHT</span>
</span><span class='line'><span class="p">};</span>
</span><span class='line'>
</span><span class='line'><span class="k">enum</span> <span class="n">AnswerType</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">RIGHT</span><span class="p">,</span>  <span class="c1">// won&#39;t compile in C++03 and C++11</span>
</span><span class='line'>  <span class="n">WRONG</span>
</span><span class='line'><span class="p">};</span>
</span></code></pre></td></tr></table></div></figure>


<p>With C++11 enum classes, the following code is all fine:</p>

<figure class='code'><figcaption><span>two enums class with same member name</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='c++'><span class='line'><span class="k">enum</span> <span class="k">class</span> <span class="nc">DirectionType</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">LEFT</span><span class="p">,</span>
</span><span class='line'>  <span class="n">RIGHT</span>
</span><span class='line'><span class="p">};</span>
</span><span class='line'>
</span><span class='line'><span class="k">enum</span> <span class="k">class</span> <span class="nc">AnswerType</span> <span class="p">{</span>
</span><span class='line'>  <span class="n">RIGHT</span><span class="p">,</span>  <span class="c1">// works!</span>
</span><span class='line'>  <span class="n">WRONG</span>
</span><span class='line'><span class="p">};</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Additional containers</h2>

<p>C++11 provides the hash-based containers <code>std::unordered_map</code>
and <code>std::unordered_set</code> (plus their non-unique counterparts).
These containers are not sorted, so they can be more efficient
than <code>std::map</code> and <code>std::set</code>.</p>

<p>Turning an <code>std::map</code> into an <code>std::unordered_map</code> is simple as
the APIs are more or less identical.</p>

<p>There is now also a singly-linked list container, named
<code>std::forward_list</code>. This obviously allows forward iteration
only, but is more space efficient than the already existing
doubly-linked list container.</p>

<h2>More</h2>

<p>Other improvements include move semantics, atomic variables and
operations, a dedicated type for NULL pointers, STL support for
threads and mutexes, regular expressions, more Unicode support,
override, final &ndash; to name only a few&hellip;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Set Up Bash Completion for ArangoDB]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/22/how-to-set-up-bash-completion-for-arangodb/"/>
    <updated>2014-10-22T23:10:32+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/22/how-to-set-up-bash-completion-for-arangodb</id>
    <content type="html"><![CDATA[<p>I was interested in how bash auto-completion works and how to write
a custom completer. After about an hour of work, I came up with a
solution that at least seems to work on Ubuntu. I now have auto-completion
for ArangoDB and all its client tools!</p>

<!-- more -->


<h2>The problem</h2>

<p>I use the command-line for almost everything, including starting
and stopping ArangoDB and its client tools. They provide lots
of options which I cannot completely memorize.</p>

<p>The bash solution for &ldquo;I don&rsquo;t know what I am looking for&rdquo; is to
press the <strong>TAB</strong> key. This will bring up a list of suggestions for
how to complete the currently entered word. I thought using the
same thing for ArangoDB&rsquo;s command-line options would be nice, too.</p>

<h2>The solution</h2>

<p>It turned out that I needed to put a shell script that generates the
auto completion for <code>arangod</code> and all the other tools into <code>/etc/bash_completion.d</code>.
From there, the system will automatically pick it up when auto-completion
is initialized.</p>

<p>The script is rather simple. For example, to have auto-completion for
<code>arangosh</code> it would look like this:</p>

<figure class='code'><figcaption><span>completion script example for arangosh</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>_arangosh<span class="o">()</span>
</span><span class='line'><span class="o">{</span>
</span><span class='line'>    <span class="nb">local </span>cur prev opts
</span><span class='line'>    <span class="nv">COMPREPLY</span><span class="o">=()</span>
</span><span class='line'>    <span class="nv">cur</span><span class="o">=</span><span class="s2">&quot;${COMP_WORDS[COMP_CWORD]}&quot;</span>
</span><span class='line'>    <span class="nv">prev</span><span class="o">=</span><span class="s2">&quot;${COMP_WORDS[COMP_CWORD-1]}&quot;</span>
</span><span class='line'>    <span class="nv">opts</span><span class="o">=</span><span class="s2">&quot;--help --server.endpoint --server.username&quot;</span> <span class="c"># ...all the options go here</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="o">[[</span> <span class="k">${</span><span class="nv">cur</span><span class="k">}</span> <span class="o">==</span> -* <span class="o">]]</span> ; <span class="k">then</span>
</span><span class='line'><span class="k">        </span><span class="nv">COMPREPLY</span><span class="o">=(</span> <span class="k">$(</span><span class="nb">compgen</span> -W <span class="s2">&quot;${opts}&quot;</span> -- <span class="k">${</span><span class="nv">cur</span><span class="k">})</span> <span class="o">)</span>
</span><span class='line'>        <span class="k">return </span>0
</span><span class='line'>    <span class="k">fi</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="nb">complete</span> -o default -F _arangosh arangosh
</span></code></pre></td></tr></table></div></figure>


<p>As can be seen, the variable <code>opts</code> should be filled with the list of possible
options. Determining the options for a binary can be achieved by invoking it with its
<code>--help</code> option, e.g.:</p>

<figure class='code'><figcaption><span>figuring out program options </span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>arangosh --help | grep -o <span class="s2">&quot;^\ \+--[a-z-]\+\(\.[a-z0-9-]\+\)\?&quot;</span> | xargs
</span><span class='line'>
</span><span class='line'><span class="c"># this will generate something like the following output:</span>
</span><span class='line'><span class="c"># --audit-log --chunk-size --configuration --help --no-auto-complete --no-colors --pager --pretty-print --prompt --quiet --temp-path --use-pager --javascript.check --javascript.current-module-directory --javascript.execute --javascript.execute-string --javascript.gc-interval --javascript.startup-directory --javascript.unit-tests --jslint --log.level --log.use-local-time --server.connect-timeout --server.database --server.disable-authentication --server.endpoint --server.password --server.request-timeout --server.ssl-protocol --server.username</span>
</span></code></pre></td></tr></table></div></figure>


<p>That has to be repeated for all binaries in the ArangoDB package (i.e. arangob, arangosh,
arangoimp, arangodump, arangorestore, and arangod).</p>

<p>As the available options might change over time, I wrote a script that extracts them
from the binaries and puts together the completions file. This script can be downloaded
<a href="http://jsteemann.github.io/downloads/code/build-completions.sh">here</a>. The script expects the already-built ArangoDB
binaries to be located in the <code>bin</code> subdirectory. Provided that ArangoDB was compiled from
source, this should already be the case.</p>

<p>The script should then be run from the base directory:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>build-completions.sh arangodb
</span></code></pre></td></tr></table></div></figure>


<p>This will write the completions script for all binaries into the file <code>arangodb</code>.
An already generated version for devel can be found <a href="http://jsteemann.github.io/downloads/code/completions-devel">here</a>.
Completions for 2.3 can be found <a href="http://jsteemann.github.io/downloads/code/completions-2.3">here</a>, the ones for 2.2
are <a href="http://jsteemann.github.io/downloads/code/completions-2.2">here</a>.</p>

<p>To activate completions, copy the appropriate file into <code>/etc/bash_completion.d/arangodb</code>.
Note that completion may need to be re-initialized once in order to make work:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>. /etc/bash_completion.d/arangodb
</span></code></pre></td></tr></table></div></figure>


<h2>Quick setup</h2>

<p>The following command should install the completions for 2.3 and activate them:</p>

<figure class='code'><figcaption><span>activate completions for ArangoDB 2.3 </span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo <span class="se">\</span>
</span><span class='line'>  wget -O /etc/bash_completion.d/arangodb <span class="se">\</span>
</span><span class='line'>    https://jsteemann.github.io/downloads/code/completions-2.3 <span class="o">&amp;&amp;</span> <span class="se">\</span>
</span><span class='line'>  . /etc/bash_completion.d/arangodb
</span></code></pre></td></tr></table></div></figure>


<p>The command for 2.2 is:</p>

<figure class='code'><figcaption><span>activate completions for ArangoDB 2.2 </span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo <span class="se">\</span>
</span><span class='line'>  wget -O /etc/bash_completion.d/arangodb <span class="se">\</span>
</span><span class='line'>    https://jsteemann.github.io/downloads/code/completions-2.2 <span class="o">&amp;&amp;</span> <span class="se">\</span>
</span><span class='line'>  . /etc/bash_completion.d/arangodb
</span></code></pre></td></tr></table></div></figure>


<p>To see it in action, type <code>arangosh --</code> and then press <strong>TAB</strong>.</p>

<h2>Other environments (MacOS etc.)</h2>

<p><em>Note: I have checked that the above works on Ubuntu and OpenSuSE. I have no idea whether this works
with other Linux distributions let alone other shells.</em></p>

<p>Some Linux/Unix distros do not have <code>/etc/bash_completion.d</code> at all. I was told MacOS is one
of them. For such environments, downloading and sourcing the completions script should work:</p>

<figure class='code'><figcaption><span>activate completion without bash_completion.d</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>wget -O ~/arangodb-completions-2.3 <span class="se">\</span>
</span><span class='line'>    https://jsteemann.github.io/downloads/code/completions-2.3
</span><span class='line'>. ~/arangodb-completions-2.3
</span></code></pre></td></tr></table></div></figure>


<p>This will enable the completions in the current shell. To enable them permanently, add the
completions script to your <code>.bashrc</code> file:</p>

<figure class='code'><figcaption><span>adding completions to .bashrc</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">echo</span> <span class="s2">&quot;. ~/arangodb-completions-2.3&quot;</span> &gt;&gt; ~/.bashrc
</span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Travis CI for a C++11 Project]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/17/using-travis-ci-for-a-c-plus-plus-11-project/"/>
    <updated>2014-10-17T19:36:57+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/17/using-travis-ci-for-a-c-plus-plus-11-project</id>
    <content type="html"><![CDATA[<p><a href="http://travis-ci.com">TravisCI</a> is a very useful cloud service
for continous integration. It can be integrated with Github, with each
commit triggering a new build and reporting back when it broke something.</p>

<p>Travis has support for many programming languages, among them C++.
But it lacks support for C++11 features.</p>

<!-- more -->


<p>Travis provides basic support for C++ projects. <a href="http://docs.travis-ci.com/user/languages/cpp/">It comes with gcc, clang,
the autotools, make, cmake and scons</a>.</p>

<p>While writing this post, Travis CI build machines run on Ubuntu 12.04
LTS 64 bit. This version of Ubuntu is rather old already, and does not bring
too many packages for C++11 development. For example, the default
C++ compiler installed on TravisCI is g++-4.6.3. This version
doesn&rsquo;t even understand the compile option <code>-std=c++11</code>.</p>

<p>Official C++11 support <a href="https://gcc.gnu.org/projects/cxx0x.html">started in g++ 4.7</a>,
though C++0x features were supported way earlier. But to get decent C++11 support
in g++, it is best to use g++4.8 or higher.</p>

<p>Fortunately TravisCI allows installing other software. To get
a more recent C++ compiler, it can simply be added from a PPA.
This can be achieved by putting the PPA in the <code>.travis.yml</code> file of your
Github repository, e.g.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">language</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">cpp</span>
</span><span class='line'><span class="l-Scalar-Plain">compiler</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">g++</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">before_install</span><span class="p-Indicator">:</span>
</span><span class='line'><span class="p-Indicator">-</span> <span class="l-Scalar-Plain">sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test</span>
</span><span class='line'><span class="p-Indicator">-</span> <span class="l-Scalar-Plain">sudo apt-get update -qq</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">install</span><span class="p-Indicator">:</span>
</span><span class='line'><span class="p-Indicator">-</span> <span class="l-Scalar-Plain">sudo apt-get install -qq g++-4.8</span>
</span><span class='line'><span class="p-Indicator">-</span> <span class="l-Scalar-Plain">export CXX=&quot;g++-4.8&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>I have set up an <a href="https://github.com/jsteemann/travis-cxx11">example project on Github</a>
that demonstrates how to use it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Compile ArangoDB From Source]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/16/how-to-compile-arangodb-from-source/"/>
    <updated>2014-10-16T22:24:48+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/16/how-to-compile-arangodb-from-source</id>
    <content type="html"><![CDATA[<p>Though we provide a lot of pre-built packages for the stable
versions of ArangoDB <a href="https://www.arangodb.org/install">here</a>, it
is often more interesting to play with the bleeding edge development
version. New ArangoDB features are normally added to the <em>devel</em>
branch, where they can be tested, documented and improved. When a
feature matures, it is either backported to a stable branch or will
eventually be released when the next stable branch is forked from
<em>devel</em>.</p>

<p>Contributing to the core of ArangoDB is also much easier with a
ready-to-go <em>devel</em> version. This post explains how to set one up
from scratch.</p>

<!-- more -->


<p>The following instructions are for Ubuntu 14.04 LTS, which seems to
be quite popular at the moment. Other flavors of Linux are probably
quite similar, though package manager and packages names will likely
be somewhat different.</p>

<h2>Using Vagrant</h2>

<p>If you don&rsquo;t have an Ubuntu 14 installation yet, you can easily
install one using <a href="http://www.vagrantup.com">Vagrant</a>. If you happen
to have a Linux installation already and are familiar with it, just
skip this section.</p>

<p>After installing Vagrant on your system, pick a suitable Vagrant box from
<a href="http://www.vagrantbox.es">here</a>. For example, I picked this 32 bit
box from the list:</p>

<pre><code>vagrant box add ubuntu-14.04-32 https://cloud-images.ubuntu.com/vagrant/trusty/current/trusty-server-cloudimg-i386-vagrant-disk1.box
</code></pre>

<p>After downloading the box, it can be made available via these commands:</p>

<pre><code>mkdir temp
cd temp
vagrant init ubuntu-14.04-32
vagrant up
</code></pre>

<p>After the VM is booted, connect to it via SSH:</p>

<pre><code>vagrant ssh
</code></pre>

<h2>Cloning the repository</h2>

<p>You&rsquo;re now on the Ubuntu VM. Next step is fetch the ArangoDB source
code from Github. Cloning the repository from there requires <code>git</code>. Let&rsquo;s
install it and clone the <em>devel</em> branch of the repository into a
directory named <em>devel</em> on the VM:</p>

<pre><code>sudo apt-get install git 
git clone -b devel https://github.com/triAGENS/ArangoDB.git
</code></pre>

<p>The repository contains a lot of history so cloning may take a while.
In case you don&rsquo;t need the full history, you can create a shallow
clone like this:</p>

<pre><code>git clone -b devel --single-branch --depth 1 https://github.com/triAGENS/ArangoDB.git 
</code></pre>

<p>This will reduce the download size from (currently) 375 MB to 56 MB
and should be much faster. The downside of using a shallow copy is
that there is no history and pushing and merging won&rsquo;t work most of
the time. So it&rsquo;s better used for throw-away tests only.</p>

<h2>Installing build tools and libraries</h2>

<p>Now that the repository has been cloned into directory <em>ArangoDB</em>,
we can install the required tools and libraries we need to build
from source:</p>

<pre><code>sudo apt-get install automake g++ libssl-dev libreadline-dev
</code></pre>

<p>If you prefer to install a different C++ compiler, please make sure it
has proper support for C++11.</p>

<p>Go 1.2 is also required. The official list of downloadable Go
versions can be found <a href="https://golang.org/dl/">here</a>. In the example,
I am using the 32 bit version in this example:</p>

<pre><code>wget https://storage.googleapis.com/golang/go1.2.2.linux-386.tar.gz
sudo tar -C /usr/local -xzf go1.2.2.linux-386.tar.gz
export PATH=$PATH:/usr/local/go/bin
echo "export PATH=\$PATH:/usr/local/go/bin" &gt;&gt; $HOME/.profile
</code></pre>

<h2>Compiling ArangoDB</h2>

<p>With all prerequisites set up, it&rsquo;s now time to compile ArangoDB.</p>

<p>You probably noticed that no <code>configure</code> file is shipped with ArangoDB
in the <code>devel</code> branch. To create it, we need to execute <code>make setup</code>
once. After that, <code>configure</code> can be executed to create the <code>Makefile</code>.
The <code>Makefile</code> finally contains the stuff that <code>make</code> needs:</p>

<pre><code>make setup
./configure --enable-all-in-one-icu --enable-all-in-one-v8 --enable-relative 
make
</code></pre>

<p>There first <code>make</code> run will take a while as it will compile all support
libraries (ICU, V8, libev, zlib) before it will actually compile ArangoDB.
Further invocations of <code>make</code> will not build these libraries again.
Only any changed code will be rebuilt.</p>

<p>Note that <code>make</code> can be parallelized if you have multiple processors
available. For 4 parallel <code>make</code> processes, use <code>make -j4</code>.</p>

<p><code>make</code> will produce a lot of output. The most important information, whether
or not an error occurred, can be found in its last line of its output. If
it does <strong>not</strong> say something like this, <code>make</code> has probably succeeded:</p>

<pre><code>make: *** [all] Error 2
</code></pre>

<h2>Starting ArangoDB</h2>

<p>When finished, <code>make</code> should have created all binaries in the <code>bin</code>
subdirectory. We can now start <code>arangod</code> and the binaries directly from
there without running a <code>make install</code>. In fact, <code>make install</code> is
awkward to do if you do many change-compile-test cycles.</p>

<pre><code>mkdir data          # creates a data directory
bin/arangod data    # starts the server
</code></pre>

<p>The server will be started as a foreground process (which is ideal
when developing the server). To stop the server, simply press CTRL-C.</p>

<h2>Connecting to ArangoDB</h2>

<p>To verify ArangoDB is actually working, open a separate terminal and
connect to it with the ArangoShell.</p>

<p>Note that if you used Vagrant, you will first need to connect to the
Vagrant box in the other terminal using <code>vagrant ssh</code> from the directory
you ran the <code>vagrant init</code> in. When connect to the Vagrant box, don&rsquo;t
forget to switch into the <code>ArangoDB</code> directory.</p>

<p>Once you&rsquo;re in the correct directory, just issue this:</p>

<pre><code>bin/arangosh
</code></pre>

<p>This should bring up the ArangoShell connected to your devel ArangoDB
instance.</p>

<h2>Making changes</h2>

<p>Time to make some changes in the code. A good place to start is usually
<code>main</code>. Here are a few places to get you started:</p>

<pre><code>~/ArangoDB$ grep -r "int main" arangod/ arangosh/
arangod/RestServer/arango.cpp:int main (int argc, char* argv[]) {
arangosh/Benchmark/arangob.cpp:int main (int argc, char* argv[]) {
arangosh/V8Client/arangorestore.cpp:int main (int argc, char* argv[]) {
arangosh/V8Client/arangodump.cpp:int main (int argc, char* argv[]) {
arangosh/V8Client/arangoimp.cpp:int main (int argc, char* argv[]) {
arangosh/V8Client/arangosh.cpp:int main (int argc, char* argv[]) {
</code></pre>

<p>Once you&rsquo;re done with your changes, you need to re-compile and run:</p>

<pre><code>make
bin/arangod data
</code></pre>

<p>Don&rsquo;t worry, <code>make</code> will only recompile what you changed plus what
depends on it and finally link it all together. This won&rsquo;t take as long
as on the previous run.</p>

<p>If you are serious about contributing to the server code, please let us
know <a href="https://groups.google.com/forum/#!forum/arangodb">here</a> so we can assist you.</p>

<h2>Getting updates</h2>

<p>We keep developing ArangoDB! To keep up to date and retrieve the latest
changes from our repository, issue the following commands:</p>

<pre><code>git pull origin devel
make
</code></pre>

<p>If <code>make</code> complains about files not found etc., the <code>Makefile</code> may have
changed. Then it&rsquo;s time for a full rebuild:</p>

<pre><code>make clean
make setup
./configure --enable-all-in-one-icu --enable-all-in-one-v8 --enable-relative 
make
</code></pre>

<p>Sometimes <code>make clean</code> isn&rsquo;t enough. <code>make</code> creates cache files for the
object files, and if they are too outdated, it will complain about files which
have been renamed already etc. In this case, you can forcefully delete its
caches by running an additional</p>

<pre><code>make superclean
</code></pre>

<p>By the way, if you used special configure options and forgot them, you
can retrieve your previous options by typing <code>head config.log</code>.</p>

<p>Enjoy!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Handling Binary Data in Foxx]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/15/handling-binary-data-in-foxx/"/>
    <updated>2014-10-15T20:41:30+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/15/handling-binary-data-in-foxx</id>
    <content type="html"><![CDATA[<p>Handling binary data in JavaScript applications is a bit
tricky because JavaScript does not provide a data type for
binary data. This post explains how to use binary data in
JavaScript actions written using ArangoDB&rsquo;s <a href="http://docs.arangodb.org/Foxx/README.html">Foxx</a>.</p>

<!-- more -->


<h1>Strings vs. binary data</h1>

<p>Internally, JavaScript strings are <a href="http://ecma-international.org/ecma-262/5.1/#sec-4.3.16">sequences of 16 bit integer values</a>.
Furthermore, the ECMAScript standard requires that a JavaScript
implementation should interpret characters in conformance with the
Unicode standard, using either UCS-2 or UTF-16 encoding.</p>

<p>While this is fine for handling natural language, it becomes problematic
when trying to work with arbitrary binary data. Binary data cannot be
used safely in a JavaScript string because it may not be valid UTF-16
data.</p>

<p>To make it work anyway, binary data needs to be stored in a wrapper
object. I won&rsquo;t go into details about ES6 typed arrays here, but will
focus on <code>Buffer</code> objects.</p>

<h1>Binary data in Foxx actions</h1>

<p>A Foxx route that shall handle HTTP POST requests containing arbitrary
(binary) body in the request body should not use <code>req.body()</code>. The
reason is that <code>req.body()</code> will return the body as a JavaScript string,
and this isn&rsquo;t going to work with arbitrary binary data.</p>

<p>Instead, the <code>req.rawBodyBuffer()</code> should be used. This will return the
request body inside a buffer.
Here&rsquo;s an example that stores the received data in a file on the server:</p>

<figure class='code'><figcaption><span>Foxx action that can handle binary input</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">controller</span><span class="p">.</span><span class="nx">post</span><span class="p">(</span><span class="s1">&#39;/receive-binary&#39;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">req</span><span class="p">,</span> <span class="nx">res</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="c1">// fetch request body into the buffer</span>
</span><span class='line'>  <span class="kd">var</span> <span class="nx">body</span> <span class="o">=</span> <span class="nx">req</span><span class="p">.</span><span class="nx">rawBodyBuffer</span><span class="p">();</span>
</span><span class='line'>  <span class="c1">// create an absolute filename, local to the Foxx application directory</span>
</span><span class='line'>  <span class="kd">var</span> <span class="nx">filename</span> <span class="o">=</span> <span class="nx">applicationContext</span><span class="p">.</span><span class="nx">foxxFilename</span><span class="p">(</span><span class="s2">&quot;body&quot;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>  <span class="nx">require</span><span class="p">(</span><span class="s2">&quot;fs&quot;</span><span class="p">).</span><span class="nx">write</span><span class="p">(</span><span class="nx">filename</span><span class="p">,</span> <span class="nx">body</span><span class="p">);</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>This action can be invoked as follows if the app is mounted with name <code>app</code>:</p>

<pre><code>curl -X POST http://localhost:8529/app/receive-binary --data-binary @filename
</code></pre>

<p>This will send the contents of the file <code>filename</code> to the server. The Foxx
action will then store the received data as is in a file name <code>body</code> in the
application directory.</p>

<p>Returning binary data from a Foxx action is simple, too. Here&rsquo;s a way that
returns the contents of the file named <code>body</code> in the application&rsquo;s directory:</p>

<figure class='code'><figcaption><span>Foxx action that returns contents of a file</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">controller</span><span class="p">.</span><span class="nx">get</span><span class="p">(</span><span class="s1">&#39;/provide-binary-file&#39;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">req</span><span class="p">,</span> <span class="nx">res</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="c1">// create an absolute filename, local to the Foxx application directory</span>
</span><span class='line'>  <span class="kd">var</span> <span class="nx">filename</span> <span class="o">=</span> <span class="nx">applicationContext</span><span class="p">.</span><span class="nx">foxxFilename</span><span class="p">(</span><span class="s2">&quot;body&quot;</span><span class="p">);</span>
</span><span class='line'>  <span class="c1">// send the contents, this will also set mime type &quot;application/octet-stream&quot;</span>
</span><span class='line'>  <span class="nx">res</span><span class="p">.</span><span class="nx">sendFile</span><span class="p">(</span><span class="nx">filename</span><span class="p">);</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>It is also possible to return data from an arbitrary buffer:</p>

<figure class='code'><figcaption><span>Foxx action that returns data in a buffer </span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">controller</span><span class="p">.</span><span class="nx">get</span><span class="p">(</span><span class="s1">&#39;/provide-binary-buffer&#39;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">req</span><span class="p">,</span> <span class="nx">res</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="c1">// create an absolute filename, local to the Foxx application directory</span>
</span><span class='line'>  <span class="kd">var</span> <span class="nx">filename</span> <span class="o">=</span> <span class="nx">applicationContext</span><span class="p">.</span><span class="nx">foxxFilename</span><span class="p">(</span><span class="s2">&quot;body&quot;</span><span class="p">);</span>
</span><span class='line'>  <span class="c1">// read the file content into a buffer</span>
</span><span class='line'>  <span class="kd">var</span> <span class="nx">fileContent</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s2">&quot;fs&quot;</span><span class="p">).</span><span class="nx">readBuffer</span><span class="p">(</span><span class="nx">filename</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// TODO: modify the contents of buffer here...</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// send the contents, this will also set mime type &quot;application/octet-stream&quot;</span>
</span><span class='line'>  <span class="nx">res</span><span class="p">.</span><span class="nx">send</span><span class="p">(</span><span class="nx">fileContent</span><span class="p">);</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<h1>Example application</h1>

<p>I quickly put together an example application that shows how to handle arbitrary
binary data in Foxx actions. The example app allows uploading files to the server.
The server will then list these files and allows downloading them again.</p>

<p>The application has no CSS at all. Its only purpose is to demo the server-side code.
The application can be downloaded <a href="http://jsteemann.github.io/downloads/code/filelist-app.tar.gz">here</a>.</p>

<p>Please note that the example application requires ArangoDB 2.3, which is currently
in development.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Understanding Where Operations Are Executed]]></title>
    <link href="http://jsteemann.github.io/blog/2014/08/30/understanding-where-operations-are-executed/"/>
    <updated>2014-08-30T22:38:42+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/08/30/understanding-where-operations-are-executed</id>
    <content type="html"><![CDATA[<p>I recently had to deal with some data processing operation that took
about 20 minutes to complete. When looking into this, I found that the
easiest and most beneficial change to the whole setup was to make the
operation a <em>server-side</em> operation instead of executing it <em>client-side</em>.</p>

<p>This change reduced the operation&rsquo;s total execution time to a few seconds.</p>

<!-- more -->


<p>I can&rsquo;t show the original processing task here, so I&rsquo;ll start with a
contrived example. Imagine the following <em>for</em> loop inserting 100K documents
into a collection named <code>test</code>:</p>

<figure class='code'><figcaption><span>inserting 100k documents</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="k">for</span> <span class="p">(</span><span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">;</span> <span class="o">++</span><span class="nx">i</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">db</span><span class="p">.</span><span class="nx">test</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">value</span><span class="o">:</span> <span class="nx">i</span> <span class="p">});</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now we only need a client application to execute the operation. As I don&rsquo;t
have a presentable client application right now, I will use the ArangoShell as
my client application.</p>

<h2>What&rsquo;s in a for loop?</h2>

<p>Running the above <em>for</em> loop inside the ArangoShell will lead to the loop being
executed inside the <em>arangosh</em> process.</p>

<p>In order to save a document in the collection, arangosh (our client) must make a
call to the ArangoDB server. This means issuing an HTTP POST request
to the server&rsquo;s REST API at <code>/_api/document/?collection=test</code>.
The server process will receive this request, insert the document, and
respond with an HTTP status code 201 or 202 to our client.
The client will then continue the loop until all documents have been inserted.</p>

<p>Now it&rsquo;s easy to see that the simple 3-line loop will issue 100,000 HTTP requests
in total. This means lots of data being pushed through the network stack(s).
It is pretty easy to imagine that this will come at a cost.</p>

<p>If we instead execute the above loop directly inside the ArangoDB server, we
can get rid of all the network overhead. The server has no need to send HTTP
calls to itself. It can simply execute the 100K inserts and is then done.
We therefore assume the loop to run somewhat faster when executed server-side.</p>

<p>A quick test on a crap laptop produced the following execution times for running
the loops:</p>

<ul>
<li>server-side execution (arangod): 1.34 seconds</li>
<li>client-side execution (arangosh): 17.32 seconds</li>
</ul>


<p><strong>Ouch</strong>. It looks like the client-server request-response overhead matters.</p>

<p>The following sections deal with how to get rid of some or even all the
client-server ping pong.</p>

<h2>Graph traversals</h2>

<p>The above <em>for</em> loop example was contrived, but imagine running
a client-side graph traversal instead. In fact, the original problem mentioned
in the introduction has been a graph traversal.</p>

<p>The problem of a graph traversal is that is often iterative and highly
dynamic. Decisions are made during the traversal as nodes are encountered,
leading to dynamic inclusion or exclusion etc. This means that it makes sense to
process nodes and edges only when needed, at the point when they are visited.</p>

<p>Even if the client can employ some sort of caching for already visited
nodes, the client still needs to ask the server about each visited
node&rsquo;s connections at least once. Otherwise it could not follow them.</p>

<p>This normally means lots of requests and responses. Compare this to the
<em>single</em> request-response alternative in which a client kicks off a server-side
traversal, and finally receives the overal result once it is assembled.</p>

<p><strong>Conclusion</strong>: traversals on anything but very small graphs should be run server-side.
A server-side action (see below) is a good way to do this. Please note that
running a server-side traversal does not mean giving up flexibility and
control flow functionality. Server-side traversals remain highly configurable
through custom JavaScript functions that allow implementation of user-defined
business logic.</p>

<h2>AQL queries</h2>

<p>We won&rsquo;t have your application send a series of 100,000 individual
insert statements to the relational database of our choice. We already
know from the past that this is going to be rather slow, so we have
learned to avoid this. In the relational context, we rather use SQL queries
that create or modify many rows in one go, e.g. an <code>INSERT INTO ... SELECT ...</code>,
bulk inserts etc.</p>

<p>ArangoDB is no different. In general, you should try to avoid issuing lots
of individual queries to the database from a client application. Instead and if
the queries look alike, try converting multiple individual operations into a
single AQL query. This will already save a lot of network overhead.</p>

<p>AQL provides multi-document operations to insert, update, and remove data. An
overview is given <a href="http://docs.arangodb.org/Aql/DataModification.html">here</a>.</p>

<p>The above 100K inserts from the contrived example can easily be transformed
into this single AQL query:</p>

<figure class='code'><figcaption><span>inserting 100k documents</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">FOR</span> <span class="nx">i</span> <span class="nx">IN</span> <span class="mi">1</span><span class="p">..</span><span class="mi">100000</span> <span class="nx">INSERT</span> <span class="p">{</span> <span class="nx">value</span><span class="o">:</span> <span class="nx">i</span> <span class="p">}</span> <span class="nx">INTO</span> <span class="nx">test</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Bulk imports</h2>

<p>For importing larger amounts of documents from files, there is the specialized
<a href="http://docs.arangodb.org/Arangoimp/README.html">arangoimp</a> import tool. It can
load data from JSON and CSV files into ArangoDB. The tool is shipped with
ArangoDB.</p>

<p>ArangoDB also provides a REST API for <a href="http://docs.arangodb.org/HttpBulkImports/README.html">bulk imports</a>
of documents.</p>

<h2>Joins</h2>

<p>A special note about <em>joins</em>: the fact that several NoSQL databases do not
provide join functionality has driven some people to emulate join functionality
on the client-side, in their applications.</p>

<p>This can be a recipe for disaster: client-side join implementation might lead
to horrendous amounts of queries that might need to be sent to the database for
fetching all the records. More than that, if data are queried individually,
the overall result may lack consistency. By the way, the same is true for
fetching referenced or linked documents.</p>

<p>ArangoDB provides join functionality via AQL queries. Additionally, AQL queries
can be used to fetch other documents with the original documents. Note that
ArangoDB has no way of defining references or links between documents, but
still AQL allows combining arbitrary documents in one query.</p>

<p>In almost all cases it make more sense to use an AQL query that performs
joins or reference-fetching server-side and close to the data than having to
deal with that on the application-side of things.</p>

<p>AQL joins are described <a href="http://docs.arangodb.org/AqlExamples/Join.html">here</a>.</p>

<h2>Server-side actions</h2>

<p>With <em>stored procedures</em>, relational databases provide another way for an
application to trigger the execution of a large amount of queries. Stored
procedures are executed server-side, too, so they allow avoiding a lot of
request-response ping pong between the application and the database, at least
for defined tasks. Additionally, stored procedures provide control flow
functionality, which can also be handy when operations depend on each other.</p>

<p>Coming back to ArangoDB: complex data-processing tasks that need to execute
multiple operations or need control flow functionality might benefit if
converted from multiple application-side operations into a single server-side
action.</p>

<p>Server-side actions run inside the ArangoDB server, closer to the data, and
can be much faster than a series of client-side operations.
A server-side action is called with just one HTTP request from the application,
so it may lead to saving lots of request-response cycles and reduction in
network overhead. Apart from that, server-side actions in ArangoDB can employ
transactions and provide the necessary control over isolation and atomicity
when executing a series of operations.</p>

<p>Business logic and control flow functionality can be integrated
easily because server-side actions in ArangoDB are JavaScript functions,
with all of the language&rsquo;s programming features being available.</p>

<p>But there&rsquo;s even more to it: a single server-side operation can be written
to put together its result in a format most convenient for the client
application. This can also lead to better encapsulation, because all an
application needs to know about a server-side action is its API or contract.
Any internals of the action can be hidden from the client application. Overall,
this supports a service-oriented approach.</p>

<p>To learn more about how to write server-side actions, please have a look
at ArangoDB&rsquo;s <a href="http://docs.arangodb.org/Foxx/README.html">Foxx</a>. It is all
about making server-side actions available via REST APIs.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Speeding Up Server-side Operations]]></title>
    <link href="http://jsteemann.github.io/blog/2014/08/20/speeding-up-server-side-operations/"/>
    <updated>2014-08-20T22:02:09+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/08/20/speeding-up-server-side-operations</id>
    <content type="html"><![CDATA[<p>Sometimes it is easier to make server-side operations run a bit faster.
In the following post I&rsquo;ll show a few low-level optimizations that can
be applied to user-defined JavaScript code that is executed inside the
ArangoDB server.</p>

<!-- more -->


<h1>Scope</h1>

<p>Some data-access operations can be sped up by using the appropriate indexes,
but that&rsquo;s not what I am going to show here.
Instead, I want to demo a few easy optimizations that don&rsquo;t require any
changes to the data. Only JavaScript code needs to be minimally adjusted
to use them.</p>

<p>Note that I am not talking about code that is executed in the ArangoShell
here. I will only be looking at code that is executed inside the arangod
server instance. The natural places for using custom JavaScript code in
the ArangoDB server are for example:</p>

<ul>
<li><a href="http://docs.arangodb.org/Foxx/README.html">Foxx</a> controllers</li>
<li><a href="http://docs.arangodb.org/Transactions/TransactionInvocation.html">transactions</a></li>
<li><a href="http://docs.arangodb.org/ModuleTasks/README.html">tasks</a></li>
<li><a href="http://docs.arangodb.org/Traversals/README.html">traversals</a></li>
</ul>


<p>Of course it does not make much sense to optimize operations that are not
called very often. The code changes I show will only be useful for server-side
operations that are called very often, for example, from within loops or
from batch processing actions.</p>

<p>Before starting to change any code, please make sure that the code is executed
often and that it accounts for a significant part of the total execution time.</p>

<h2>Baseline</h2>

<p>Imagine the following custom JavaScript code running somewhere inside ArangoDB:</p>

<figure class='code'><figcaption><span>baseline</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">;</span> <span class="o">++</span><span class="nx">i</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">db</span><span class="p">.</span><span class="nx">test</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">value</span><span class="o">:</span> <span class="mi">1</span> <span class="p">});</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>This code inserts 100,000 documents into a collection <code>test</code>. Each document has
one attribute only. These numbers are arbitrary, but good enough for a demo.</p>

<p>What can we do to improve the runtime of the above code?</p>

<h2>Non-optimizations</h2>

<p>The <em>for</em> statement itself is not worth optimizing. It won&rsquo;t matter much if we used
pre-increment or post-increment for the loop induction variable <code>i</code> or if we
turned the <em>for</em> loop into a <em>while</em> loop. Any changes here might only save us a
few nanoseconds in total, but are likely to make the code more unreadable.</p>

<p>Let&rsquo;s not do that!</p>

<h2>Avoiding accessors</h2>

<p>Clearly, we should be looking at the <code>save</code> operation.</p>

<p><code>db.test.save()</code> looks like a function call, and we learned that function are
expensive. In this case, we cannot avoid the function call to <code>save()</code>, but we
can avoid another <em>hidden function call</em>. Yes, <code>db.test</code> actually calls a function,
though it does not look like it does.</p>

<p>The <code>db</code> object has auto-magic member attributes. The <code>db</code> object will have a
member attribute for existing collection. The member will automatically vanish when
a collection gets dropped, and the member will rename itself when collections are
renamed.</p>

<p>This magic is made possible by late-binding attributes and using accessor functions
for attribute accesses on the <code>db</code> object: whenever the attributes of the <code>db</code> object
are queried, an accessor function (<em>property query</em>) is called internally to compile
them. Accessing a specific attribute of the <code>db</code> object will also call an accessor
function (<em>property get</em>). This is exactly what happens in our case when we access
<code>db.test</code>.</p>

<p>If this was too complicated, it may become more obvious if we modified the original
code to this:</p>

<figure class='code'><figcaption><span>using attribute lookup</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">;</span> <span class="o">++</span><span class="nx">i</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">db</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">].</span><span class="nx">save</span><span class="p">({</span> <span class="nx">value</span><span class="o">:</span> <span class="mi">1</span> <span class="p">});</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now it should be obvious that accessing <code>test</code> requires an attribute lookup on the
<code>db</code> object, and behind the scenes the same will happen if we had written <code>db.test</code>
instead.</p>

<p>Let&rsquo;s avoid the repeated call to the accessor function inside the loop! This can
easily be achieved by assigning <code>db.test</code> to a variable once and forever outside
of the loop. This technique is called loop-invariant code motion, and it can be
applied in a lot of other situations, too:</p>

<figure class='code'><figcaption><span>loop-invariant code motion</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="kd">var</span> <span class="nx">collection</span> <span class="o">=</span> <span class="nx">db</span><span class="p">.</span><span class="nx">test</span><span class="p">;</span>
</span><span class='line'><span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">;</span> <span class="o">++</span><span class="nx">i</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">collection</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">value</span><span class="o">:</span> <span class="mi">1</span> <span class="p">});</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>(on a side note: you cannot assign <code>db.test.save</code> to a variable and call it as a
function)</p>

<h2>Enjoying the silence</h2>

<p>The <code>save</code> operation is chatty. Every time it is called, it will return some meta
data from the just-inserted document, e.g.:</p>

<figure class='code'><figcaption><span>save result</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="s2">&quot;test/11443981931568&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;_rev&quot;</span> <span class="p">:</span> <span class="s2">&quot;11443981931568&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;_key&quot;</span> <span class="p">:</span> <span class="s2">&quot;11443981931568&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>In our case, we&rsquo;re not interested in these returned values, and we don&rsquo;t
capture them in a variable.
The <code>save</code> function doesn&rsquo;t know this and will happily assemble its
result array. The array consists of three string values (six when also counting
attribute names). Setting up the result definitely requires costly
memory allocations and string copying.</p>

<p>We can avoid all this by passing an <em>options</em> parameter into <code>save</code>, and setting
its <code>silent</code> attribute to <code>true</code>:</p>

<figure class='code'><figcaption><span>silence option</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">;</span> <span class="o">++</span><span class="nx">i</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">db</span><span class="p">.</span><span class="nx">test</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">value</span><span class="o">:</span> <span class="mi">1</span> <span class="p">},</span> <span class="p">{</span> <span class="nx">silent</span><span class="o">:</span> <span class="kc">true</span> <span class="p">});</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now <code>save()</code> will only return a boolean value, which is much quicker.</p>

<h2>Transactions</h2>

<p>Yet another alternative is use to wrap the operations in the loop into a
transaction. Transaction themselves won&rsquo;t buy us much feature-wise, so why use
them? The reason is simple: if we do not use a transaction ourselves, each
<code>save</code> operation will implicitly be executed in a transaction of its own.
For a loop with 100,000 operations, that will be 100K transactions!</p>

<p>So when we put all the operations into a single, now explicit transaction,
we can save the overhead of 99,999 transaction begin and commit operations.
Here&rsquo;s how to do it:</p>

<figure class='code'><figcaption><span>transaction</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">_executeTransaction</span><span class="p">({</span>
</span><span class='line'>  <span class="nx">collections</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">write</span><span class="o">:</span> <span class="s2">&quot;test&quot;</span>
</span><span class='line'>  <span class="p">},</span>
</span><span class='line'>  <span class="nx">action</span><span class="o">:</span> <span class="kd">function</span> <span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">;</span> <span class="o">++</span><span class="nx">i</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>      <span class="nx">db</span><span class="p">.</span><span class="nx">test</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">value</span><span class="o">:</span> <span class="mi">1</span> <span class="p">});</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<h1>Results</h1>

<p>How far have we got with these minimal code adjustments?</p>

<p>I have put together a <a href="http://jsteemann.github.io/downloads/code/speeding-up-server.js">script</a>
that can be run in arangod. The script will run each version of the loop
10 times and time the execution. The minimum, maximum and
average execution times are printed (in seconds, less is better). Note that
the absolute times do not matter much here. Please have a look at the percentage
column, which shows the execution time of each variant in comparison to the
baseline.</p>

<p>Here&rsquo;s an excerpt of the script&rsquo;s output:</p>

<figure class='code'><figcaption><span>results</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>test name      |   total (s) |     min (s) |     max (s) |    avg2 (s) |       %
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>baseline       |     13.0940 |      1.2907 |      1.3357 |      1.3084 |  100.00
</span><span class='line'>loop-invariant |     10.6888 |      1.0506 |      1.1042 |      1.0667 |   81.53
</span><span class='line'>silence        |     11.7186 |      1.1512 |      1.2247 |      1.1678 |   89.25
</span><span class='line'>transaction    |     10.1521 |      0.9987 |      1.0346 |      1.0149 |   77.56
</span><span class='line'>combined       |      7.8545 |      0.7768 |      0.7977 |      0.7850 |   59.99
</span></code></pre></td></tr></table></div></figure>


<p>As can be seen, moving the loop-invariant accessor function call outside of the
loop provided an almost 20% speedup (from 1.30 to 1.06 s). Using the silence
option did also provide some, but not the same speedup. Using transactions reduced
the execution time, and by putting all this together, a reduction of about 40 %
was achieved.</p>

<p>Your mileage may vary. Please feel free to adjust the test script and run your
own tests.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why JSON?]]></title>
    <link href="http://jsteemann.github.io/blog/2014/08/14/why-json/"/>
    <updated>2014-08-14T22:27:27+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/08/14/why-json</id>
    <content type="html"><![CDATA[<h1>To JSON or not?</h1>

<p>We&rsquo;re often asked why ArangoDB uses <a href="http://json.org">JSON</a> as its
data-interchange format for transferring documents from clients to
the database server and back. This is often accompanied by the
question if we could use <code>&lt;insert fancy format here&gt;</code> instead.</p>

<p>In the following article, I&rsquo;ll try to outline the reasons for why
we picked JSON as the interchange format, and why we still use it.</p>

<p>I&rsquo;ll start with a discussion of the pros and cons of JSON, look at
some alternative formats and present my personal opinion on why
using a different format may not provide too much benefit for us,
at least at the moment.</p>

<!-- more -->


<p>This post does not intend to say that any of these formats are better
or worse in general. I think there are applications for all of them.</p>

<p>However, I wanted to look at the different formats with our specific
use case, i.e. a RESTful database, in mind.</p>

<h1>What I don&rsquo;t like about JSON</h1>

<p>JSON is often criticized for its inefficiency and lack of <strong>real</strong>
data types. I&rsquo;ll often criticize it myself.</p>

<p>Following are my personal top 3 pain points.</p>

<h2>Parsing and memory allocation</h2>

<p>I have to admit that parsing JSON is painful from the efficiency
perspective. When the JSON parser encounters a <code>{</code> token,
it will know this is the start of an object, but it has no idea how
many object members will follow and need to be stored with the
object. The same is true for lists (starting with <code>[</code>).</p>

<p>String values are no different: when the parser encounters a <code>"</code>,
the length of the string is still unknown. To determine the length
of the string, one must read until the end of the string, taking
into account escape sequences for special characters, e.g. <code>\/</code>,
<code>\n</code>, <code>\t</code>, <code>\\</code>, but also Unicode escape sequences.</p>

<p>For example, the escaped 36-byte string <code>In K\u00f6ln, it's 15 \u00b0 outside</code>
will be parsed into the 28-byte UTF-8 string <code>In Kln, it's 15  outside</code>.</p>

<p>With the overall size of objects, lists or strings unknown at the
start of a token, it&rsquo;s hard to reserve the <strong>right</strong> amount of memory.
Instead, memory either needs to be allocated on the fly as JSON
tokens are parsed, or (potentially too big) chunk(s) of memory
needs to be put aside at the start of parsing. The parser can
then use this already allocated memory to store whatever is found
afterwards.</p>

<h2>Verbosity</h2>

<p>JSON data can also become very fluffy. I already mentioned that
serializing strings to JSON might incur some overhead due to escape
sequences.</p>

<p>But there&rsquo;s more things like this: each boolean value requires 4
(<code>true</code>) or 5 (<code>false</code>) bytes respectively. Repeating object member
names need to be stored repeatedly, as JSON does not provide string
interning or similar mechanisms.</p>

<h2>Data types</h2>

<p>Apart from that, the JSON type system is limited. There is only one
type to represent numbers. Different types for representing numbers
of different value ranges are (intentionally) missing. For example,
one might miss 64 bit integer data types or arbitrary precision
numbers. A date type (for calendar dates and times) is often missed, too.</p>

<p>And yes, binary data cannot be represented in JSON without converting
them into a JSON string first. This may require base64-encoding or
something similar.</p>

<p>In general, the available data types in JSON are very limited, and the
format by itself is not extensible. Extending JSON with own type information
will either create ill-formed JSON (read: <em>non-portable</em>) or would
introduce special meaning members that other programs and tools won&rsquo;t
understand (read: <em>non-portable</em>).</p>

<h1>Why still use JSON?</h1>

<p>So what are the reasons to still stick with JSON?
From my point of view, there are still a few good reasons to do so:</p>

<h2>Simplicity</h2>

<p>The <a href="http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf">JSON specification</a>
fits on five pages (including images). It is simple and intuitive.</p>

<p>Additionally, JSON-encoded data is instantly comprehensible. There is
simply no need to look up the meanings of binary magic values in format
specifications. It is also very easy to spot errors in ill-formed JSON.</p>

<p>In my eyes, looking at JSON data during a debugging session is much
easier than looking at binary data (and I do look at binary data sometimes).</p>

<h2>Flexibility</h2>

<p>JSON requires no schema to be defined for data. This is good, as it allows to
get something done earlier. Schemas also tend to change over time, and this
can become a problem with other formats that have schemas. With schema-less JSON,
a schema change becomes a no-brainer &ndash; just change the data inside the JSON
and you&rsquo;re done. No need to maintain a separate schema.</p>

<p>The schema-relaxed approach of JSON also plays quite well with languages that
are loosely typed or allow runtime modifications of data structures. Most
scripting languages are in this category.</p>

<h2>Language support</h2>

<p>JSON is supported in almost every environment. Support for JSON is
sometimes built into languages directly (JavaScript) or the languages come
with built-in serialization and deserialization functions (e.g. PHP).
Just go and use it.</p>

<p>For any other language without built-in support for JSON, it won&rsquo;t be hard to find
a robust implementation for JSON serialization/deserialization.</p>

<p>In the ArangoDB server, we use a lot of JavaScript code ourselves. Users
can also extend the server functionality with JavaScript. Guess what happens
when a JSON request is sent to the server and its payload is handed to a
JavaScript-based action handler in the server? Yes, we&rsquo;ll take the request
body and create JavaScript objects from it. This is as simple as it can be,
because we have native JSON support in JavaScript, our server-side programming
language.</p>

<p>We also encourage users to use ArangoDB as a back end for their JavaScript-based
front ends. Especially when running in a browser, using JSON as the interchange
format inside AJAX* requests makes sense. You don&rsquo;t want to load serialization/deserialization
libraries that handle binary format into front ends for various reasons.</p>

<p>Many tools, including browsers, also support inspecting JSON data or can
import or export JSON-encoded data.</p>

<p>*Pop quiz: does anyone remember what was the meaning of the &ldquo;X&rdquo; in AJAX??</p>

<h1>Alternatives</h1>

<p>As I have tried to outline above, I think JSON has both strengths and
weaknesses. Is there an alternative format that is superior? I am listing
a few candidate formats below, and try to assess them quickly.</p>

<p>One thing that they all have in common is that they are not as much supported
by programming languages and tools as JSON is at the moment. For most of the
alternative formats, you would have to install some library in the environment
of your choice. XML is already available in many environments by default, with
the notable exception of JavaScript.</p>

<p>Even if a format is well supported by most programming languages, there are
other tools that should handle the format, too.</p>

<p>If there aren&rsquo;t any tools that allow converting existing data into the format,
then this is a severe limitation. Browsers, for example, are important tools.
Most of the alternative formats cannot be inspected easily with a browser,
which makes debugging data transfers from browser-based applications hard.</p>

<p>Additionally, one should consider how much example datasets are available.
I think at the moment it&rsquo;s much more likely that you&rsquo;ll find a JSON-encoded
dump of Wikipedia somewhere on the Internet than in one of the alternative
formats.</p>

<h2>Proprietary format</h2>

<p>An alternative to using JSON would be to create and our own binary format.
We could use a protocol tailored to our needs, and make it very very
efficient. The disadvantages of using a proprietary format are
that it is nowhere supported, so writing clients for ArangoDB in
another language becomes much harder for ourselves and for third-party
contributors. Effectively, we would need to write an adapter for
our binary protocol for each environment we want to have ArangoDB
used in.</p>

<p>This sounds like it would take a lot of time and keep us from doing
other things.</p>

<h2>XML</h2>

<p>It&rsquo;s human-readable, understandable, has a good standard type system
and is extensible. But if you thought that JSON is already inefficient
and verbose, try using XML and have fun. A colleague of mine even
claimed that XML is not human-readable due to its chattyness.</p>

<p>XML also hasn&rsquo;t been adopted much in the JavaScript community, and we
need to find a format that plays nicely with JavaScript.</p>

<h2>Smile</h2>

<p>There is also the <a href="http://wiki.fasterxml.com/SmileFormat">Smile</a> format.
Its goals are to provide an efficient alternative to JSON. It looks
good, but it does not seem to be used much outside of <a href="http://wiki.fasterxml.com/JacksonHome">Jackson</a>.
As mentioned earlier, we need a format that is supported in a variety of
environments.</p>

<h2>BSON</h2>

<p>Then there is <a href="http://bsonspec.org/">BSON</a>, made popular by MongoDB.
We had a look at it. It is not as space-efficient as it could be, but
it makes memory allocation very easy and allows for fast packing and
unpacking. It is not so good when values inside the structure need to
be updated. There are BSON-libraries for several languages</p>

<p>Still, it is a binary format. Using it for communication in the ArangoDB
cases includes using it from arbitrary JavaScript programs (including
applications run in a browser), using it in AJAX calls etc. This sounds
a bit like debugging hell.</p>

<h2>Msgpack</h2>

<p><a href="http://msgpack.org/">Msgpack</a> so far looks like the most-promising
alternative. It seems to become available in more and more programming
language environments. The format also seems to be relatively efficient.</p>

<p>A major drawback is that as a binary format, it will still be hard to debug.
Tool support is also not that great yet. Using Msgpack with a browser also
sounds like fun. I&rsquo;d like if tools like Firebug could display Msgpack
packet internals.</p>

<h2>Protocol buffers</h2>

<p>Two years ago, we also experimented with <a href="https://code.google.com/p/protobuf/">Protocol buffers</a>.
Protocol buffers require to set up a schema for the data first, and
then provide efficient means to serialize data from the wire into
programming-language objects.</p>

<p>The problem is that there are no fixed schemas in a document database
like ArangoDB. Users can structure their documents as they like. Each
document can have a completely different structure.</p>

<p>We ended up defining a schema for something JSON-like inside Protocol
buffers, and it did not make much sense in our use case.</p>

<h1>Conclusion</h1>

<p>There are alternative formats out there that address some of the issues
that JSON has from my point of view. However, none of the other formats
is yet that widely supported and easy to use as JSON.</p>

<p>This may change over time.</p>

<p>For our use case, it looks like Msgpack could fit quite well, but
probably only as a second, alternative interface for highest-efficiency
data transfers.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Benchmarking ArangoDB's Write-ahead Log]]></title>
    <link href="http://jsteemann.github.io/blog/2014/08/07/benchmarking-arangodbs-write-ahead-log/"/>
    <updated>2014-08-07T01:27:04+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/08/07/benchmarking-arangodbs-write-ahead-log</id>
    <content type="html"><![CDATA[<h1>Motivation</h1>

<p>One of the major changes in ArangoDB 2.2 was the introduction of the
<em>write-ahead log</em> (abbreviated <em>WAL</em>).</p>

<p>The introduction of the WAL changed how documents are stored internally in
ArangoDB. A lot of things have been changed for it under the hood, and it has
been a lot of work to implement it.</p>

<p>During the implementation, we refactored some code parts and made them
considerably faster. From these changes we expected a positive effect on the
database performance. But due to the fact that shape information is now also
saved in the write-ahead log, there may also be some negative effect.</p>

<p>We developers were of course very interested in seeing the net effects, so
we ran some tests for a few use cases. We compared ArangoDB 2.1.2 (still without
the WAL) with ArangoDB 2.2.1 (with the WAL). The results are interesting.</p>

<!-- more -->


<h1>Test setup</h1>

<p>To get a broad overview of performance changes, we ran a few different test cases:</p>

<ul>
<li><strong>document</strong>: inserts a document</li>
<li><strong>crud</strong>: inserts a document, fetches it, updates it, and deletes it</li>
<li><strong>crud-append</strong>: inserts a document, fetches it, updates it, and fetches it again</li>
<li><strong>multi-collection</strong>: transactionally save two documents in two collections</li>
<li><strong>random-shapes</strong>: save documents with completely different structures/shapes</li>
</ul>


<p>All tests were run with the <code>arangob</code> benchmark tool, with various concurrency levels,
complexity settings and repeated several times. <code>arangob</code> was invoked like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>arangob                         \
</span><span class='line'>  --test-case $case             \
</span><span class='line'>  --request $requests           \
</span><span class='line'>  --concurrency $concurrency    \
</span><span class='line'>  --complexity $complexity</span></code></pre></td></tr></table></div></figure>


<p>Both ArangoDB servers and <code>arangob</code> were located on the same server. Only one
ArangoDB server was active during each test run, and the other was shut down so
it didn&rsquo;t compete for system resources.</p>

<h1>Test results</h1>

<p>Following are the results for the different test cases.</p>

<p>In the result tables, the columns have the following meanings:</p>

<ul>
<li><strong>Complexity</strong>: the number of attributes for the test documents, used as parameter
<code>--complexity</code> for <code>arangob</code></li>
<li><strong>Requests</strong>: the number of operations executed, used as parameter <code>--requests</code>
for <code>arangob</code></li>
<li><strong>Concurrency</strong>: the number of client threads started by <code>arangob</code>, used a parameter
<code>concurrency</code> for <code>arangob</code></li>
<li><strong>Time 2.1</strong>: test execution time (in seconds) for ArangoDB 2.1</li>
<li><strong>Time 2.2</strong>: test execution time (in seconds) for ArangoDB 2.2</li>
<li><strong>T2.1/T2.2</strong>: relative performance of ArangoDB 2.1 compared to ArangoDB 2.2. Values
less than one indicate that ArangoDB 2.1 was faster than ArangoDB 2.2. Values
greater than one indicate that ArangoDB 2.1 was slower than ArangoDB 2.2. A
value of one means that both versions had equal speed.</li>
</ul>


<p>Please note that the absolute execution times aren&rsquo;t too interesting in the
results shown here. We haven&rsquo;t used the most powerful server on earth for running
these tests. We were most interested in how ArangoDB 2.2 compared to
ArangoDB 2.1.</p>

<h2>Inserting documents</h2>

<p>The <code>document</code> test appends new documents (with an identical structure) to a
collection. Here are the results for inserting a million documents with 100
attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>       100       1000000               1       97.452       94.839         1.02    
</span><span class='line'>       100       1000000               2       61.146       53.928         1.13   
</span><span class='line'>       100       1000000               4       54.368       31.379         1.73  </span></code></pre></td></tr></table></div></figure>


<p>Following are the results for 100,000 documents with 1,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>      1000        100000               1       86.883       80.669         1.07 
</span><span class='line'>      1000        100000               2       59.381       48.599         1.22 
</span><span class='line'>      1000        100000               4       53.784       27.494         1.95 </span></code></pre></td></tr></table></div></figure>


<p>The results for 5,000 documents with 10,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>     10000          5000               1       43.991       40.577         1.08 
</span><span class='line'>     10000          5000               2       31.403       26.117         1.20 
</span><span class='line'>     10000          5000               4       28.713       20.044         1.43 </span></code></pre></td></tr></table></div></figure>


<p>As we can see in the results above, ArangoDB 2.2 is faster than ArangoDB 2.1 for
all tested configurations. The difference is negligible if the test client is
single-threaded (one insert thread), but ArangoDB 2.2 is considerably faster than
ArangoDB 2.1 with more concurrent clients.</p>

<h2>CRUD operations (I)</h2>

<p>The <code>crud</code> test case inserts a document, fetches it, updates it, fetches it again
and finally deletes it. Executing 1 million crud operations on documents with 100
attributes each results in the following execution times:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>       100       1000000               1       66.856       67.072         0.99       
</span><span class='line'>       100       1000000               2       47.907       47.043         1.01        
</span><span class='line'>       100       1000000               4       42.089       42.047         1.00         </span></code></pre></td></tr></table></div></figure>


<p>Running 100,000 crud operations on documents with 1,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>      1000        100000               1      160.228      158.312         1.01 
</span><span class='line'>      1000        100000               2      147.413      147.990         0.99  
</span><span class='line'>      1000        100000               4      143.575      143.233         1.00   </span></code></pre></td></tr></table></div></figure>


<p>And here are the test results for running 5,000 crud operations on documents with
10,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>     10000          5000               1      645.859      643.924         1.00        
</span><span class='line'>     10000          5000               2      640.414      640.767         0.99       
</span><span class='line'>     10000          5000               4      637.438      637.132         1.00      </span></code></pre></td></tr></table></div></figure>


<p>The results of all these tests show that performance for the tested workload hasn&rsquo;t
changed between ArangoDB 2.1 and 2.2. This is somewhat expected, as the WAL should
not affect the performance of read and delete operations much: reading a document
does not require writing to the WAL at all, and removing a document only requires
writing a very small remove marker to the WAL.</p>

<h2>CRUD operations (II)</h2>

<p>The <code>crud-append</code> test case inserts a document, fetches it, updates it, and fetches
it again. Executing 1 million crud operations on documents with 100 attributes each
results in the following execution times:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>       100       1000000               1       81.187       79.079         1.02 
</span><span class='line'>       100       1000000               2       59.544       56.934         1.04  
</span><span class='line'>       100       1000000               4       53.845       52.098         1.03   </span></code></pre></td></tr></table></div></figure>


<p>Running 100,000 crud operations on documents with 1,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>      1000        100000               1      200.057      196.722         1.01 
</span><span class='line'>      1000        100000               2      182.436      181.633         1.00 
</span><span class='line'>      1000        100000               4      181.233      180.631         1.00 </span></code></pre></td></tr></table></div></figure>


<p>And here are the test results for running 5,000 crud operations on documents with
10,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>     10000          5000               1      804.781      801.903         1.00 
</span><span class='line'>     10000          5000               2      796.589      797.693         0.99  
</span><span class='line'>     10000          5000               4      796.664      795.823         1.00  </span></code></pre></td></tr></table></div></figure>


<p>Again, ArangoDB 2.1 and 2.2 are pretty much the same speed for the tested operations.</p>

<h2>Multi-collection write transactions</h2>

<p>The <code>multi-collection</code> test stores two documents in two different collections
transactionally. Here are the results for executing 100,000 transactions for
documents with 100 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>       100        100000               1     6936.895       30.736       225.69   
</span><span class='line'>       100        100000               2     6946.524       25.577       271.59    
</span><span class='line'>       100        100000               4     7720.682       24.334       317.27     </span></code></pre></td></tr></table></div></figure>


<p>Executing 10,000 transactions on documents with 1,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>      1000         10000               1      949.974       21.368        44.45     
</span><span class='line'>      1000         10000               2      953.672       19.322        49.35    
</span><span class='line'>      1000         10000               4      941.645       20.486        45.96   </span></code></pre></td></tr></table></div></figure>


<p>And finally, the results for executing 500 transactions on documents with 10,000
attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>     10000           500               1       46.776       10.413         4.49 
</span><span class='line'>     10000           500               2       45.102       10.173         4.43 
</span><span class='line'>     10000           500               4       44.172        9.192         4.80  </span></code></pre></td></tr></table></div></figure>


<p>The above results show that ArangoDB 2.2 is much faster than ArangoDB 2.1 for
executing transactions that write to two collections.</p>

<p>We expected that! Multi-collection (write) transactions in ArangoDB 2.2 require
far less calls to <code>msync</code> than in ArangoDB 2.1. ArangoDB 2.2 can sync operations
of multiple transactions together in one call to <code>msync</code>. ArangoDB 2.1 needed to
synchronize each transaction separately.</p>

<h2>(Fully) heterogenous documents</h2>

<p>The <code>random-shapes</code> test inserts documents that have different structures each.
For each inserted document a new shape will need to be stored. Inserting one million
documents with 100 attributes each results in the following figures:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>       100       1000000               1      664.006       87.181         7.61        
</span><span class='line'>       100       1000000               2      433.570       60.613         7.15       
</span><span class='line'>       100       1000000               4      313.666       45.327         6.92      </span></code></pre></td></tr></table></div></figure>


<p>
The results show that ArangoDB 2.2 is considerably faster than ArangoDB 2.1 for
these cases &ndash; even with the storage overhead of writing the shapes to the WAL.</p>

<p>Now we inserted 100,000 documents with 1,000 document attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>      1000        100000              1        61.709       66.954         0.92    
</span><span class='line'>      1000        100000              2        39.294       46.458         0.84   
</span><span class='line'>      1000        100000              4        36.866       40.910         0.90  </span></code></pre></td></tr></table></div></figure>


<p>In these cases, the storage overhead of writing all shapes to the WAL seems to
start to matter, and ArangoDB 2.2 gets slower than ArangoDB 2.1 in this test
case.</p>

<p>The same was true when we inserted 5,000 documents with 10,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>     10000          5000               1       25.337       30.412         0.83    
</span><span class='line'>     10000          5000               2       20.021       22.128         0.90     
</span><span class='line'>     10000          5000               4       14.800       18.872         0.78      </span></code></pre></td></tr></table></div></figure>


<p>Note that the <code>random-shapes</code> test case is an extreme test case. We do not
consider it realistic that all documents in a collection have completely different
attribute names. Still we included it in our tests because we were sure that this
would be a case in which the overhead of the WAL would be clearly measurable.</p>

<p>Note that there is a way to make ArangoDB 2.2 faster than ArangoDB 2.1 even for
this test case: setting the option <code>--wal.suppress-shape-information</code> to <code>true</code>
will make ArangoDB not write shape information to the WAL, making document write
operations much faster in case all documents have heterogenous structures.</p>

<p>The option won&rsquo;t help much if a shapes repeat a lot. In this case, the WAL overhead
shouldn&rsquo;t matter too much already, or ArangoDB 2.2 should already be faster than 2.1
(as shown in the results above).</p>

<h1>Summary</h1>

<p>The tests revealed that the overhead of the WAL in ArangoDB 2.2 seems to be
negligible for most of the tested workloads. In many cases, ArangoDB 2.2 with
the WAL is even faster than ArangoDB 2.1 that did not have a WAL at all.</p>

<p>There is one notable exception: when documents have fully heterogenous structures,
the overhead of the WAL is measurable and significant. Though we consider this
to be a rather hypothetical case, we have added the configurtion option
<code>--wal.suppress-shape-information</code>. This can be used to turn off storing
shape information in the WAL. This is not safe when the server is to be used
as a replication master, but should work in cases when replication is not used.</p>

<p>The option should not have a big effect if documents are greatly or at least
somewhat homogenous. For these cases, ArangoDB 2.2 with its WAL should already
be as fast as 2.1 (or even faster).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How ArangoDB's Write-ahead Log Works]]></title>
    <link href="http://jsteemann.github.io/blog/2014/08/06/how-arangodbs-write-ahead-log-works/"/>
    <updated>2014-08-06T21:14:00+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/08/06/how-arangodbs-write-ahead-log-works</id>
    <content type="html"><![CDATA[<p>Since version 2.2, ArangoDB stores all data-modification operations in its
<em>write-ahead log</em> (abbreviated <em>WAL</em>). The introduction of the WAL massively
changed how data are stored in ArangoDB.</p>

<!-- more -->


<h1>What&rsquo;s in the WAL?</h1>

<p>The WAL contains data of all data-modification operations that were executed in
the ArangoDB server instance. Operations are written to the WAL in the order of
execution. The following types of operations are logged to the WAL:</p>

<ul>
<li>creating, updating, replacing or removing documents</li>
<li>creating, modifying or dropping collections and their indexes</li>
<li>creating or dropping databases</li>
</ul>


<p>The WAL is used for all databases of an ArangoDB server. Database ids are stored
in the WAL in order to tell data from different databases apart.</p>

<h1>Recovery using the WAL</h1>

<p>Should the ArangoDB server crash, it will replay its write-ahead
logs at restart. Replaying the logs will make the server recover the same
state of data as before the crash.</p>

<p>Any document-modification operations might belong to a transaction. Transaction
data are also stored in the write-ahead log, allowing the recovery of committed
transactions and preventing the recovery of aborted or unfinished transactions.</p>

<p>Let&rsquo;s assume the following operations are executed in an ArangoDB server in this
order&hellip;</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Seq#  |  Operation type       |  Transaction#  |  Context
</span><span class='line'>------+-----------------------+----------------+---------------------------------------
</span><span class='line'>   1  |  start transaction    |           773  |  database "_system"
</span><span class='line'>   2  |  insert document      |           773  |  collection "test", key "foo"
</span><span class='line'>   3  |  start transaction    |           774  |  database "_system"
</span><span class='line'>   4  |  insert document      |           774  |  collection "mycollection", key "bar"
</span><span class='line'>   5  |  start transaction    |           775  |  database "_system"
</span><span class='line'>   6  |  update document      |           775  |  collection "boom", key "test"
</span><span class='line'>   7  |  abort transaction    |           774  |  -                
</span><span class='line'>   8  |  remove document      |           773  |  collection "test", key "baz"
</span><span class='line'>   9  |  commit transaction   |           773  |  -     </span></code></pre></td></tr></table></div></figure>


<p>&hellip;and then the server goes down due to a power outage.</p>

<p>On server restart, the WAL contents will be replayed, so the server will redo the
above operations. It will find out that operations #2 and #8 belong to transaction #773.
Transaction #773 was already committed, so all of its operations must and will be
recovered.</p>

<p>Further it will find out that operation #4 belongs to transaction #774, which was
aborted by the user. Therefore, this operation will not be replayed but ignored.</p>

<p>Finally, it will find operation #6 belongs to transaction #775. For this transaction,
there is neither an abort nor a commit operation in the log. Because the transaction
was never committed, all of its operations are not replayed at restart and the server
will behave as if the transaction never happened.</p>

<h1>WAL and replication</h1>

<p>A side-effect of having a write-ahead log is that it can also be used for replication.
When a slave server fetches the latest changes from the master, the master can simply
read the operations from its WAL. Data in the WAL are self-contained, meaning the
master can efficiently compile the list of changes using only the WAL and without
performing lookups elsewhere.</p>

<p>The WAL is there and will be used anyway, enabling any ArangoDB server to be used as
a replication master without any configuration. Previous versions of ArangoDB (without
the WAL) required setting up an extra component for replication logging. This
requirement is now gone.</p>

<h1>Organization of the WAL</h1>

<p>The WAL is actually a collection of logfiles. Logfiles are named <code>logfile-xxxx.db</code>
(with xxxx being the logfile&rsquo;s id). Logfiles with lower ids are older than logfiles
with higher ids. By default, the logfiles reside in the <em>journals</em> sub-directory of
ArangoDB&rsquo;s database directory.</p>

<p>At any point in time, one of the logfiles will be the <em>active</em> logfile. ArangoDB will
write all data-modifications to the active logfile. Writing is append-only, meaning
ArangoDB will never overwrite existing logfile data. To ensure logfile integrity,
a CRC32 checksum is calculated for each logfile entry. This checksum is validated when
a logfile is replayed. When there is a checksum mismatch, this indicates a disk error
or an incompletely written operation &ndash; in both cases it won&rsquo;t be safe to recover and
replay the operation.</p>

<p>If an operation can&rsquo;t be written into the active logfile due to lack of space, the
active logfile will be closed and a new logfile will become the active logfile.</p>

<p>A background thread will open new logfiles before the current active one is fully
filled up. This is done to ensure that no waiting is required when there is a switch
of the active logfile.</p>

<p>By default, each logfile has a size of 32 MB, allowing lots of operations to be stored
in it. If you want to adjust the default size, the option <code>--wal.logfile-size</code> is for you.</p>

<h1>Logfile synchronization</h1>

<p>Writes to logfiles are synchronized to disk automatically in a configurable interval
(the option to look for is <code>--wal.sync-interval</code>). To get immediate synchronization
of operations, operations can be run with the <code>waitForSync</code> attribute set to <code>true</code>,
or on collections with the <code>waitForSync</code> attribute being set.</p>

<p>For example, the following operations will have been synchronized to disk when the
operations return:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="c1">// operation will be synchronized because the `waitForSync` attribute </span>
</span><span class='line'><span class="c1">// is set on operation level</span>
</span><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">test</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">foo</span><span class="o">:</span> <span class="s2">&quot;bar&quot;</span> <span class="p">},</span> <span class="p">{</span> <span class="nx">waitForSync</span><span class="o">:</span> <span class="kc">true</span> <span class="p">});</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// operation will be synchronized because the `waitForSync` attribute </span>
</span><span class='line'><span class="c1">// is set on collection level</span>
</span><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">mycollection</span><span class="p">.</span><span class="nx">properties</span><span class="p">({</span> <span class="nx">waitForSync</span><span class="o">:</span> <span class="kc">true</span> <span class="p">});</span>
</span><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">mycollection</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">foo</span><span class="o">:</span> <span class="s2">&quot;bar&quot;</span> <span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>When no immediate synchronization has been requested, ArangoDB will have a background
thread periodically call <code>msync</code> for not-yet synchronized logfile regions. Multiple
operations are synchronized together because they reside in adjacent memory regions.
That means automatic synchronization can get away with far less calls to <code>msync</code> than
there are operations.</p>

<h1>Storage overhead</h1>

<p>Documents stored in the WAL (as part of an insert, update or replace operation) are
stored in a format that contains the document values plus the document&rsquo;s shape.
This allows reading a document fully from a WAL entry without looking up shape
information elsewhere, making it faster and also more reliable.</p>

<p>Storing shape information in the WAL has a storage space overhead though. The overhead
should not matter much if a logfile contains a lot of documents with identical shapes.
ArangoDB will make sure each shape is only stored once per WAL logfile. This has
turned out to be a rather good solution: it reduces WAL storage space requirements
greatly, and still is reliable and fast, as shape lookups are local to the current
WAL logfile only.</p>

<p>The overhead of storing shape information in the WAL will matter most when documents
have completely different shapes. In this case, no shape information will ever be
re-used. While this may happen in benchmarks with synthetic data, we found that in
reality there are often lots of identically-structured documents and thus a lot of
potential for re-using shapes.</p>

<p>Note that storing shape information in the WAL can be turned off to reduce overhead.
ArangoDB provides the option <code>--wal.suppress-shape-information</code> for this purpose.
When set to <code>true</code>, no shape information will be written to the WAL. Note that by
default, the option is set to <code>false</code> and that the option shouldn&rsquo;t be changed if
the server is to be used as a replication master. If documents aren&rsquo;t too heterogenous,
setting the option to <code>true</code> won&rsquo;t help much. It will help a lot if all documents
that are stored have different shapes (which we consider unrealistic, but we still
provide the option to reduce overhead in this case).</p>

<h1>WAL cleanup</h1>

<p>WAL logfiles that are completely filled are subject to garbage collection. WAL
garbage collection is performed by a separate garbage collector thread. The thread
will copy over the still-relevant operations into the collection datafiles.
After that, indexes will be adjusted to point to the new storage locations.
Documents that have become obsolete due to later changes will not be copied from
the WAL into the collection datafiles at all.</p>

<p>Garbage-collected logfiles are deleted by ArangoDB automatically if there exist
more of these &ldquo;historic&rdquo; logfiles than configured. The number of historic logfiles
to keep before deletion is configured using the option <code>--wal.historic-logfiles</code>.</p>

<p>If no replication is to be used, there is no need to keep any historic logfiles.
They have no purpose but to provide a history of recent changes. The more history
there is on a master server, the longer is the period for which slave servers can
request changes for.
How much history is needed depends on how reliable the network connection between
a replication slave and the master is. If the network connection is known to fail
periodically, it may be wise to keep a few historic logfiles on the master, so the
slave can catch up from the point it stopped when the network connection is
re-established.</p>

<p>If network connections are reliable or no replication is to be used at all, the
number of historic logfiles can be set to a low value to save disk space.</p>

<h1>Side-effects of the WAL</h1>

<p>The WAL can be used for replication, removing the requirement to explicitly turn
on the separate logging of operations for replication purposes. This is a clear
improvement over previous versions of ArangoDB.</p>

<p>The introduction of the WAL also caused a few other minor changes:</p>

<p>While documents are stored in a WAL logfile, their sizes won&rsquo;t be included in
the output of the <code>figures</code> method of the collection. When a WAL logfile gets
garbage-collected, documents will physically be moved into the collection logfiles
and the figures will be updated.</p>

<p>Note that the output of the <code>count</code> method is not affected by whether a document
is stored in the WAL or in a collection logfile.</p>

<p>Another side-effect of storing operations in the WAL first is that no collection
logfiles will be created when the first document is inserted. So there will be
collections with documents but without any logfiles, at least temporarily until
the WAL garbage collection kicks in and will transfer data from the WAL to the
collection logfiles.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Schema Handling in ArangoDB]]></title>
    <link href="http://jsteemann.github.io/blog/2014/06/03/schema-handling-in-arangodb/"/>
    <updated>2014-06-03T22:57:58+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/06/03/schema-handling-in-arangodb</id>
    <content type="html"><![CDATA[<h1>Schemas vs. schema-free</h1>

<p>In a relational database, all rows in a table have the same structure.
The structure is saved once for the table, and the invidiual rows only
contain the row&rsquo;s values. This is an efficient approach if all records
have the exact same structure, i.e. the same attributes (same names and
same data types).</p>

<!-- more -->




<figure class='code'><figcaption><span>Example records </span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>firstName (varchar)  |  lastName (varchar)  |  status (varchar)
</span><span class='line'>---------------------+----------------------+------------------
</span><span class='line'>"fred"               |  "foxx"              |  "active"
</span><span class='line'>"john"               |  "doe"               |  "inactive"</span></code></pre></td></tr></table></div></figure>


<p>This is not a good fit if the data structure changes. In this case, an
<code>ALTER TABLE</code> command would need to be issued in the relational database,
converting all existing rows into the new structure. This is an expensive
operation because it normally requires rewriting all existing rows.</p>

<p>The situation becomes really difficult when there is no definite structure
for a table &ndash; if rows shall have a dynamic or variable structure, then
it can be quite hard to define a sensible relational table schema!</p>

<p>This is where NoSQL databases enter the game &ndash; mostly they don&rsquo;t require
defining a schema for a &ldquo;table&rdquo; at all. Instead, each individual record
will not only contain its data values, but also its own schema. This means
much higher flexibility as every record can its completely own data
structure.</p>

<p>This flexibility has a disadvantage though: storing schemas in individual
records requires more storage space than storing the schema only once for
the complete table. This is especially true if most (or even all) records
in the table do have the same structure. A lot of storage space can be
wasted while storing the same structure information again and again and again&hellip;</p>

<h1>Schemas in ArangoDB</h1>

<p>ArangoDB tries to be different in this respect: on the one hand it is a
schema-free database and thus allows <em>flexible storage</em>. All documents in a
collection (the ArangoDB lingo for <em>record</em> and <em>table</em>) can have the same
or totally different structures. We leave this choice up to the user.</p>

<p>On the other hand, ArangoDB will exploit the similarities in document
structures to <em>save storage space</em>. It will detect identical document
schemas, and only save each unique schema once. This process is called
<strong>shaping</strong> in ArangoDB.</p>

<h2>Shaping</h2>

<p>We optimized ArangoDB for this use case because we found that in reality, the
documents in a collection will either have absolutely the same schema, or
there will only be a few different schemas in use.</p>

<p>From the user perspective there are no schemas in ArangoDB: there is no way
to create or alter the schema of a collection at all. Instead, ArangoDB
will use the attribute names and data types contained in the JSON data of
each document. All of this happens automatically.</p>

<p>For each new document in a collection, ArangoDB will first figure out the
schema. It will then check if it has already processed a document with the
same schema. If yes, then there is no need to save the schema information
again. Instead, the new document will only contain a pointer to an already
existing schema. This does not require much storage space.</p>

<p>If ArangoDB figures out that it has not yet processed a document with the
same schema, it will store the document schema once, and store a pointer
to the schema in the new document. This is a slightly more expensive
operation, but it pays out when there are multiple documents in a
collection with the same structure.</p>

<p>When ArangoDB looks at document schemas, it takes into account the attribute
names and the attribute value data types contained in a document. All
attribute names and data types in a document make the so-called <em>shape</em>.</p>

<p>Each shape is only stored once for each collection. Any attribute name used
in a collection is also stored only once, and then reused from any shape that
contains the attribute name.</p>

<h2>Examples</h2>

<p>The following documents do have different values but still their schemas are
identical:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span> <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;first&quot;</span> <span class="p">:</span> <span class="s2">&quot;fred&quot;</span><span class="p">,</span> <span class="nt">&quot;last&quot;</span> <span class="p">:</span> <span class="s2">&quot;foxx&quot;</span> <span class="p">},</span> <span class="nt">&quot;status&quot;</span> <span class="p">:</span> <span class="s2">&quot;active&quot;</span> <span class="p">}</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;first&quot;</span> <span class="p">:</span> <span class="s2">&quot;john&quot;</span><span class="p">,</span> <span class="nt">&quot;last&quot;</span> <span class="p">:</span> <span class="s2">&quot;doe&quot;</span> <span class="p">},</span> <span class="nt">&quot;status&quot;</span> <span class="p">:</span> <span class="s2">&quot;inactive&quot;</span> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Both documents contain attributes named <code>name</code> and <code>status</code>. <code>name</code> is an
array with two sub-attributes <code>first</code> and <code>last</code>, which are both strings.
<code>status</code> also has string values in both documents.</p>

<p>ArangoDB will save this schema only once in a so-called <em>shape</em>. The documents
will store their own data values plus a pointer to this (same) shape.</p>

<p>The next two documents have different, yet unknown schemas. ArangoDB will
therefore store these two schemas in two new shapes:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span> <span class="nt">&quot;firstName&quot;</span> <span class="p">:</span> <span class="s2">&quot;jack&quot;</span><span class="p">,</span> <span class="nt">&quot;lastName&quot;</span> <span class="p">:</span> <span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="nt">&quot;status&quot;</span> <span class="p">:</span> <span class="s2">&quot;inactive&quot;</span> <span class="p">}</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;username&quot;</span><span class="p">,</span> <span class="nt">&quot;status&quot;</span> <span class="p">:</span> <span class="s2">&quot;unknown&quot;</span> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>We would end up with three diferent <em>shapes</em> for the four documents. This
might not sound impressive, but if more documents are saved with one of the
existing shapes, then storing each shape just once might really pay out.</p>

<h2>A note on attribute names</h2>

<p>Even though the latter two example documents had unique schemas, we saw in
the examples that attribute names were already repeating. For example, all
documents shown so far had an attribute named <code>status</code>, and some also
had a <code>name</code> attribute.</p>

<p>ArangoDB figures out when attribute names repeat, and it will not store the
same attribute name more than once in a collection. Given that many
documents in a collection use a fixed set of repeating attribute names,
this approach can lead to considerable storage space reductions.</p>

<p>As an aside, reusing attribute name information allows using descriptive
(read: long) attribute names in ArangoDB with very low storage overhead.</p>

<p>For example, in ArangoDB it will not cost much extra space to use long
attribute names like these in lots of documents:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span> <span class="nt">&quot;firstNameOfTheUser&quot;</span> <span class="p">:</span> <span class="s2">&quot;jack&quot;</span><span class="p">,</span> <span class="nt">&quot;lastNameOfTheUser&quot;</span> <span class="p">:</span> <span class="s2">&quot;black&quot;</span> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Each unique attribute name is only stored once per collection. In ArangoDB
there is thus no need to <em>artifically</em> shorten the attribute names in data
like it sometimes is done in other schema-free databases to save storage
space:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span> <span class="nt">&quot;fn&quot;</span> <span class="p">:</span> <span class="s2">&quot;jack&quot;</span><span class="p">,</span> <span class="nt">&quot;ln&quot;</span> <span class="p">:</span> <span class="s2">&quot;black&quot;</span> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>This artifical crippling of the attribute names makes the meaning of the
attributes quite unclear and should be avoided. As mentioned, it is not
necessary to do this in ArangoDB as it will save attribute names separate
from attribute values, and repeating attribute names are not stored
repeatedly.</p>
]]></content>
  </entry>
  
</feed>
