<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2014-10-16T02:13:55+02:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Handling Binary Data in Foxx]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/15/handling-binary-data-in-foxx/"/>
    <updated>2014-10-15T20:41:30+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/15/handling-binary-data-in-foxx</id>
    <content type="html"><![CDATA[<p>Handling binary data in JavaScript applications is a bit
tricky because JavaScript does not provide a data type for
binary data. This post explains how to use binary data in
JavaScript actions written using ArangoDB&rsquo;s <a href="http://docs.arangodb.org/Foxx/README.html">Foxx</a>.</p>

<!-- more -->


<h1>Strings vs. binary data</h1>

<p>Internally, JavaScript strings are <a href="http://ecma-international.org/ecma-262/5.1/#sec-4.3.16">sequences of 16 bit integer values</a>.
Furthermore, the ECMAScript standard requires that a JavaScript
implementation should interpret characters in conformance with the
Unicode standard, using either UCS-2 or UTF-16 encoding.</p>

<p>While this is fine for handling natural language, it becomes problematic
when trying to work with arbitrary binary data. Binary data cannot be
used safely in a JavaScript string because it may not be valid UTF-16
data.</p>

<p>To make it work anyway, binary data needs to be stored in a wrapper
object. I won&rsquo;t go into details about ES6 typed arrays here, but will
focus on <code>Buffer</code> objects.</p>

<h1>Binary data in Foxx actions</h1>

<p>A Foxx route that shall handle HTTP POST requests containing arbitrary
(binary) body in the request body should not use <code>req.body()</code>. The
reason is that <code>req.body()</code> will return the body as a JavaScript string,
and this isn&rsquo;t going to work with arbitrary binary data.</p>

<p>Instead, the <code>req.rawBodyBuffer()</code> should be used. This will return the
request body inside a buffer.
Here&rsquo;s an example that stores the received data in a file on the server:</p>

<figure class='code'><figcaption><span>Foxx action that can handle binary input</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">controller</span><span class="p">.</span><span class="nx">post</span><span class="p">(</span><span class="s1">&#39;/receive-binary&#39;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">req</span><span class="p">,</span> <span class="nx">res</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="c1">// fetch request body into the buffer</span>
</span><span class='line'>  <span class="kd">var</span> <span class="nx">body</span> <span class="o">=</span> <span class="nx">req</span><span class="p">.</span><span class="nx">rawBodyBuffer</span><span class="p">();</span>
</span><span class='line'>  <span class="c1">// create an absolute filename, local to the Foxx application directory</span>
</span><span class='line'>  <span class="kd">var</span> <span class="nx">filename</span> <span class="o">=</span> <span class="nx">applicationContext</span><span class="p">.</span><span class="nx">foxxFilename</span><span class="p">(</span><span class="s2">&quot;body&quot;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>  <span class="nx">require</span><span class="p">(</span><span class="s2">&quot;fs&quot;</span><span class="p">).</span><span class="nx">write</span><span class="p">(</span><span class="nx">filename</span><span class="p">,</span> <span class="nx">body</span><span class="p">);</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>This action can be invoked as follows if the app is mounted with name <code>app</code>:</p>

<pre><code>curl -X POST http://localhost:8529/app/receive-binary --data-binary @filename
</code></pre>

<p>This will send the contents of the file <code>filename</code> to the server. The Foxx
action will then store the received data as is in a file name <code>body</code> in the
application directory.</p>

<p>Returning binary data from a Foxx action is simple, too. Here&rsquo;s a way that
returns the contents of the file named <code>body</code> in the application&rsquo;s directory:</p>

<figure class='code'><figcaption><span>Foxx action that returns contents of a file</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">controller</span><span class="p">.</span><span class="nx">get</span><span class="p">(</span><span class="s1">&#39;/provide-binary-file&#39;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">req</span><span class="p">,</span> <span class="nx">res</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="c1">// create an absolute filename, local to the Foxx application directory</span>
</span><span class='line'>  <span class="kd">var</span> <span class="nx">filename</span> <span class="o">=</span> <span class="nx">applicationContext</span><span class="p">.</span><span class="nx">foxxFilename</span><span class="p">(</span><span class="s2">&quot;body&quot;</span><span class="p">);</span>
</span><span class='line'>  <span class="c1">// send the contents, this will also set mime type &quot;application/octet-stream&quot;</span>
</span><span class='line'>  <span class="nx">res</span><span class="p">.</span><span class="nx">sendFile</span><span class="p">(</span><span class="nx">filename</span><span class="p">);</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>It is also possible to return data from an arbitrary buffer:</p>

<figure class='code'><figcaption><span>Foxx action that returns data in a buffer </span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">controller</span><span class="p">.</span><span class="nx">get</span><span class="p">(</span><span class="s1">&#39;/provide-binary-buffer&#39;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">req</span><span class="p">,</span> <span class="nx">res</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="c1">// create an absolute filename, local to the Foxx application directory</span>
</span><span class='line'>  <span class="kd">var</span> <span class="nx">filename</span> <span class="o">=</span> <span class="nx">applicationContext</span><span class="p">.</span><span class="nx">foxxFilename</span><span class="p">(</span><span class="s2">&quot;body&quot;</span><span class="p">);</span>
</span><span class='line'>  <span class="c1">// read the file content into a buffer</span>
</span><span class='line'>  <span class="kd">var</span> <span class="nx">fileContent</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s2">&quot;fs&quot;</span><span class="p">).</span><span class="nx">readBuffer</span><span class="p">(</span><span class="nx">filename</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// TODO: modify the contents of buffer here...</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// send the contents, this will also set mime type &quot;application/octet-stream&quot;</span>
</span><span class='line'>  <span class="nx">res</span><span class="p">.</span><span class="nx">send</span><span class="p">(</span><span class="nx">fileContent</span><span class="p">);</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<h1>Example application</h1>

<p>I quickly put together an example application that shows how to handle arbitrary
binary data in Foxx actions. The example app allows uploading files to the server.
The server will then list these files and allows downloading them again.</p>

<p>The application has no CSS at all. Its only purpose is to demo the server-side code.
The application can be downloaded <a href="http://jsteemann.github.io/downloads/code/filelist-app.tar.gz">here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Understanding Where Operations Are Executed]]></title>
    <link href="http://jsteemann.github.io/blog/2014/08/30/understanding-where-operations-are-executed/"/>
    <updated>2014-08-30T22:38:42+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/08/30/understanding-where-operations-are-executed</id>
    <content type="html"><![CDATA[<p>I recently had to deal with some data processing operation that took
about 20 minutes to complete. When looking into this, I found that the
easiest and most beneficial change to the whole setup was to make the
operation a <em>server-side</em> operation instead of executing it <em>client-side</em>.</p>

<p>This change reduced the operation&rsquo;s total execution time to a few seconds.</p>

<!-- more -->


<p>I can&rsquo;t show the original processing task here, so I&rsquo;ll start with a
contrived example. Imagine the following <em>for</em> loop inserting 100K documents
into a collection named <code>test</code>:</p>

<figure class='code'><figcaption><span>inserting 100k documents</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="k">for</span> <span class="p">(</span><span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">;</span> <span class="o">++</span><span class="nx">i</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">db</span><span class="p">.</span><span class="nx">test</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">value</span><span class="o">:</span> <span class="nx">i</span> <span class="p">});</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now we only need a client application to execute the operation. As I don&rsquo;t
have a presentable client application right now, I will use the ArangoShell as
my client application.</p>

<h2>What&rsquo;s in a for loop?</h2>

<p>Running the above <em>for</em> loop inside the ArangoShell will lead to the loop being
executed inside the <em>arangosh</em> process.</p>

<p>In order to save a document in the collection, arangosh (our client) must make a
call to the ArangoDB server. This means issuing an HTTP POST request
to the server&rsquo;s REST API at <code>/_api/document/?collection=test</code>.
The server process will receive this request, insert the document, and
respond with an HTTP status code 201 or 202 to our client.
The client will then continue the loop until all documents have been inserted.</p>

<p>Now it&rsquo;s easy to see that the simple 3-line loop will issue 100,000 HTTP requests
in total. This means lots of data being pushed through the network stack(s).
It is pretty easy to imagine that this will come at a cost.</p>

<p>If we instead execute the above loop directly inside the ArangoDB server, we
can get rid of all the network overhead. The server has no need to send HTTP
calls to itself. It can simply execute the 100K inserts and is then done.
We therefore assume the loop to run somewhat faster when executed server-side.</p>

<p>A quick test on a crap laptop produced the following execution times for running
the loops:</p>

<ul>
<li>server-side execution (arangod): 1.34 seconds</li>
<li>client-side execution (arangosh): 17.32 seconds</li>
</ul>


<p><strong>Ouch</strong>. It looks like the client-server request-response overhead matters.</p>

<p>The following sections deal with how to get rid of some or even all the
client-server ping pong.</p>

<h2>Graph traversals</h2>

<p>The above <em>for</em> loop example was contrived, but imagine running
a client-side graph traversal instead. In fact, the original problem mentioned
in the introduction has been a graph traversal.</p>

<p>The problem of a graph traversal is that is often iterative and highly
dynamic. Decisions are made during the traversal as nodes are encountered,
leading to dynamic inclusion or exclusion etc. This means that it makes sense to
process nodes and edges only when needed, at the point when they are visited.</p>

<p>Even if the client can employ some sort of caching for already visited
nodes, the client still needs to ask the server about each visited
node&rsquo;s connections at least once. Otherwise it could not follow them.</p>

<p>This normally means lots of requests and responses. Compare this to the
<em>single</em> request-response alternative in which a client kicks off a server-side
traversal, and finally receives the overal result once it is assembled.</p>

<p><strong>Conclusion</strong>: traversals on anything but very small graphs should be run server-side.
A server-side action (see below) is a good way to do this. Please note that
running a server-side traversal does not mean giving up flexibility and
control flow functionality. Server-side traversals remain highly configurable
through custom JavaScript functions that allow implementation of user-defined
business logic.</p>

<h2>AQL queries</h2>

<p>We won&rsquo;t have your application send a series of 100,000 individual
insert statements to the relational database of our choice. We already
know from the past that this is going to be rather slow, so we have
learned to avoid this. In the relational context, we rather use SQL queries
that create or modify many rows in one go, e.g. an <code>INSERT INTO ... SELECT ...</code>,
bulk inserts etc.</p>

<p>ArangoDB is no different. In general, you should try to avoid issuing lots
of individual queries to the database from a client application. Instead and if
the queries look alike, try converting multiple individual operations into a
single AQL query. This will already save a lot of network overhead.</p>

<p>AQL provides multi-document operations to insert, update, and remove data. An
overview is given <a href="http://docs.arangodb.org/Aql/DataModification.html">here</a>.</p>

<p>The above 100K inserts from the contrived example can easily be transformed
into this single AQL query:</p>

<figure class='code'><figcaption><span>inserting 100k documents</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">FOR</span> <span class="nx">i</span> <span class="nx">IN</span> <span class="mi">1</span><span class="p">..</span><span class="mi">100000</span> <span class="nx">INSERT</span> <span class="p">{</span> <span class="nx">value</span><span class="o">:</span> <span class="nx">i</span> <span class="p">}</span> <span class="nx">INTO</span> <span class="nx">test</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Bulk imports</h2>

<p>For importing larger amounts of documents from files, there is the specialized
<a href="http://docs.arangodb.org/Arangoimp/README.html">arangoimp</a> import tool. It can
load data from JSON and CSV files into ArangoDB. The tool is shipped with
ArangoDB.</p>

<p>ArangoDB also provides a REST API for <a href="http://docs.arangodb.org/HttpBulkImports/README.html">bulk imports</a>
of documents.</p>

<h2>Joins</h2>

<p>A special note about <em>joins</em>: the fact that several NoSQL databases do not
provide join functionality has driven some people to emulate join functionality
on the client-side, in their applications.</p>

<p>This can be a recipe for disaster: client-side join implementation might lead
to horrendous amounts of queries that might need to be sent to the database for
fetching all the records. More than that, if data are queried individually,
the overall result may lack consistency. By the way, the same is true for
fetching referenced or linked documents.</p>

<p>ArangoDB provides join functionality via AQL queries. Additionally, AQL queries
can be used to fetch other documents with the original documents. Note that
ArangoDB has no way of defining references or links between documents, but
still AQL allows combining arbitrary documents in one query.</p>

<p>In almost all cases it make more sense to use an AQL query that performs
joins or reference-fetching server-side and close to the data than having to
deal with that on the application-side of things.</p>

<p>AQL joins are described <a href="http://docs.arangodb.org/AqlExamples/Join.html">here</a>.</p>

<h2>Server-side actions</h2>

<p>With <em>stored procedures</em>, relational databases provide another way for an
application to trigger the execution of a large amount of queries. Stored
procedures are executed server-side, too, so they allow avoiding a lot of
request-response ping pong between the application and the database, at least
for defined tasks. Additionally, stored procedures provide control flow
functionality, which can also be handy when operations depend on each other.</p>

<p>Coming back to ArangoDB: complex data-processing tasks that need to execute
multiple operations or need control flow functionality might benefit if
converted from multiple application-side operations into a single server-side
action.</p>

<p>Server-side actions run inside the ArangoDB server, closer to the data, and
can be much faster than a series of client-side operations.
A server-side action is called with just one HTTP request from the application,
so it may lead to saving lots of request-response cycles and reduction in
network overhead. Apart from that, server-side actions in ArangoDB can employ
transactions and provide the necessary control over isolation and atomicity
when executing a series of operations.</p>

<p>Business logic and control flow functionality can be integrated
easily because server-side actions in ArangoDB are JavaScript functions,
with all of the language&rsquo;s programming features being available.</p>

<p>But there&rsquo;s even more to it: a single server-side operation can be written
to put together its result in a format most convenient for the client
application. This can also lead to better encapsulation, because all an
application needs to know about a server-side action is its API or contract.
Any internals of the action can be hidden from the client application. Overall,
this supports a service-oriented approach.</p>

<p>To learn more about how to write server-side actions, please have a look
at ArangoDB&rsquo;s <a href="http://docs.arangodb.org/Foxx/README.html">Foxx</a>. It is all
about making server-side actions available via REST APIs.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Speeding Up Server-side Operations]]></title>
    <link href="http://jsteemann.github.io/blog/2014/08/20/speeding-up-server-side-operations/"/>
    <updated>2014-08-20T22:02:09+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/08/20/speeding-up-server-side-operations</id>
    <content type="html"><![CDATA[<p>Sometimes it is easier to make server-side operations run a bit faster.
In the following post I&rsquo;ll show a few low-level optimizations that can
be applied to user-defined JavaScript code that is executed inside the
ArangoDB server.</p>

<!-- more -->


<h1>Scope</h1>

<p>Some data-access operations can be sped up by using the appropriate indexes,
but that&rsquo;s not what I am going to show here.
Instead, I want to demo a few easy optimizations that don&rsquo;t require any
changes to the data. Only JavaScript code needs to be minimally adjusted
to use them.</p>

<p>Note that I am not talking about code that is executed in the ArangoShell
here. I will only be looking at code that is executed inside the arangod
server instance. The natural places for using custom JavaScript code in
the ArangoDB server are for example:</p>

<ul>
<li><a href="http://docs.arangodb.org/Foxx/README.html">Foxx</a> controllers</li>
<li><a href="http://docs.arangodb.org/Transactions/TransactionInvocation.html">transactions</a></li>
<li><a href="http://docs.arangodb.org/ModuleTasks/README.html">tasks</a></li>
<li><a href="http://docs.arangodb.org/Traversals/README.html">traversals</a></li>
</ul>


<p>Of course it does not make much sense to optimize operations that are not
called very often. The code changes I show will only be useful for server-side
operations that are called very often, for example, from within loops or
from batch processing actions.</p>

<p>Before starting to change any code, please make sure that the code is executed
often and that it accounts for a significant part of the total execution time.</p>

<h2>Baseline</h2>

<p>Imagine the following custom JavaScript code running somewhere inside ArangoDB:</p>

<figure class='code'><figcaption><span>baseline</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">;</span> <span class="o">++</span><span class="nx">i</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">db</span><span class="p">.</span><span class="nx">test</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">value</span><span class="o">:</span> <span class="mi">1</span> <span class="p">});</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>This code inserts 100,000 documents into a collection <code>test</code>. Each document has
one attribute only. These numbers are arbitrary, but good enough for a demo.</p>

<p>What can we do to improve the runtime of the above code?</p>

<h2>Non-optimizations</h2>

<p>The <em>for</em> statement itself is not worth optimizing. It won&rsquo;t matter much if we used
pre-increment or post-increment for the loop induction variable <code>i</code> or if we
turned the <em>for</em> loop into a <em>while</em> loop. Any changes here might only save us a
few nanoseconds in total, but are likely to make the code more unreadable.</p>

<p>Let&rsquo;s not do that!</p>

<h2>Avoiding accessors</h2>

<p>Clearly, we should be looking at the <code>save</code> operation.</p>

<p><code>db.test.save()</code> looks like a function call, and we learned that function are
expensive. In this case, we cannot avoid the function call to <code>save()</code>, but we
can avoid another <em>hidden function call</em>. Yes, <code>db.test</code> actually calls a function,
though it does not look like it does.</p>

<p>The <code>db</code> object has auto-magic member attributes. The <code>db</code> object will have a
member attribute for existing collection. The member will automatically vanish when
a collection gets dropped, and the member will rename itself when collections are
renamed.</p>

<p>This magic is made possible by late-binding attributes and using accessor functions
for attribute accesses on the <code>db</code> object: whenever the attributes of the <code>db</code> object
are queried, an accessor function (<em>property query</em>) is called internally to compile
them. Accessing a specific attribute of the <code>db</code> object will also call an accessor
function (<em>property get</em>). This is exactly what happens in our case when we access
<code>db.test</code>.</p>

<p>If this was too complicated, it may become more obvious if we modified the original
code to this:</p>

<figure class='code'><figcaption><span>using attribute lookup</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">;</span> <span class="o">++</span><span class="nx">i</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">db</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">].</span><span class="nx">save</span><span class="p">({</span> <span class="nx">value</span><span class="o">:</span> <span class="mi">1</span> <span class="p">});</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now it should be obvious that accessing <code>test</code> requires an attribute lookup on the
<code>db</code> object, and behind the scenes the same will happen if we had written <code>db.test</code>
instead.</p>

<p>Let&rsquo;s avoid the repeated call to the accessor function inside the loop! This can
easily be achieved by assigning <code>db.test</code> to a variable once and forever outside
of the loop. This technique is called loop-invariant code motion, and it can be
applied in a lot of other situations, too:</p>

<figure class='code'><figcaption><span>loop-invariant code motion</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="kd">var</span> <span class="nx">collection</span> <span class="o">=</span> <span class="nx">db</span><span class="p">.</span><span class="nx">test</span><span class="p">;</span>
</span><span class='line'><span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">;</span> <span class="o">++</span><span class="nx">i</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">collection</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">value</span><span class="o">:</span> <span class="mi">1</span> <span class="p">});</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>(on a side note: you cannot assign <code>db.test.save</code> to a variable and call it as a
function)</p>

<h2>Enjoying the silence</h2>

<p>The <code>save</code> operation is chatty. Every time it is called, it will return some meta
data from the just-inserted document, e.g.:</p>

<figure class='code'><figcaption><span>save result</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;_id&quot;</span> <span class="p">:</span> <span class="s2">&quot;test/11443981931568&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;_rev&quot;</span> <span class="p">:</span> <span class="s2">&quot;11443981931568&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;_key&quot;</span> <span class="p">:</span> <span class="s2">&quot;11443981931568&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>In our case, we&rsquo;re not interested in these returned values, and we don&rsquo;t
capture them in a variable.
The <code>save</code> function doesn&rsquo;t know this and will happily assemble its
result array. The array consists of three string values (six when also counting
attribute names). Setting up the result definitely requires costly
memory allocations and string copying.</p>

<p>We can avoid all this by passing an <em>options</em> parameter into <code>save</code>, and setting
its <code>silent</code> attribute to <code>true</code>:</p>

<figure class='code'><figcaption><span>silence option</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">;</span> <span class="o">++</span><span class="nx">i</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">db</span><span class="p">.</span><span class="nx">test</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">value</span><span class="o">:</span> <span class="mi">1</span> <span class="p">},</span> <span class="p">{</span> <span class="nx">silent</span><span class="o">:</span> <span class="kc">true</span> <span class="p">});</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now <code>save()</code> will only return a boolean value, which is much quicker.</p>

<h2>Transactions</h2>

<p>Yet another alternative is use to wrap the operations in the loop into a
transaction. Transaction themselves won&rsquo;t buy us much feature-wise, so why use
them? The reason is simple: if we do not use a transaction ourselves, each
<code>save</code> operation will implicitly be executed in a transaction of its own.
For a loop with 100,000 operations, that will be 100K transactions!</p>

<p>So when we put all the operations into a single, now explicit transaction,
we can save the overhead of 99,999 transaction begin and commit operations.
Here&rsquo;s how to do it:</p>

<figure class='code'><figcaption><span>transaction</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">_executeTransaction</span><span class="p">({</span>
</span><span class='line'>  <span class="nx">collections</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">write</span><span class="o">:</span> <span class="s2">&quot;test&quot;</span>
</span><span class='line'>  <span class="p">},</span>
</span><span class='line'>  <span class="nx">action</span><span class="o">:</span> <span class="kd">function</span> <span class="p">()</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="mi">100000</span><span class="p">;</span> <span class="o">++</span><span class="nx">i</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>      <span class="nx">db</span><span class="p">.</span><span class="nx">test</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">value</span><span class="o">:</span> <span class="mi">1</span> <span class="p">});</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<h1>Results</h1>

<p>How far have we got with these minimal code adjustments?</p>

<p>I have put together a <a href="http://jsteemann.github.io/downloads/code/speeding-up-server.js">script</a>
that can be run in arangod. The script will run each version of the loop
10 times and time the execution. The minimum, maximum and
average execution times are printed (in seconds, less is better). Note that
the absolute times do not matter much here. Please have a look at the percentage
column, which shows the execution time of each variant in comparison to the
baseline.</p>

<p>Here&rsquo;s an excerpt of the script&rsquo;s output:</p>

<figure class='code'><figcaption><span>results</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>test name      |   total (s) |     min (s) |     max (s) |    avg2 (s) |       %
</span><span class='line'>--------------------------------------------------------------------------------
</span><span class='line'>baseline       |     13.0940 |      1.2907 |      1.3357 |      1.3084 |  100.00
</span><span class='line'>loop-invariant |     10.6888 |      1.0506 |      1.1042 |      1.0667 |   81.53
</span><span class='line'>silence        |     11.7186 |      1.1512 |      1.2247 |      1.1678 |   89.25
</span><span class='line'>transaction    |     10.1521 |      0.9987 |      1.0346 |      1.0149 |   77.56
</span><span class='line'>combined       |      7.8545 |      0.7768 |      0.7977 |      0.7850 |   59.99
</span></code></pre></td></tr></table></div></figure>


<p>As can be seen, moving the loop-invariant accessor function call outside of the
loop provided an almost 20% speedup (from 1.30 to 1.06 s). Using the silence
option did also provide some, but not the same speedup. Using transactions reduced
the execution time, and by putting all this together, a reduction of about 40 %
was achieved.</p>

<p>Your mileage may vary. Please feel free to adjust the test script and run your
own tests.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why JSON?]]></title>
    <link href="http://jsteemann.github.io/blog/2014/08/14/why-json/"/>
    <updated>2014-08-14T22:27:27+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/08/14/why-json</id>
    <content type="html"><![CDATA[<h1>To JSON or not?</h1>

<p>We&rsquo;re often asked why ArangoDB uses <a href="http://json.org">JSON</a> as its
data-interchange format for transferring documents from clients to
the database server and back. This is often accompanied by the
question if we could use <code>&lt;insert fancy format here&gt;</code> instead.</p>

<p>In the following article, I&rsquo;ll try to outline the reasons for why
we picked JSON as the interchange format, and why we still use it.</p>

<p>I&rsquo;ll start with a discussion of the pros and cons of JSON, look at
some alternative formats and present my personal opinion on why
using a different format may not provide too much benefit for us,
at least at the moment.</p>

<!-- more -->


<p>This post does not intend to say that any of these formats are better
or worse in general. I think there are applications for all of them.</p>

<p>However, I wanted to look at the different formats with our specific
use case, i.e. a RESTful database, in mind.</p>

<h1>What I don&rsquo;t like about JSON</h1>

<p>JSON is often criticized for its inefficiency and lack of <strong>real</strong>
data types. I&rsquo;ll often criticize it myself.</p>

<p>Following are my personal top 3 pain points.</p>

<h2>Parsing and memory allocation</h2>

<p>I have to admit that parsing JSON is painful from the efficiency
perspective. When the JSON parser encounters a <code>{</code> token,
it will know this is the start of an object, but it has no idea how
many object members will follow and need to be stored with the
object. The same is true for lists (starting with <code>[</code>).</p>

<p>String values are no different: when the parser encounters a <code>"</code>,
the length of the string is still unknown. To determine the length
of the string, one must read until the end of the string, taking
into account escape sequences for special characters, e.g. <code>\/</code>,
<code>\n</code>, <code>\t</code>, <code>\\</code>, but also Unicode escape sequences.</p>

<p>For example, the escaped 36-byte string <code>In K\u00f6ln, it's 15 \u00b0 outside</code>
will be parsed into the 28-byte UTF-8 string <code>In Köln, it's 15 ° outside</code>.</p>

<p>With the overall size of objects, lists or strings unknown at the
start of a token, it&rsquo;s hard to reserve the <strong>right</strong> amount of memory.
Instead, memory either needs to be allocated on the fly as JSON
tokens are parsed, or (potentially too big) chunk(s) of memory
needs to be put aside at the start of parsing. The parser can
then use this already allocated memory to store whatever is found
afterwards.</p>

<h2>Verbosity</h2>

<p>JSON data can also become very fluffy. I already mentioned that
serializing strings to JSON might incur some overhead due to escape
sequences.</p>

<p>But there&rsquo;s more things like this: each boolean value requires 4
(<code>true</code>) or 5 (<code>false</code>) bytes respectively. Repeating object member
names need to be stored repeatedly, as JSON does not provide string
interning or similar mechanisms.</p>

<h2>Data types</h2>

<p>Apart from that, the JSON type system is limited. There is only one
type to represent numbers. Different types for representing numbers
of different value ranges are (intentionally) missing. For example,
one might miss 64 bit integer data types or arbitrary precision
numbers. A date type (for calendar dates and times) is often missed, too.</p>

<p>And yes, binary data cannot be represented in JSON without converting
them into a JSON string first. This may require base64-encoding or
something similar.</p>

<p>In general, the available data types in JSON are very limited, and the
format by itself is not extensible. Extending JSON with own type information
will either create ill-formed JSON (read: <em>non-portable</em>) or would
introduce special meaning members that other programs and tools won&rsquo;t
understand (read: <em>non-portable</em>).</p>

<h1>Why still use JSON?</h1>

<p>So what are the reasons to still stick with JSON?
From my point of view, there are still a few good reasons to do so:</p>

<h2>Simplicity</h2>

<p>The <a href="http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf">JSON specification</a>
fits on five pages (including images). It is simple and intuitive.</p>

<p>Additionally, JSON-encoded data is instantly comprehensible. There is
simply no need to look up the meanings of binary magic values in format
specifications. It is also very easy to spot errors in ill-formed JSON.</p>

<p>In my eyes, looking at JSON data during a debugging session is much
easier than looking at binary data (and I do look at binary data sometimes).</p>

<h2>Flexibility</h2>

<p>JSON requires no schema to be defined for data. This is good, as it allows to
get something done earlier. Schemas also tend to change over time, and this
can become a problem with other formats that have schemas. With schema-less JSON,
a schema change becomes a no-brainer &ndash; just change the data inside the JSON
and you&rsquo;re done. No need to maintain a separate schema.</p>

<p>The schema-relaxed approach of JSON also plays quite well with languages that
are loosely typed or allow runtime modifications of data structures. Most
scripting languages are in this category.</p>

<h2>Language support</h2>

<p>JSON is supported in almost every environment. Support for JSON is
sometimes built into languages directly (JavaScript) or the languages come
with built-in serialization and deserialization functions (e.g. PHP).
Just go and use it.</p>

<p>For any other language without built-in support for JSON, it won&rsquo;t be hard to find
a robust implementation for JSON serialization/deserialization.</p>

<p>In the ArangoDB server, we use a lot of JavaScript code ourselves. Users
can also extend the server functionality with JavaScript. Guess what happens
when a JSON request is sent to the server and its payload is handed to a
JavaScript-based action handler in the server? Yes, we&rsquo;ll take the request
body and create JavaScript objects from it. This is as simple as it can be,
because we have native JSON support in JavaScript, our server-side programming
language.</p>

<p>We also encourage users to use ArangoDB as a back end for their JavaScript-based
front ends. Especially when running in a browser, using JSON as the interchange
format inside AJAX* requests makes sense. You don&rsquo;t want to load serialization/deserialization
libraries that handle binary format into front ends for various reasons.</p>

<p>Many tools, including browsers, also support inspecting JSON data or can
import or export JSON-encoded data.</p>

<p>*Pop quiz: does anyone remember what was the meaning of the &ldquo;X&rdquo; in AJAX??</p>

<h1>Alternatives</h1>

<p>As I have tried to outline above, I think JSON has both strengths and
weaknesses. Is there an alternative format that is superior? I am listing
a few candidate formats below, and try to assess them quickly.</p>

<p>One thing that they all have in common is that they are not as much supported
by programming languages and tools as JSON is at the moment. For most of the
alternative formats, you would have to install some library in the environment
of your choice. XML is already available in many environments by default, with
the notable exception of JavaScript.</p>

<p>Even if a format is well supported by most programming languages, there are
other tools that should handle the format, too.</p>

<p>If there aren&rsquo;t any tools that allow converting existing data into the format,
then this is a severe limitation. Browsers, for example, are important tools.
Most of the alternative formats cannot be inspected easily with a browser,
which makes debugging data transfers from browser-based applications hard.</p>

<p>Additionally, one should consider how much example datasets are available.
I think at the moment it&rsquo;s much more likely that you&rsquo;ll find a JSON-encoded
dump of Wikipedia somewhere on the Internet than in one of the alternative
formats.</p>

<h2>Proprietary format</h2>

<p>An alternative to using JSON would be to create and our own binary format.
We could use a protocol tailored to our needs, and make it very very
efficient. The disadvantages of using a proprietary format are
that it is nowhere supported, so writing clients for ArangoDB in
another language becomes much harder for ourselves and for third-party
contributors. Effectively, we would need to write an adapter for
our binary protocol for each environment we want to have ArangoDB
used in.</p>

<p>This sounds like it would take a lot of time and keep us from doing
other things.</p>

<h2>XML</h2>

<p>It&rsquo;s human-readable, understandable, has a good standard type system
and is extensible. But if you thought that JSON is already inefficient
and verbose, try using XML and have fun. A colleague of mine even
claimed that XML is not human-readable due to its chattyness.</p>

<p>XML also hasn&rsquo;t been adopted much in the JavaScript community, and we
need to find a format that plays nicely with JavaScript.</p>

<h2>Smile</h2>

<p>There is also the <a href="http://wiki.fasterxml.com/SmileFormat">Smile</a> format.
Its goals are to provide an efficient alternative to JSON. It looks
good, but it does not seem to be used much outside of <a href="http://wiki.fasterxml.com/JacksonHome">Jackson</a>.
As mentioned earlier, we need a format that is supported in a variety of
environments.</p>

<h2>BSON</h2>

<p>Then there is <a href="http://bsonspec.org/">BSON</a>, made popular by MongoDB.
We had a look at it. It is not as space-efficient as it could be, but
it makes memory allocation very easy and allows for fast packing and
unpacking. It is not so good when values inside the structure need to
be updated. There are BSON-libraries for several languages</p>

<p>Still, it is a binary format. Using it for communication in the ArangoDB
cases includes using it from arbitrary JavaScript programs (including
applications run in a browser), using it in AJAX calls etc. This sounds
a bit like debugging hell.</p>

<h2>Msgpack</h2>

<p><a href="http://msgpack.org/">Msgpack</a> so far looks like the most-promising
alternative. It seems to become available in more and more programming
language environments. The format also seems to be relatively efficient.</p>

<p>A major drawback is that as a binary format, it will still be hard to debug.
Tool support is also not that great yet. Using Msgpack with a browser also
sounds like fun. I&rsquo;d like if tools like Firebug could display Msgpack
packet internals.</p>

<h2>Protocol buffers</h2>

<p>Two years ago, we also experimented with <a href="https://code.google.com/p/protobuf/">Protocol buffers</a>.
Protocol buffers require to set up a schema for the data first, and
then provide efficient means to serialize data from the wire into
programming-language objects.</p>

<p>The problem is that there are no fixed schemas in a document database
like ArangoDB. Users can structure their documents as they like. Each
document can have a completely different structure.</p>

<p>We ended up defining a schema for something JSON-like inside Protocol
buffers, and it did not make much sense in our use case.</p>

<h1>Conclusion</h1>

<p>There are alternative formats out there that address some of the issues
that JSON has from my point of view. However, none of the other formats
is yet that widely supported and easy to use as JSON.</p>

<p>This may change over time.</p>

<p>For our use case, it looks like Msgpack could fit quite well, but
probably only as a second, alternative interface for highest-efficiency
data transfers.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Benchmarking ArangoDB's Write-ahead Log]]></title>
    <link href="http://jsteemann.github.io/blog/2014/08/07/benchmarking-arangodbs-write-ahead-log/"/>
    <updated>2014-08-07T01:27:04+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/08/07/benchmarking-arangodbs-write-ahead-log</id>
    <content type="html"><![CDATA[<h1>Motivation</h1>

<p>One of the major changes in ArangoDB 2.2 was the introduction of the
<em>write-ahead log</em> (abbreviated <em>WAL</em>).</p>

<p>The introduction of the WAL changed how documents are stored internally in
ArangoDB. A lot of things have been changed for it under the hood, and it has
been a lot of work to implement it.</p>

<p>During the implementation, we refactored some code parts and made them
considerably faster. From these changes we expected a positive effect on the
database performance. But due to the fact that shape information is now also
saved in the write-ahead log, there may also be some negative effect.</p>

<p>We developers were of course very interested in seeing the net effects, so
we ran some tests for a few use cases. We compared ArangoDB 2.1.2 (still without
the WAL) with ArangoDB 2.2.1 (with the WAL). The results are interesting.</p>

<!-- more -->


<h1>Test setup</h1>

<p>To get a broad overview of performance changes, we ran a few different test cases:</p>

<ul>
<li><strong>document</strong>: inserts a document</li>
<li><strong>crud</strong>: inserts a document, fetches it, updates it, and deletes it</li>
<li><strong>crud-append</strong>: inserts a document, fetches it, updates it, and fetches it again</li>
<li><strong>multi-collection</strong>: transactionally save two documents in two collections</li>
<li><strong>random-shapes</strong>: save documents with completely different structures/shapes</li>
</ul>


<p>All tests were run with the <code>arangob</code> benchmark tool, with various concurrency levels,
complexity settings and repeated several times. <code>arangob</code> was invoked like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>arangob                         \
</span><span class='line'>  --test-case $case             \
</span><span class='line'>  --request $requests           \
</span><span class='line'>  --concurrency $concurrency    \
</span><span class='line'>  --complexity $complexity</span></code></pre></td></tr></table></div></figure>


<p>Both ArangoDB servers and <code>arangob</code> were located on the same server. Only one
ArangoDB server was active during each test run, and the other was shut down so
it didn&rsquo;t compete for system resources.</p>

<h1>Test results</h1>

<p>Following are the results for the different test cases.</p>

<p>In the result tables, the columns have the following meanings:</p>

<ul>
<li><strong>Complexity</strong>: the number of attributes for the test documents, used as parameter
<code>--complexity</code> for <code>arangob</code></li>
<li><strong>Requests</strong>: the number of operations executed, used as parameter <code>--requests</code>
for <code>arangob</code></li>
<li><strong>Concurrency</strong>: the number of client threads started by <code>arangob</code>, used a parameter
<code>concurrency</code> for <code>arangob</code></li>
<li><strong>Time 2.1</strong>: test execution time (in seconds) for ArangoDB 2.1</li>
<li><strong>Time 2.2</strong>: test execution time (in seconds) for ArangoDB 2.2</li>
<li><strong>T2.1/T2.2</strong>: relative performance of ArangoDB 2.1 compared to ArangoDB 2.2. Values
less than one indicate that ArangoDB 2.1 was faster than ArangoDB 2.2. Values
greater than one indicate that ArangoDB 2.1 was slower than ArangoDB 2.2. A
value of one means that both versions had equal speed.</li>
</ul>


<p>Please note that the absolute execution times aren&rsquo;t too interesting in the
results shown here. We haven&rsquo;t used the most powerful server on earth for running
these tests. We were most interested in how ArangoDB 2.2 compared to
ArangoDB 2.1.</p>

<h2>Inserting documents</h2>

<p>The <code>document</code> test appends new documents (with an identical structure) to a
collection. Here are the results for inserting a million documents with 100
attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>       100       1000000               1       97.452       94.839         1.02    
</span><span class='line'>       100       1000000               2       61.146       53.928         1.13   
</span><span class='line'>       100       1000000               4       54.368       31.379         1.73  </span></code></pre></td></tr></table></div></figure>


<p>Following are the results for 100,000 documents with 1,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>      1000        100000               1       86.883       80.669         1.07 
</span><span class='line'>      1000        100000               2       59.381       48.599         1.22 
</span><span class='line'>      1000        100000               4       53.784       27.494         1.95 </span></code></pre></td></tr></table></div></figure>


<p>The results for 5,000 documents with 10,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>     10000          5000               1       43.991       40.577         1.08 
</span><span class='line'>     10000          5000               2       31.403       26.117         1.20 
</span><span class='line'>     10000          5000               4       28.713       20.044         1.43 </span></code></pre></td></tr></table></div></figure>


<p>As we can see in the results above, ArangoDB 2.2 is faster than ArangoDB 2.1 for
all tested configurations. The difference is negligible if the test client is
single-threaded (one insert thread), but ArangoDB 2.2 is considerably faster than
ArangoDB 2.1 with more concurrent clients.</p>

<h2>CRUD operations (I)</h2>

<p>The <code>crud</code> test case inserts a document, fetches it, updates it, fetches it again
and finally deletes it. Executing 1 million crud operations on documents with 100
attributes each results in the following execution times:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>       100       1000000               1       66.856       67.072         0.99       
</span><span class='line'>       100       1000000               2       47.907       47.043         1.01        
</span><span class='line'>       100       1000000               4       42.089       42.047         1.00         </span></code></pre></td></tr></table></div></figure>


<p>Running 100,000 crud operations on documents with 1,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>      1000        100000               1      160.228      158.312         1.01 
</span><span class='line'>      1000        100000               2      147.413      147.990         0.99  
</span><span class='line'>      1000        100000               4      143.575      143.233         1.00   </span></code></pre></td></tr></table></div></figure>


<p>And here are the test results for running 5,000 crud operations on documents with
10,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>     10000          5000               1      645.859      643.924         1.00        
</span><span class='line'>     10000          5000               2      640.414      640.767         0.99       
</span><span class='line'>     10000          5000               4      637.438      637.132         1.00      </span></code></pre></td></tr></table></div></figure>


<p>The results of all these tests show that performance for the tested workload hasn&rsquo;t
changed between ArangoDB 2.1 and 2.2. This is somewhat expected, as the WAL should
not affect the performance of read and delete operations much: reading a document
does not require writing to the WAL at all, and removing a document only requires
writing a very small remove marker to the WAL.</p>

<h2>CRUD operations (II)</h2>

<p>The <code>crud-append</code> test case inserts a document, fetches it, updates it, and fetches
it again. Executing 1 million crud operations on documents with 100 attributes each
results in the following execution times:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>       100       1000000               1       81.187       79.079         1.02 
</span><span class='line'>       100       1000000               2       59.544       56.934         1.04  
</span><span class='line'>       100       1000000               4       53.845       52.098         1.03   </span></code></pre></td></tr></table></div></figure>


<p>Running 100,000 crud operations on documents with 1,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>      1000        100000               1      200.057      196.722         1.01 
</span><span class='line'>      1000        100000               2      182.436      181.633         1.00 
</span><span class='line'>      1000        100000               4      181.233      180.631         1.00 </span></code></pre></td></tr></table></div></figure>


<p>And here are the test results for running 5,000 crud operations on documents with
10,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>     10000          5000               1      804.781      801.903         1.00 
</span><span class='line'>     10000          5000               2      796.589      797.693         0.99  
</span><span class='line'>     10000          5000               4      796.664      795.823         1.00  </span></code></pre></td></tr></table></div></figure>


<p>Again, ArangoDB 2.1 and 2.2 are pretty much the same speed for the tested operations.</p>

<h2>Multi-collection write transactions</h2>

<p>The <code>multi-collection</code> test stores two documents in two different collections
transactionally. Here are the results for executing 100,000 transactions for
documents with 100 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>       100        100000               1     6936.895       30.736       225.69   
</span><span class='line'>       100        100000               2     6946.524       25.577       271.59    
</span><span class='line'>       100        100000               4     7720.682       24.334       317.27     </span></code></pre></td></tr></table></div></figure>


<p>Executing 10,000 transactions on documents with 1,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>      1000         10000               1      949.974       21.368        44.45     
</span><span class='line'>      1000         10000               2      953.672       19.322        49.35    
</span><span class='line'>      1000         10000               4      941.645       20.486        45.96   </span></code></pre></td></tr></table></div></figure>


<p>And finally, the results for executing 500 transactions on documents with 10,000
attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>     10000           500               1       46.776       10.413         4.49 
</span><span class='line'>     10000           500               2       45.102       10.173         4.43 
</span><span class='line'>     10000           500               4       44.172        9.192         4.80  </span></code></pre></td></tr></table></div></figure>


<p>The above results show that ArangoDB 2.2 is much faster than ArangoDB 2.1 for
executing transactions that write to two collections.</p>

<p>We expected that! Multi-collection (write) transactions in ArangoDB 2.2 require
far less calls to <code>msync</code> than in ArangoDB 2.1. ArangoDB 2.2 can sync operations
of multiple transactions together in one call to <code>msync</code>. ArangoDB 2.1 needed to
synchronize each transaction separately.</p>

<h2>(Fully) heterogenous documents</h2>

<p>The <code>random-shapes</code> test inserts documents that have different structures each.
For each inserted document a new shape will need to be stored. Inserting one million
documents with 100 attributes each results in the following figures:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>       100       1000000               1      664.006       87.181         7.61        
</span><span class='line'>       100       1000000               2      433.570       60.613         7.15       
</span><span class='line'>       100       1000000               4      313.666       45.327         6.92      </span></code></pre></td></tr></table></div></figure>


<p>
The results show that ArangoDB 2.2 is considerably faster than ArangoDB 2.1 for
these cases &ndash; even with the storage overhead of writing the shapes to the WAL.</p>

<p>Now we inserted 100,000 documents with 1,000 document attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>      1000        100000              1        61.709       66.954         0.92    
</span><span class='line'>      1000        100000              2        39.294       46.458         0.84   
</span><span class='line'>      1000        100000              4        36.866       40.910         0.90  </span></code></pre></td></tr></table></div></figure>


<p>In these cases, the storage overhead of writing all shapes to the WAL seems to
start to matter, and ArangoDB 2.2 gets slower than ArangoDB 2.1 in this test
case.</p>

<p>The same was true when we inserted 5,000 documents with 10,000 attributes each:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Complexity      Requests     Concurrency     Time 2.1     Time 2.2    T2.1/T2.2
</span><span class='line'>-------------------------------------------------------------------------------
</span><span class='line'>     10000          5000               1       25.337       30.412         0.83    
</span><span class='line'>     10000          5000               2       20.021       22.128         0.90     
</span><span class='line'>     10000          5000               4       14.800       18.872         0.78      </span></code></pre></td></tr></table></div></figure>


<p>Note that the <code>random-shapes</code> test case is an extreme test case. We do not
consider it realistic that all documents in a collection have completely different
attribute names. Still we included it in our tests because we were sure that this
would be a case in which the overhead of the WAL would be clearly measurable.</p>

<p>Note that there is a way to make ArangoDB 2.2 faster than ArangoDB 2.1 even for
this test case: setting the option <code>--wal.suppress-shape-information</code> to <code>true</code>
will make ArangoDB not write shape information to the WAL, making document write
operations much faster in case all documents have heterogenous structures.</p>

<p>The option won&rsquo;t help much if a shapes repeat a lot. In this case, the WAL overhead
shouldn&rsquo;t matter too much already, or ArangoDB 2.2 should already be faster than 2.1
(as shown in the results above).</p>

<h1>Summary</h1>

<p>The tests revealed that the overhead of the WAL in ArangoDB 2.2 seems to be
negligible for most of the tested workloads. In many cases, ArangoDB 2.2 with
the WAL is even faster than ArangoDB 2.1 that did not have a WAL at all.</p>

<p>There is one notable exception: when documents have fully heterogenous structures,
the overhead of the WAL is measurable and significant. Though we consider this
to be a rather hypothetical case, we have added the configurtion option
<code>--wal.suppress-shape-information</code>. This can be used to turn off storing
shape information in the WAL. This is not safe when the server is to be used
as a replication master, but should work in cases when replication is not used.</p>

<p>The option should not have a big effect if documents are greatly or at least
somewhat homogenous. For these cases, ArangoDB 2.2 with its WAL should already
be as fast as 2.1 (or even faster).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How ArangoDB's Write-ahead Log Works]]></title>
    <link href="http://jsteemann.github.io/blog/2014/08/06/how-arangodbs-write-ahead-log-works/"/>
    <updated>2014-08-06T21:14:00+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/08/06/how-arangodbs-write-ahead-log-works</id>
    <content type="html"><![CDATA[<p>Since version 2.2, ArangoDB stores all data-modification operations in its
<em>write-ahead log</em> (abbreviated <em>WAL</em>). The introduction of the WAL massively
changed how data are stored in ArangoDB.</p>

<!-- more -->


<h1>What&rsquo;s in the WAL?</h1>

<p>The WAL contains data of all data-modification operations that were executed in
the ArangoDB server instance. Operations are written to the WAL in the order of
execution. The following types of operations are logged to the WAL:</p>

<ul>
<li>creating, updating, replacing or removing documents</li>
<li>creating, modifying or dropping collections and their indexes</li>
<li>creating or dropping databases</li>
</ul>


<p>The WAL is used for all databases of an ArangoDB server. Database ids are stored
in the WAL in order to tell data from different databases apart.</p>

<h1>Recovery using the WAL</h1>

<p>Should the ArangoDB server crash, it will replay its write-ahead
logs at restart. Replaying the logs will make the server recover the same
state of data as before the crash.</p>

<p>Any document-modification operations might belong to a transaction. Transaction
data are also stored in the write-ahead log, allowing the recovery of committed
transactions and preventing the recovery of aborted or unfinished transactions.</p>

<p>Let&rsquo;s assume the following operations are executed in an ArangoDB server in this
order&hellip;</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Seq#  |  Operation type       |  Transaction#  |  Context
</span><span class='line'>------+-----------------------+----------------+---------------------------------------
</span><span class='line'>   1  |  start transaction    |           773  |  database "_system"
</span><span class='line'>   2  |  insert document      |           773  |  collection "test", key "foo"
</span><span class='line'>   3  |  start transaction    |           774  |  database "_system"
</span><span class='line'>   4  |  insert document      |           774  |  collection "mycollection", key "bar"
</span><span class='line'>   5  |  start transaction    |           775  |  database "_system"
</span><span class='line'>   6  |  update document      |           775  |  collection "boom", key "test"
</span><span class='line'>   7  |  abort transaction    |           774  |  -                
</span><span class='line'>   8  |  remove document      |           773  |  collection "test", key "baz"
</span><span class='line'>   9  |  commit transaction   |           773  |  -     </span></code></pre></td></tr></table></div></figure>


<p>&hellip;and then the server goes down due to a power outage.</p>

<p>On server restart, the WAL contents will be replayed, so the server will redo the
above operations. It will find out that operations #2 and #8 belong to transaction #773.
Transaction #773 was already committed, so all of its operations must and will be
recovered.</p>

<p>Further it will find out that operation #4 belongs to transaction #774, which was
aborted by the user. Therefore, this operation will not be replayed but ignored.</p>

<p>Finally, it will find operation #6 belongs to transaction #775. For this transaction,
there is neither an abort nor a commit operation in the log. Because the transaction
was never committed, all of its operations are not replayed at restart and the server
will behave as if the transaction never happened.</p>

<h1>WAL and replication</h1>

<p>A side-effect of having a write-ahead log is that it can also be used for replication.
When a slave server fetches the latest changes from the master, the master can simply
read the operations from its WAL. Data in the WAL are self-contained, meaning the
master can efficiently compile the list of changes using only the WAL and without
performing lookups elsewhere.</p>

<p>The WAL is there and will be used anyway, enabling any ArangoDB server to be used as
a replication master without any configuration. Previous versions of ArangoDB (without
the WAL) required setting up an extra component for replication logging. This
requirement is now gone.</p>

<h1>Organization of the WAL</h1>

<p>The WAL is actually a collection of logfiles. Logfiles are named <code>logfile-xxxx.db</code>
(with xxxx being the logfile&rsquo;s id). Logfiles with lower ids are older than logfiles
with higher ids. By default, the logfiles reside in the <em>journals</em> sub-directory of
ArangoDB&rsquo;s database directory.</p>

<p>At any point in time, one of the logfiles will be the <em>active</em> logfile. ArangoDB will
write all data-modifications to the active logfile. Writing is append-only, meaning
ArangoDB will never overwrite existing logfile data. To ensure logfile integrity,
a CRC32 checksum is calculated for each logfile entry. This checksum is validated when
a logfile is replayed. When there is a checksum mismatch, this indicates a disk error
or an incompletely written operation &ndash; in both cases it won&rsquo;t be safe to recover and
replay the operation.</p>

<p>If an operation can&rsquo;t be written into the active logfile due to lack of space, the
active logfile will be closed and a new logfile will become the active logfile.</p>

<p>A background thread will open new logfiles before the current active one is fully
filled up. This is done to ensure that no waiting is required when there is a switch
of the active logfile.</p>

<p>By default, each logfile has a size of 32 MB, allowing lots of operations to be stored
in it. If you want to adjust the default size, the option <code>--wal.logfile-size</code> is for you.</p>

<h1>Logfile synchronization</h1>

<p>Writes to logfiles are synchronized to disk automatically in a configurable interval
(the option to look for is <code>--wal.sync-interval</code>). To get immediate synchronization
of operations, operations can be run with the <code>waitForSync</code> attribute set to <code>true</code>,
or on collections with the <code>waitForSync</code> attribute being set.</p>

<p>For example, the following operations will have been synchronized to disk when the
operations return:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="c1">// operation will be synchronized because the `waitForSync` attribute </span>
</span><span class='line'><span class="c1">// is set on operation level</span>
</span><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">test</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">foo</span><span class="o">:</span> <span class="s2">&quot;bar&quot;</span> <span class="p">},</span> <span class="p">{</span> <span class="nx">waitForSync</span><span class="o">:</span> <span class="kc">true</span> <span class="p">});</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// operation will be synchronized because the `waitForSync` attribute </span>
</span><span class='line'><span class="c1">// is set on collection level</span>
</span><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">mycollection</span><span class="p">.</span><span class="nx">properties</span><span class="p">({</span> <span class="nx">waitForSync</span><span class="o">:</span> <span class="kc">true</span> <span class="p">});</span>
</span><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">mycollection</span><span class="p">.</span><span class="nx">save</span><span class="p">({</span> <span class="nx">foo</span><span class="o">:</span> <span class="s2">&quot;bar&quot;</span> <span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>When no immediate synchronization has been requested, ArangoDB will have a background
thread periodically call <code>msync</code> for not-yet synchronized logfile regions. Multiple
operations are synchronized together because they reside in adjacent memory regions.
That means automatic synchronization can get away with far less calls to <code>msync</code> than
there are operations.</p>

<h1>Storage overhead</h1>

<p>Documents stored in the WAL (as part of an insert, update or replace operation) are
stored in a format that contains the document values plus the document&rsquo;s shape.
This allows reading a document fully from a WAL entry without looking up shape
information elsewhere, making it faster and also more reliable.</p>

<p>Storing shape information in the WAL has a storage space overhead though. The overhead
should not matter much if a logfile contains a lot of documents with identical shapes.
ArangoDB will make sure each shape is only stored once per WAL logfile. This has
turned out to be a rather good solution: it reduces WAL storage space requirements
greatly, and still is reliable and fast, as shape lookups are local to the current
WAL logfile only.</p>

<p>The overhead of storing shape information in the WAL will matter most when documents
have completely different shapes. In this case, no shape information will ever be
re-used. While this may happen in benchmarks with synthetic data, we found that in
reality there are often lots of identically-structured documents and thus a lot of
potential for re-using shapes.</p>

<p>Note that storing shape information in the WAL can be turned off to reduce overhead.
ArangoDB provides the option <code>--wal.suppress-shape-information</code> for this purpose.
When set to <code>true</code>, no shape information will be written to the WAL. Note that by
default, the option is set to <code>false</code> and that the option shouldn&rsquo;t be changed if
the server is to be used as a replication master. If documents aren&rsquo;t too heterogenous,
setting the option to <code>true</code> won&rsquo;t help much. It will help a lot if all documents
that are stored have different shapes (which we consider unrealistic, but we still
provide the option to reduce overhead in this case).</p>

<h1>WAL cleanup</h1>

<p>WAL logfiles that are completely filled are subject to garbage collection. WAL
garbage collection is performed by a separate garbage collector thread. The thread
will copy over the still-relevant operations into the collection datafiles.
After that, indexes will be adjusted to point to the new storage locations.
Documents that have become obsolete due to later changes will not be copied from
the WAL into the collection datafiles at all.</p>

<p>Garbage-collected logfiles are deleted by ArangoDB automatically if there exist
more of these &ldquo;historic&rdquo; logfiles than configured. The number of historic logfiles
to keep before deletion is configured using the option <code>--wal.historic-logfiles</code>.</p>

<p>If no replication is to be used, there is no need to keep any historic logfiles.
They have no purpose but to provide a history of recent changes. The more history
there is on a master server, the longer is the period for which slave servers can
request changes for.
How much history is needed depends on how reliable the network connection between
a replication slave and the master is. If the network connection is known to fail
periodically, it may be wise to keep a few historic logfiles on the master, so the
slave can catch up from the point it stopped when the network connection is
re-established.</p>

<p>If network connections are reliable or no replication is to be used at all, the
number of historic logfiles can be set to a low value to save disk space.</p>

<h1>Side-effects of the WAL</h1>

<p>The WAL can be used for replication, removing the requirement to explicitly turn
on the separate logging of operations for replication purposes. This is a clear
improvement over previous versions of ArangoDB.</p>

<p>The introduction of the WAL also caused a few other minor changes:</p>

<p>While documents are stored in a WAL logfile, their sizes won&rsquo;t be included in
the output of the <code>figures</code> method of the collection. When a WAL logfile gets
garbage-collected, documents will physically be moved into the collection logfiles
and the figures will be updated.</p>

<p>Note that the output of the <code>count</code> method is not affected by whether a document
is stored in the WAL or in a collection logfile.</p>

<p>Another side-effect of storing operations in the WAL first is that no collection
logfiles will be created when the first document is inserted. So there will be
collections with documents but without any logfiles, at least temporarily until
the WAL garbage collection kicks in and will transfer data from the WAL to the
collection logfiles.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Schema Handling in ArangoDB]]></title>
    <link href="http://jsteemann.github.io/blog/2014/06/03/schema-handling-in-arangodb/"/>
    <updated>2014-06-03T22:57:58+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/06/03/schema-handling-in-arangodb</id>
    <content type="html"><![CDATA[<h1>Schemas vs. schema-free</h1>

<p>In a relational database, all rows in a table have the same structure.
The structure is saved once for the table, and the invidiual rows only
contain the row&rsquo;s values. This is an efficient approach if all records
have the exact same structure, i.e. the same attributes (same names and
same data types).</p>

<!-- more -->




<figure class='code'><figcaption><span>Example records </span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>firstName (varchar)  |  lastName (varchar)  |  status (varchar)
</span><span class='line'>---------------------+----------------------+------------------
</span><span class='line'>"fred"               |  "foxx"              |  "active"
</span><span class='line'>"john"               |  "doe"               |  "inactive"</span></code></pre></td></tr></table></div></figure>


<p>This is not a good fit if the data structure changes. In this case, an
<code>ALTER TABLE</code> command would need to be issued in the relational database,
converting all existing rows into the new structure. This is an expensive
operation because it normally requires rewriting all existing rows.</p>

<p>The situation becomes really difficult when there is no definite structure
for a table &ndash; if rows shall have a dynamic or variable structure, then
it can be quite hard to define a sensible relational table schema!</p>

<p>This is where NoSQL databases enter the game &ndash; mostly they don&rsquo;t require
defining a schema for a &ldquo;table&rdquo; at all. Instead, each individual record
will not only contain its data values, but also its own schema. This means
much higher flexibility as every record can its completely own data
structure.</p>

<p>This flexibility has a disadvantage though: storing schemas in individual
records requires more storage space than storing the schema only once for
the complete table. This is especially true if most (or even all) records
in the table do have the same structure. A lot of storage space can be
wasted while storing the same structure information again and again and again&hellip;</p>

<h1>Schemas in ArangoDB</h1>

<p>ArangoDB tries to be different in this respect: on the one hand it is a
schema-free database and thus allows <em>flexible storage</em>. All documents in a
collection (the ArangoDB lingo for <em>record</em> and <em>table</em>) can have the same
or totally different structures. We leave this choice up to the user.</p>

<p>On the other hand, ArangoDB will exploit the similarities in document
structures to <em>save storage space</em>. It will detect identical document
schemas, and only save each unique schema once. This process is called
<strong>shaping</strong> in ArangoDB.</p>

<h2>Shaping</h2>

<p>We optimized ArangoDB for this use case because we found that in reality, the
documents in a collection will either have absolutely the same schema, or
there will only be a few different schemas in use.</p>

<p>From the user perspective there are no schemas in ArangoDB: there is no way
to create or alter the schema of a collection at all. Instead, ArangoDB
will use the attribute names and data types contained in the JSON data of
each document. All of this happens automatically.</p>

<p>For each new document in a collection, ArangoDB will first figure out the
schema. It will then check if it has already processed a document with the
same schema. If yes, then there is no need to save the schema information
again. Instead, the new document will only contain a pointer to an already
existing schema. This does not require much storage space.</p>

<p>If ArangoDB figures out that it has not yet processed a document with the
same schema, it will store the document schema once, and store a pointer
to the schema in the new document. This is a slightly more expensive
operation, but it pays out when there are multiple documents in a
collection with the same structure.</p>

<p>When ArangoDB looks at document schemas, it takes into account the attribute
names and the attribute value data types contained in a document. All
attribute names and data types in a document make the so-called <em>shape</em>.</p>

<p>Each shape is only stored once for each collection. Any attribute name used
in a collection is also stored only once, and then reused from any shape that
contains the attribute name.</p>

<h2>Examples</h2>

<p>The following documents do have different values but still their schemas are
identical:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span> <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;first&quot;</span> <span class="p">:</span> <span class="s2">&quot;fred&quot;</span><span class="p">,</span> <span class="nt">&quot;last&quot;</span> <span class="p">:</span> <span class="s2">&quot;foxx&quot;</span> <span class="p">},</span> <span class="nt">&quot;status&quot;</span> <span class="p">:</span> <span class="s2">&quot;active&quot;</span> <span class="p">}</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="nt">&quot;first&quot;</span> <span class="p">:</span> <span class="s2">&quot;john&quot;</span><span class="p">,</span> <span class="nt">&quot;last&quot;</span> <span class="p">:</span> <span class="s2">&quot;doe&quot;</span> <span class="p">},</span> <span class="nt">&quot;status&quot;</span> <span class="p">:</span> <span class="s2">&quot;inactive&quot;</span> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Both documents contain attributes named <code>name</code> and <code>status</code>. <code>name</code> is an
array with two sub-attributes <code>first</code> and <code>last</code>, which are both strings.
<code>status</code> also has string values in both documents.</p>

<p>ArangoDB will save this schema only once in a so-called <em>shape</em>. The documents
will store their own data values plus a pointer to this (same) shape.</p>

<p>The next two documents have different, yet unknown schemas. ArangoDB will
therefore store these two schemas in two new shapes:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span> <span class="nt">&quot;firstName&quot;</span> <span class="p">:</span> <span class="s2">&quot;jack&quot;</span><span class="p">,</span> <span class="nt">&quot;lastName&quot;</span> <span class="p">:</span> <span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="nt">&quot;status&quot;</span> <span class="p">:</span> <span class="s2">&quot;inactive&quot;</span> <span class="p">}</span>
</span><span class='line'><span class="p">{</span> <span class="nt">&quot;name&quot;</span> <span class="p">:</span> <span class="s2">&quot;username&quot;</span><span class="p">,</span> <span class="nt">&quot;status&quot;</span> <span class="p">:</span> <span class="s2">&quot;unknown&quot;</span> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>We would end up with three diferent <em>shapes</em> for the four documents. This
might not sound impressive, but if more documents are saved with one of the
existing shapes, then storing each shape just once might really pay out.</p>

<h2>A note on attribute names</h2>

<p>Even though the latter two example documents had unique schemas, we saw in
the examples that attribute names were already repeating. For example, all
documents shown so far had an attribute named <code>status</code>, and some also
had a <code>name</code> attribute.</p>

<p>ArangoDB figures out when attribute names repeat, and it will not store the
same attribute name more than once in a collection. Given that many
documents in a collection use a fixed set of repeating attribute names,
this approach can lead to considerable storage space reductions.</p>

<p>As an aside, reusing attribute name information allows using descriptive
(read: long) attribute names in ArangoDB with very low storage overhead.</p>

<p>For example, in ArangoDB it will not cost much extra space to use long
attribute names like these in lots of documents:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span> <span class="nt">&quot;firstNameOfTheUser&quot;</span> <span class="p">:</span> <span class="s2">&quot;jack&quot;</span><span class="p">,</span> <span class="nt">&quot;lastNameOfTheUser&quot;</span> <span class="p">:</span> <span class="s2">&quot;black&quot;</span> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Each unique attribute name is only stored once per collection. In ArangoDB
there is thus no need to <em>artifically</em> shorten the attribute names in data
like it sometimes is done in other schema-free databases to save storage
space:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span> <span class="nt">&quot;fn&quot;</span> <span class="p">:</span> <span class="s2">&quot;jack&quot;</span><span class="p">,</span> <span class="nt">&quot;ln&quot;</span> <span class="p">:</span> <span class="s2">&quot;black&quot;</span> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>This artifical crippling of the attribute names makes the meaning of the
attributes quite unclear and should be avoided. As mentioned, it is not
necessary to do this in ArangoDB as it will save attribute names separate
from attribute values, and repeating attribute names are not stored
repeatedly.</p>
]]></content>
  </entry>
  
</feed>
