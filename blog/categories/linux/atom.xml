<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Linux | J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2015-03-11T12:33:21+01:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using Ccache When Working With Different Branches]]></title>
    <link href="http://jsteemann.github.io/blog/2015/02/07/using-ccache-when-working-with-different-branches/"/>
    <updated>2015-02-07T17:00:15+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/02/07/using-ccache-when-working-with-different-branches</id>
    <content type="html"><![CDATA[<p>Git makes working with many different branches in the same local repository easy and efficient.</p>

<p>In a C/C++ project, the code must be re-compiled after switching into another branch.
If the branches only differ minimally, running <code>make</code> will only re-compile the parts that are
actually different, and after that re-link them. That won&rsquo;t take too long, though especially
link times can be annoying.</p>

<p>However, if there are differences in central header files that are included from every file,
then <code>make</code> has no option but to <strong>re-compile everything</strong>. This can take significant amounts of
time (and coffee).</p>

<p>I just realized that there is a solution to speed up re-compilation in this situation:
<a href="http://linux.die.net/man/1/ccache">ccache</a>!</p>

<!-- more -->


<h2>Why ccache can help</h2>

<p>ccache is a wrapper for the actual compiler command. It will call the compiler with the specified
arguments, and capture the compiler output. When called again with the same arguments, it will
look in its internal cache for a ready-to-serve result. If one is present, it will return it
without invoking the compiler again. Otherwise, or if it detects some changes that forbid serving
outdated results from the cache, it will transparently invoke the compiler.</p>

<p>When switching back to another branch that you had already compiled before, running <code>make</code>
may re-build <em>everything</em> due to changes in headers. But it is not unlikely that you had built
the branch before already. If so, and ccache was involved in the previous build, it may still
have all the info required for re-compilation in its cache.</p>

<p>And everyone will be happy: <code>make</code> will run its full rebuild, but most operations won&rsquo;t be handed
to the compiler because ccache is sitting in between, serving results from its cache.
And you as a developer won&rsquo;t lose that much time.</p>

<h2>Some figures</h2>

<p>Following are some figures demonstrating its potential when running a <code>make</code> in the devel branch
after having returned from a different branch with significant changes.</p>

<h3>With ccache, but cache empty</h3>

<p><code>plain time make
real  12m43.501s
user  11m52.550s
sys 0m44.110s
</code></p>

<h3>With ccache, everything in cache</h3>

<p><code>plain time make
real  0m55.572s
user  0m26.346s
sys 0m7.551s
</code></p>

<p>That&rsquo;s a <strong>build time reduction of more than 90 %</strong>!</p>

<p>This is already the optimal result, as everything was already present in the cache.
However, the situation was not unrealistic. I often switch into another branch, try something
out or commit a small change, and the return to the original branch. I already started having
many separate directories for the different branches to avoid frequent recompilation.
ccache can be relief here.</p>

<p>By the way, timing results are from my laptop. I did not bother to run <code>make</code> with parallel
jobs as this has limited effect on my laptop, though on more decent hardware it may be beneficial
both with and without ccache, though I guess, with many parallel jobs and a full cache, linking
will become the most expensive part.</p>

<h2>How to use ccache</h2>

<p>For Ubuntu, ccache is available in package <code>ccache</code>. You can easily install it with:
<code>bash Installing ccache on Ubuntu
sudo apt-get install ccache
</code></p>

<p>The most convenient way to use ccache in your build is to change your <code>CC</code> and <code>CXX</code>
environment variables as follows:
<code>bash setting compilers environment variables
export CC="ccache gcc"
export CXX="ccache g++"
</code></p>

<p>I suggest putting that into <code>.bashrc</code> so the variables will be set in every session and not
just once. After that, running <code>configure</code> will write a <code>Makefile</code> that will use ccache for
building object files.</p>

<p>Note: that will change these environment variables globally, so ccache may be used for other
projects, too.</p>

<h3>What ccache cannot do</h3>

<p>I already forgot about ccache because when working in a single branch it does not provide that
many benefits. When making changes to your code, you can be pretty sure the new code won&rsquo;t be
in the cache yet. Running <code>make</code> then will invoke ccache, but this will result in a cache miss.
It cannot help here, because the new code was never compiled before and thus in no cache.</p>

<p>Additionally, <code>make</code> is smart enough on its own to only re-build the parts of the program that
have actually changed or depend on the changes you made.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Core Dumps of Failed TravisCI Builds]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/30/getting-core-dumps-of-failed-travisci-builds/"/>
    <updated>2014-10-30T23:05:48+01:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/30/getting-core-dumps-of-failed-travisci-builds</id>
    <content type="html"><![CDATA[<p>I recently wrote about <a href="/blog/2014/10/17/using-travis-ci-for-a-c-plus-plus-11-project/">using TravisCI for continuously testing C++11 projects</a>.</p>

<p><strong>Now, what if a build fails?</strong></p>

<p>Especially for C and C++ projects, build failures may mean crashed
programs. In a local setup, the usual way to analyze program crashes
is to manually inspect the core files that are written on crash.</p>

<p>With TravisCI, there is no way to log in to a build machine and
inspect a core dump interactively. There is no SSH access to
the build machines. TravisCI does not even persist any state of
builds but the result and the log output.</p>

<p>There is a way to get to the core dumps, but it was fiddly to find
out and set up.</p>

<!-- more -->


<p>The basic idea is to run <code>gdb</code> on the TravisCI build machine
automatically when a build fails. <code>gdb</code> can be scripted, so all
we need to do is to make it print a backtrace in all threads at
the time of the crash.</p>

<p>By default, no core dumps will be produced on TravisCI. To turn them
on, an appropriate ulimit value must be set. We also need to install
<code>gdb</code> so we can actually run it. Here is the <code>.travis.yml</code> adjustment
for these prerequisites:</p>

<p>```yaml adjustments for install and before_script hooks
install:
&ndash; sudo apt-get install -y gdb  # install gdb</p>

<p>before_script:
&ndash; ulimit -c unlimited -S       # enable core dumps
```</p>

<p>To get an idea of where the program crashed, we can finally install
an <code>after_failure</code> hook. This hook can check for a core file and use
<code>gdb</code> to print a nice backtrace.</p>

<p>The core file pattern on TravisCI seems to be <code>core-%p</code>, so core
filenames will include the executable&rsquo;s process id and change on
every run. We can use <code>find</code> to look for files named <code>core*</code> in the
cwd and pick the first one as there should only be at most one core
file per build:</p>

<p><code>yaml adjustments for after_failure hook
after_failure:
- COREFILE=$(find . -maxdepth 1 -name "core*" | head -n 1) # find core file
- if [[ -f "$COREFILE" ]]; then gdb -c "$COREFILE" example -ex "thread apply all bt" -ex "set pagination 0" -batch; fi
</code></p>

<p>A failed build might produce output like this:</p>

<p><img src="/downloads/screenshots/travis-ci-gdb.png"></p>

<p>I recommend compiling the executable to test with debug symbols on and
with all optimizations turned off (i.e. compiler options <code>-g -O0</code>).
Otherwise backtraces might reveal less useful information for debugging.</p>

<p>On a side note: the <a href="http://lint.travis-ci.org/">Travis WebLint</a> is a
handy tool for validating <code>.travis.yml</code> files <em>before</em> pushing them.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Set Up Bash Completion for ArangoDB]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/22/how-to-set-up-bash-completion-for-arangodb/"/>
    <updated>2014-10-22T23:10:32+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/22/how-to-set-up-bash-completion-for-arangodb</id>
    <content type="html"><![CDATA[<p>I was interested in how bash auto-completion works and how to write
a custom completer. After about an hour of work, I came up with a
solution that at least seems to work on Ubuntu. I now have auto-completion
for ArangoDB and all its client tools!</p>

<!-- more -->


<h2>The problem</h2>

<p>I use the command-line for almost everything, including starting
and stopping ArangoDB and its client tools. They provide lots
of options which I cannot completely memorize.</p>

<p>The bash solution for &ldquo;I don&rsquo;t know what I am looking for&rdquo; is to
press the <strong>TAB</strong> key. This will bring up a list of suggestions for
how to complete the currently entered word. I thought using the
same thing for ArangoDB&rsquo;s command-line options would be nice, too.</p>

<h2>The solution</h2>

<p>It turned out that I needed to put a shell script that generates the
auto completion for <code>arangod</code> and all the other tools into <code>/etc/bash_completion.d</code>.
From there, the system will automatically pick it up when auto-completion
is initialized.</p>

<p>The script is rather simple. For example, to have auto-completion for
<code>arangosh</code> it would look like this:</p>

<p>```bash completion script example for arangosh
_arangosh()
{</p>

<pre><code>local cur prev opts
COMPREPLY=()
cur="${COMP_WORDS[COMP_CWORD]}"
prev="${COMP_WORDS[COMP_CWORD-1]}"
opts="--help --server.endpoint --server.username" # ...all the options go here

if [[ ${cur} == -* ]] ; then
    COMPREPLY=( $(compgen -W "${opts}" -- ${cur}) )
    return 0
fi
</code></pre>

<p>}</p>

<p>complete -o default -F _arangosh arangosh
```</p>

<p>As can be seen, the variable <code>opts</code> should be filled with the list of possible
options. Determining the options for a binary can be achieved by invoking it with its
<code>--help</code> option, e.g.:</p>

<p>```bash figuring out program options
arangosh &mdash;help | grep -o &ldquo;^\ +&mdash;[a-z-]+(.[a-z0-9-]+)\?&rdquo; | xargs</p>

<h1>this will generate something like the following output:</h1>

<h1>&mdash;audit-log &mdash;chunk-size &mdash;configuration &mdash;help &mdash;no-auto-complete &mdash;no-colors &mdash;pager &mdash;pretty-print &mdash;prompt &mdash;quiet &mdash;temp-path &mdash;use-pager &mdash;javascript.check &mdash;javascript.current-module-directory &mdash;javascript.execute &mdash;javascript.execute-string &mdash;javascript.gc-interval &mdash;javascript.startup-directory &mdash;javascript.unit-tests &mdash;jslint &mdash;log.level &mdash;log.use-local-time &mdash;server.connect-timeout &mdash;server.database &mdash;server.disable-authentication &mdash;server.endpoint &mdash;server.password &mdash;server.request-timeout &mdash;server.ssl-protocol &mdash;server.username</h1>

<p>```</p>

<p>That has to be repeated for all binaries in the ArangoDB package (i.e. arangob, arangosh,
arangoimp, arangodump, arangorestore, and arangod).</p>

<p>As the available options might change over time, I wrote a script that extracts them
from the binaries and puts together the completions file. This script can be downloaded
<a href="/downloads/code/build-completions.sh">here</a>. The script expects the already-built ArangoDB
binaries to be located in the <code>bin</code> subdirectory. Provided that ArangoDB was compiled from
source, this should already be the case.</p>

<p>The script should then be run from the base directory:
<code>bash
build-completions.sh arangodb
</code>
This will write the completions script for all binaries into the file <code>arangodb</code>.
An already generated version for devel can be found <a href="/downloads/code/completions-devel">here</a>.
Completions for 2.3 can be found <a href="/downloads/code/completions-2.3">here</a>, the ones for 2.2
are <a href="/downloads/code/completions-2.2">here</a>.</p>

<p>To activate completions, copy the appropriate file into <code>/etc/bash_completion.d/arangodb</code>.
Note that completion may need to be re-initialized once in order to make work:
<code>bash
. /etc/bash_completion.d/arangodb
</code></p>

<h2>Quick setup</h2>

<p>The following command should install the completions for 2.3 and activate them:
```bash activate completions for ArangoDB 2.3
sudo \
  wget -O /etc/bash_completion.d/arangodb \</p>

<pre><code>https://jsteemann.github.io/downloads/code/completions-2.3 &amp;&amp; \
</code></pre>

<p>  . /etc/bash_completion.d/arangodb
```</p>

<p>The command for 2.2 is:
```bash activate completions for ArangoDB 2.2
sudo \
  wget -O /etc/bash_completion.d/arangodb \</p>

<pre><code>https://jsteemann.github.io/downloads/code/completions-2.2 &amp;&amp; \
</code></pre>

<p>  . /etc/bash_completion.d/arangodb
```</p>

<p>To see it in action, type <code>arangosh --</code> and then press <strong>TAB</strong>.</p>

<h2>Other environments (MacOS etc.)</h2>

<p><em>Note: I have checked that the above works on Ubuntu and OpenSuSE. I have no idea whether this works
with other Linux distributions let alone other shells.</em></p>

<p>Some Linux/Unix distros do not have <code>/etc/bash_completion.d</code> at all. I was told MacOS is one
of them. For such environments, downloading and sourcing the completions script should work:</p>

<p>```bash activate completion without bash_completion.d
wget -O ~/arangodb-completions-2.3 \</p>

<pre><code>https://jsteemann.github.io/downloads/code/completions-2.3
</code></pre>

<p>. ~/arangodb-completions-2.3
```</p>

<p>This will enable the completions in the current shell. To enable them permanently, add the
completions script to your <code>.bashrc</code> file:
<code>bash adding completions to .bashrc
echo ". ~/arangodb-completions-2.3" &gt;&gt; ~/.bashrc
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Travis CI for a C++11 Project]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/17/using-travis-ci-for-a-c-plus-plus-11-project/"/>
    <updated>2014-10-17T19:36:57+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/17/using-travis-ci-for-a-c-plus-plus-11-project</id>
    <content type="html"><![CDATA[<p><a href="http://travis-ci.com">TravisCI</a> is a very useful cloud service
for continous integration. It can be integrated with Github, with each
commit triggering a new build and reporting back when it broke something.</p>

<p>Travis has support for many programming languages, among them C++.
But it lacks support for C++11 features.</p>

<!-- more -->


<p>Travis provides basic support for C++ projects. <a href="http://docs.travis-ci.com/user/languages/cpp/">It comes with gcc, clang,
the autotools, make, cmake and scons</a>.</p>

<p>While writing this post, Travis CI build machines run on Ubuntu 12.04
LTS 64 bit. This version of Ubuntu is rather old already, and does not bring
too many packages for C++11 development. For example, the default
C++ compiler installed on TravisCI is g++-4.6.3. This version
doesn&rsquo;t even understand the compile option <code>-std=c++11</code>.</p>

<p>Official C++11 support <a href="https://gcc.gnu.org/projects/cxx0x.html">started in g++ 4.7</a>,
though C++0x features were supported way earlier. But to get decent C++11 support
in g++, it is best to use g++4.8 or higher.</p>

<p>Fortunately TravisCI allows installing other software. To get
a more recent C++ compiler, it can simply be added from a PPA.
This can be achieved by putting the PPA in the <code>.travis.yml</code> file of your
Github repository, e.g.</p>

<p>```yaml
language: cpp
compiler: g++</p>

<p>before_install:
&ndash; sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test
&ndash; sudo apt-get update -qq</p>

<p>install:
&ndash; sudo apt-get install -qq g++-4.8
&ndash; export CXX=&ldquo;g++-4.8&rdquo;
```</p>

<p>I have set up an <a href="https://github.com/jsteemann/travis-cxx11">example project on Github</a>
that demonstrates how to use it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Compile ArangoDB From Source]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/16/how-to-compile-arangodb-from-source/"/>
    <updated>2014-10-16T22:24:48+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/16/how-to-compile-arangodb-from-source</id>
    <content type="html"><![CDATA[<p>Though we provide a lot of pre-built packages for the stable
versions of ArangoDB <a href="https://www.arangodb.org/install">here</a>, it
is often more interesting to play with the bleeding edge development
version. New ArangoDB features are normally added to the <em>devel</em>
branch, where they can be tested, documented and improved. When a
feature matures, it is either backported to a stable branch or will
eventually be released when the next stable branch is forked from
<em>devel</em>.</p>

<p>Contributing to the core of ArangoDB is also much easier with a
ready-to-go <em>devel</em> version. This post explains how to set one up
from scratch.</p>

<!-- more -->


<p>The following instructions are for Ubuntu 14.04 LTS, which seems to
be quite popular at the moment. Other flavors of Linux are probably
quite similar, though package manager and packages names will likely
be somewhat different.</p>

<h2>Using Vagrant</h2>

<p>If you don&rsquo;t have an Ubuntu 14 installation yet, you can easily
install one using <a href="http://www.vagrantup.com">Vagrant</a>. If you happen
to have a Linux installation already and are familiar with it, just
skip this section.</p>

<p>After installing Vagrant on your system, pick a suitable Vagrant box from
<a href="http://www.vagrantbox.es">here</a>. For example, I picked this 32 bit
box from the list:</p>

<pre><code>vagrant box add ubuntu-14.04-32 https://cloud-images.ubuntu.com/vagrant/trusty/current/trusty-server-cloudimg-i386-vagrant-disk1.box
</code></pre>

<p>After downloading the box, it can be made available via these commands:</p>

<pre><code>mkdir temp
cd temp
vagrant init ubuntu-14.04-32
vagrant up
</code></pre>

<p>After the VM is booted, connect to it via SSH:</p>

<pre><code>vagrant ssh
</code></pre>

<h2>Cloning the repository</h2>

<p>You&rsquo;re now on the Ubuntu VM. Next step is fetch the ArangoDB source
code from Github. Cloning the repository from there requires <code>git</code>. Let&rsquo;s
install it and clone the <em>devel</em> branch of the repository into a
directory named <em>devel</em> on the VM:</p>

<pre><code>sudo apt-get install git 
git clone -b devel https://github.com/arangodb/arangodb.git
</code></pre>

<p>The repository contains a lot of history so cloning may take a while.
In case you don&rsquo;t need the full history, you can create a shallow
clone like this:</p>

<pre><code>git clone -b devel --single-branch --depth 1 https://github.com/arangodb/arangodb.git 
</code></pre>

<p>This will reduce the download size from (currently) 375 MB to 56 MB
and should be much faster. The downside of using a shallow copy is
that there is no history and pushing and merging won&rsquo;t work most of
the time. So it&rsquo;s better used for throw-away tests only.</p>

<h2>Installing build tools and libraries</h2>

<p>Now that the repository has been cloned into directory <em>arangodb</em>,
we can install the required tools and libraries we need to build
from source:</p>

<pre><code>sudo apt-get install automake g++ libssl-dev libreadline-dev
</code></pre>

<p>If you prefer to install a different C++ compiler, please make sure it
has proper support for C++11.</p>

<p>Go 1.2 is also required. The official list of downloadable Go
versions can be found <a href="https://golang.org/dl/">here</a>. In the example,
I am using the 32 bit version in this example:</p>

<pre><code>wget https://storage.googleapis.com/golang/go1.2.2.linux-386.tar.gz
sudo tar -C /usr/local -xzf go1.2.2.linux-386.tar.gz
export PATH=$PATH:/usr/local/go/bin
echo "export PATH=\$PATH:/usr/local/go/bin" &gt;&gt; $HOME/.profile
</code></pre>

<h2>Compiling ArangoDB</h2>

<p>With all prerequisites set up, it&rsquo;s now time to compile ArangoDB.</p>

<p>You probably noticed that no <code>configure</code> file is shipped with ArangoDB
in the <code>devel</code> branch. To create it, we need to execute <code>make setup</code>
once. After that, <code>configure</code> can be executed to create the <code>Makefile</code>.
The <code>Makefile</code> finally contains the stuff that <code>make</code> needs:</p>

<pre><code>make setup
./configure --enable-relative 
make
</code></pre>

<p>There first <code>make</code> run will take a while as it will compile all support
libraries (ICU, V8, libev, zlib) before it will actually compile ArangoDB.
Further invocations of <code>make</code> will not build these libraries again.
Only any changed code will be rebuilt.</p>

<p>Note that <code>make</code> can be parallelized if you have multiple processors
available. For 4 parallel <code>make</code> processes, use <code>make -j4</code>.</p>

<p><code>make</code> will produce a lot of output. The most important information, whether
or not an error occurred, can be found in its last line of its output. If
it does <strong>not</strong> say something like this, <code>make</code> has probably succeeded:</p>

<pre><code>make: *** [all] Error 2
</code></pre>

<p>You can also execute the following command directly after <code>make</code> to check
the exit status of the <code>make</code> process:</p>

<pre><code>echo $?
</code></pre>

<p>This will print <code>0</code> if <code>make</code> was successful, and a non-zero value otherwise.</p>

<h2>Starting ArangoDB</h2>

<p>When finished, <code>make</code> should have created all binaries in the <code>bin</code>
subdirectory. We can now start <code>arangod</code> and the binaries directly from
there without running a <code>make install</code>. In fact, <code>make install</code> is
awkward to do if you do many change-compile-test cycles.</p>

<pre><code>mkdir data          # creates a data directory
bin/arangod data    # starts the server
</code></pre>

<p>The server will be started as a foreground process (which is ideal
when developing the server). To stop the server, simply press CTRL-C.</p>

<h2>Connecting to ArangoDB</h2>

<p>To verify ArangoDB is actually working, open a separate terminal and
connect to it with the ArangoShell.</p>

<p>Note that if you used Vagrant, you will first need to connect to the
Vagrant box in the other terminal using <code>vagrant ssh</code> from the directory
you ran the <code>vagrant init</code> in. When connect to the Vagrant box, don&rsquo;t
forget to switch into the <code>arangodb</code> directory.</p>

<p>Once you&rsquo;re in the correct directory, just issue this:</p>

<pre><code>bin/arangosh
</code></pre>

<p>This should bring up the ArangoShell connected to your devel ArangoDB
instance.</p>

<h2>Making changes</h2>

<p>Time to make some changes in the code. A good place to start is usually
<code>main</code>. Here are a few places to get you started:</p>

<pre><code>~/arangodb$ grep -r "int main" arangod/ arangosh/
arangod/RestServer/arangod.cpp:int main (int argc, char* argv[]) {
arangosh/Benchmark/arangob.cpp:int main (int argc, char* argv[]) {
arangosh/V8Client/arangorestore.cpp:int main (int argc, char* argv[]) {
arangosh/V8Client/arangodump.cpp:int main (int argc, char* argv[]) {
arangosh/V8Client/arangoimp.cpp:int main (int argc, char* argv[]) {
arangosh/V8Client/arangosh.cpp:int main (int argc, char* argv[]) {
</code></pre>

<p>Once you&rsquo;re done with your changes, you need to re-compile and run:</p>

<pre><code>make
bin/arangod data
</code></pre>

<p>Don&rsquo;t worry, <code>make</code> will only recompile what you changed plus what
depends on it and finally link it all together. This won&rsquo;t take as long
as on the previous run.</p>

<p>If you are serious about contributing to the server code, please let us
know <a href="https://groups.google.com/forum/#!forum/arangodb">here</a> so we can assist you.</p>

<h2>Getting updates</h2>

<p>We keep developing ArangoDB! To keep up to date and retrieve the latest
changes from our repository, issue the following commands:</p>

<pre><code>git pull origin devel
make
</code></pre>

<p>If <code>make</code> complains about files not found etc., the <code>Makefile</code> may have
changed. Then it&rsquo;s time for a cleanup:</p>

<pre><code>make clean
make setup
./configure --enable-relative 
make
</code></pre>

<p>By the way, if you used special configure options and forgot them, you
can retrieve your previous options by typing <code>head config.log</code>.
Note: as of December 2014 (ArangoDB 2.4), most configure options starting
with <code>--enable-all-in-one-</code> have been removed. If your <code>config.log</code> still
contains them, you can safely omit them in any future invocations of
<code>configure</code>.</p>

<p>Sometimes <code>make clean</code> isn&rsquo;t enough. <code>make</code> creates cache files for the
object files, and if they are too outdated, it will complain about files which
have been renamed already etc. In this case, you can forcefully delete its
caches by running an additional</p>

<pre><code>make superclean
</code></pre>

<p>This also cleans already built libraries in the 3rdParty directory. It
also removes the <code>configure</code> file, so after <code>make superclean</code> everything
will need to be built from again. This may take a long time, so you should
only run <code>make superclean</code> if after a <code>make clean</code> run there are still linker
errors or complaints about missing files.</p>

<h2>Debugging</h2>

<p>If you are making changes in the ArangoDB C++ code and want to test them,
it will be sensible to install debugging tools such as <em>gdb</em> and <em>valgrind</em>:</p>

<pre><code>sudo apt-get install gdb valgrind   
</code></pre>

<p>Additionally, you may want to enable core files. This can be done by executing</p>

<pre><code>ulimit -c unlimited
</code></pre>

<p>in the shell, and by putting the above line in your home directory&rsquo;s <code>.bashrc</code>
file to make it a permanent setting.</p>

<p>Additionally, you may want to set environment variables in your <code>.bashrc</code> that
control compilation options. For development, I&rsquo;d recommend using the following
options:</p>

<pre><code>export CFLAGS="-g -O0"
export CXXFLAGS="-g -O0"
</code></pre>

<p>This will turn off all optimizations and also generate debug symbols.</p>

<p>Enjoy!</p>
]]></content>
  </entry>
  
</feed>
