<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Linux | J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2016-06-22T18:19:35+02:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How Much Memory Does an STL Container Use?]]></title>
    <link href="http://jsteemann.github.io/blog/2016/06/14/how-much-memory-does-an-stl-container-use/"/>
    <updated>2016-06-14T00:35:29+02:00</updated>
    <id>http://jsteemann.github.io/blog/2016/06/14/how-much-memory-does-an-stl-container-use</id>
    <content type="html"><![CDATA[<p>Ever wondered how much heap memory will be used by STL containers, and
in what chunks they will allocate it?</p>

<p>Here is the answer for some frequently used containers types containing
uint64_t values (an 8 byte type). For the associative containers I also
used uint64_t as the key type.</p>

<!-- more -->


<p>All results are for the STL implementation I had ready at hand (g++5.3 on
Ubuntu 16.04, x86_64, libstdc++.so.6.0.22, with default allocator).
The results may be completely different for other platforms and/or other
data types.</p>

<p>The following containers are compared:</p>

<ul>
<li>std::vector&lt;uint64_t></li>
<li>std::map&lt;uint64, uint64_t></li>
<li>std::set&lt;uint64_t></li>
<li>std::unordered_map&lt;uint64, uint64_t></li>
<li>std::unordered_set&lt;uint64_t></li>
<li>std::deque&lt;uint64_t></li>
</ul>


<p>The containers themselves are creared on the stack. To store the elements,
the containers will need to use heap memory. The number of elements in the
containers (<em>n</em>) is increased exponentially from 0 (empty) to 512 in the
tests. The memory usage pattern should be quite clear by then.</p>

<p>Reported are the amount of heap memory allocated by the container after all
elements have been inserted, the total number of heap memory allocated by
the container during its whole lifetime (i.e. the sum of all its <code>malloc</code>s),
plus the number of calls to <code>malloc</code> and <code>free</code> the container issued.</p>

<p>```plain heap allocation results</p>

<h2>n =     0</h2>

<p>vector         =>     0 bytes allocd at end,  total:     0 bytes mallocd,    0 malloc(s), 0 free(s)
map            =>     0 bytes allocd at end,  total:     0 bytes mallocd,    0 malloc(s), 0 free(s)
set            =>     0 bytes allocd at end,  total:     0 bytes mallocd,    0 malloc(s), 0 free(s)
unordered_map  =>     0 bytes allocd at end,  total:     0 bytes mallocd,    0 malloc(s), 0 free(s)
unordered_set  =>     0 bytes allocd at end,  total:     0 bytes mallocd,    0 malloc(s), 0 free(s)
deque          =>   576 bytes allocd at end,  total:   576 bytes mallocd,    2 malloc(s), 0 free(s)</p>

<h2>n =     1</h2>

<p>vector         =>     8 bytes allocd at end,  total:     8 bytes mallocd,    1 malloc(s), 0 free(s)
map            =>    48 bytes allocd at end,  total:    48 bytes mallocd,    1 malloc(s), 0 free(s)
set            =>    40 bytes allocd at end,  total:    40 bytes mallocd,    1 malloc(s), 0 free(s)
unordered_map  =>    40 bytes allocd at end,  total:    40 bytes mallocd,    2 malloc(s), 0 free(s)
unordered_set  =>    32 bytes allocd at end,  total:    32 bytes mallocd,    2 malloc(s), 0 free(s)
deque          =>   576 bytes allocd at end,  total:   576 bytes mallocd,    2 malloc(s), 0 free(s)</p>

<h2>n =     2</h2>

<p>vector         =>    16 bytes allocd at end,  total:    24 bytes mallocd,    2 malloc(s), 1 free(s)
map            =>    96 bytes allocd at end,  total:    96 bytes mallocd,    2 malloc(s), 0 free(s)
set            =>    80 bytes allocd at end,  total:    80 bytes mallocd,    2 malloc(s), 0 free(s)
unordered_map  =>    88 bytes allocd at end,  total:   104 bytes mallocd,    4 malloc(s), 1 free(s)
unordered_set  =>    72 bytes allocd at end,  total:    88 bytes mallocd,    4 malloc(s), 1 free(s)
deque          =>   576 bytes allocd at end,  total:   576 bytes mallocd,    2 malloc(s), 0 free(s)</p>

<h2>n =     4</h2>

<p>vector         =>    32 bytes allocd at end,  total:    56 bytes mallocd,    3 malloc(s), 2 free(s)
map            =>   192 bytes allocd at end,  total:   192 bytes mallocd,    4 malloc(s), 0 free(s)
set            =>   160 bytes allocd at end,  total:   160 bytes mallocd,    4 malloc(s), 0 free(s)
unordered_map  =>   136 bytes allocd at end,  total:   152 bytes mallocd,    6 malloc(s), 1 free(s)
unordered_set  =>   104 bytes allocd at end,  total:   120 bytes mallocd,    6 malloc(s), 1 free(s)
deque          =>   576 bytes allocd at end,  total:   576 bytes mallocd,    2 malloc(s), 0 free(s)</p>

<h2>n =     8</h2>

<p>vector         =>    64 bytes allocd at end,  total:   120 bytes mallocd,    4 malloc(s), 3 free(s)
map            =>   384 bytes allocd at end,  total:   384 bytes mallocd,    8 malloc(s), 0 free(s)
set            =>   320 bytes allocd at end,  total:   320 bytes mallocd,    8 malloc(s), 0 free(s)
unordered_map  =>   280 bytes allocd at end,  total:   336 bytes mallocd,   11 malloc(s), 2 free(s)
unordered_set  =>   216 bytes allocd at end,  total:   272 bytes mallocd,   11 malloc(s), 2 free(s)
deque          =>   576 bytes allocd at end,  total:   576 bytes mallocd,    2 malloc(s), 0 free(s)</p>

<h2>n =    16</h2>

<p>vector         =>   128 bytes allocd at end,  total:   248 bytes mallocd,    5 malloc(s), 4 free(s)
map            =>   768 bytes allocd at end,  total:   768 bytes mallocd,   16 malloc(s), 0 free(s)
set            =>   640 bytes allocd at end,  total:   640 bytes mallocd,   16 malloc(s), 0 free(s)
unordered_map  =>   568 bytes allocd at end,  total:   712 bytes mallocd,   20 malloc(s), 3 free(s)
unordered_set  =>   440 bytes allocd at end,  total:   584 bytes mallocd,   20 malloc(s), 3 free(s)
deque          =>   576 bytes allocd at end,  total:   576 bytes mallocd,    2 malloc(s), 0 free(s)</p>

<h2>n =    32</h2>

<p>vector         =>   256 bytes allocd at end,  total:   504 bytes mallocd,    6 malloc(s), 5 free(s)
map            =>  1536 bytes allocd at end,  total:  1536 bytes mallocd,   32 malloc(s), 0 free(s)
set            =>  1280 bytes allocd at end,  total:  1280 bytes mallocd,   32 malloc(s), 0 free(s)
unordered_map  =>  1144 bytes allocd at end,  total:  1472 bytes mallocd,   37 malloc(s), 4 free(s)
unordered_set  =>   888 bytes allocd at end,  total:  1216 bytes mallocd,   37 malloc(s), 4 free(s)
deque          =>   576 bytes allocd at end,  total:   576 bytes mallocd,    2 malloc(s), 0 free(s)</p>

<h2>n =    64</h2>

<p>vector         =>   512 bytes allocd at end,  total:  1016 bytes mallocd,    7 malloc(s), 6 free(s)
map            =>  3072 bytes allocd at end,  total:  3072 bytes mallocd,   64 malloc(s), 0 free(s)
set            =>  2560 bytes allocd at end,  total:  2560 bytes mallocd,   64 malloc(s), 0 free(s)
unordered_map  =>  2312 bytes allocd at end,  total:  3016 bytes mallocd,   70 malloc(s), 5 free(s)
unordered_set  =>  1800 bytes allocd at end,  total:  2504 bytes mallocd,   70 malloc(s), 5 free(s)
deque          =>  1088 bytes allocd at end,  total:  1088 bytes mallocd,    3 malloc(s), 0 free(s)</p>

<h2>n =   128</h2>

<p>vector         =>  1024 bytes allocd at end,  total:  2040 bytes mallocd,    8 malloc(s), 7 free(s)
map            =>  6144 bytes allocd at end,  total:  6144 bytes mallocd,  128 malloc(s), 0 free(s)
set            =>  5120 bytes allocd at end,  total:  5120 bytes mallocd,  128 malloc(s), 0 free(s)
unordered_map  =>  4664 bytes allocd at end,  total:  6144 bytes mallocd,  135 malloc(s), 6 free(s)
unordered_set  =>  3640 bytes allocd at end,  total:  5120 bytes mallocd,  135 malloc(s), 6 free(s)
deque          =>  1600 bytes allocd at end,  total:  1600 bytes mallocd,    4 malloc(s), 0 free(s)</p>

<h2>n =   256</h2>

<p>vector         =>  2048 bytes allocd at end,  total:  4088 bytes mallocd,    9 malloc(s), 8 free(s)
map            => 12288 bytes allocd at end,  total: 12288 bytes mallocd,  256 malloc(s), 0 free(s)
set            => 10240 bytes allocd at end,  total: 10240 bytes mallocd,  256 malloc(s), 0 free(s)
unordered_map  =>  9416 bytes allocd at end,  total: 12488 bytes mallocd,  264 malloc(s), 7 free(s)
unordered_set  =>  7368 bytes allocd at end,  total: 10440 bytes mallocd,  264 malloc(s), 7 free(s)
deque          =>  2624 bytes allocd at end,  total:  2624 bytes mallocd,    6 malloc(s), 0 free(s)</p>

<h2>n =   512</h2>

<p>vector         =>  4096 bytes allocd at end,  total:  8184 bytes mallocd,   10 malloc(s), 9 free(s)
map            => 24576 bytes allocd at end,  total: 24576 bytes mallocd,  512 malloc(s), 0 free(s)
set            => 20480 bytes allocd at end,  total: 20480 bytes mallocd,  512 malloc(s), 0 free(s)
unordered_map  => 18872 bytes allocd at end,  total: 25216 bytes mallocd,  521 malloc(s), 8 free(s)
unordered_set  => 14776 bytes allocd at end,  total: 21120 bytes mallocd,  521 malloc(s), 8 free(s)
deque          =>  4752 bytes allocd at end,  total:  4816 bytes mallocd,   11 malloc(s), 1 free(s)
```</p>

<p>I have intentionally not done any optimizations such as calling <code>reserve()</code>
on the containers before inserting the individual elements, in order to
reflect some real-word scenarios in which it is unclear how much elements
will be added to the containers during program execution.</p>

<p>The test program for reproduction is <a href="/downloads/code/containers.cpp">here</a>. Compile and run it with:</p>

<p><code>bash compiling and executing the test program
g++ -std=c++11 -O0 containers.cpp -o containers
for i in 0 1 2 4 8 16 32 64 128 256 512; do ./containers "$i"; done
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Compiling an Optimized Version of ArangoDB]]></title>
    <link href="http://jsteemann.github.io/blog/2016/06/09/compiling-an-optimized-version-of-arangodb/"/>
    <updated>2016-06-09T20:31:31+02:00</updated>
    <id>http://jsteemann.github.io/blog/2016/06/09/compiling-an-optimized-version-of-arangodb</id>
    <content type="html"><![CDATA[<p>Why should you care about compiling ArangoDB on your own when there are
official release packages that are ready to use?</p>

<!--more -->


<p>There are three main reasons for compiling on your own:</p>

<ul>
<li><p>as a developer you want to <em>make changes to the ArangoDB C++ source code</em>.
Then your only option obviously is to compile on your own. Please consult
the <a href="/blog/2016/06/09/compiling-a-debug-version-of-arangodb/">compiling a debug version of ArangoDB</a>
page for more information.</p></li>
<li><p>you are trying to <em>get meaningful stack traces from core dumps</em> produced
by ArangoDB and need an ArangoDB binary that comes with enough debug
information (debug symbols, probably also assertions turned on). In this
case, please also consult the <a href="/blog/2016/06/09/compiling-a-debug-version-of-arangodb/">compiling a debug version of ArangoDB</a>
blog post for how to get this done.</p></li>
<li><p>you want to use an ArangoDB binary that is <em>optimized for your specific
target architecture</em>.</p></li>
</ul>


<p>The latter reason is relevant because the official release packages that
are provided by ArangoDB cannot make too many assumptions about the environment
in which they will be used. In the general release packages there is not so
much room for platform-specific optimizations as there would be if you are
compiling just for the local machine.</p>

<p>For example, all relevant CPU offer <a href="https://en.wikipedia.org/wiki/SIMD">SIMD</a>
instructions that a compiler can exploit when generating code. But different
generations of CPUs offer different levels of SIMD instructions. Not every CPU
in use today provides SSE4, not to talk about AVX.</p>

<p>To make our release packages compatible with most environments, we have had
to make some conservative assumptions about the CPU abilities, which effectively
disables many optimizations that would have been possible when creating a
build that only needs to run on a specific architecture.</p>

<p>To fully exploit the capabilities of a specific target environment, it&rsquo;s required
to build executables for that specific architecture. Most compilers offer an option
<code>-march</code> for that. You normally want to set this to <code>native</code> when compiling an
optimized version. There are also lots of compiler options for enabling or disabling
specific CPU features such as <code>-msse</code>, <code>-msse2</code>, <code>-msse3</code>, <code>-mssse3</code>,
<code>-msse4.1</code>, <code>-msse4.2</code>, <code>-msse4</code>, <code>-mavx</code>, <code>-mavx2</code>, to name just a few.</p>

<p>The good news is that there is no need to deal with such compiler-specific optimization
options in order to get an optimized build. The cmake-based ArangoDB 3.0 builds will
automatically test the local environment&rsquo;s capabilities and set the compiler options
based on which CPU abilities were detected.</p>

<p>For example, a mere <code>(cd build &amp;&amp; cmake -DCMAKE_BUILD_TYPE=Release ..)</code> will run the
CPU ability detection and configure the build to use the features supported by the
local architecture:</p>

<p><code>bash configuring a release build
(mkdir -p build; cd build &amp;&amp; cmake -DCMAKE_BUILD_TYPE=Release ..)
</code></p>

<p>For example, on my laptop this prints:
<code>plain cmake output
-- The CXX compiler identification is GNU 5.3.1
-- The C compiler identification is GNU 5.3.1
...
-- target changed from "" to "auto"
-- Detected CPU: haswell
-- Performing Test check_cxx_compiler_flag__march_core_avx2
-- Performing Test check_cxx_compiler_flag__march_core_avx2 - Success
-- Performing Test check_cxx_compiler_flag__msse2
-- Performing Test check_cxx_compiler_flag__msse2 - Success
-- Performing Test check_cxx_compiler_flag__msse3
-- Performing Test check_cxx_compiler_flag__msse3 - Success
-- Looking for pmmintrin.h
-- Looking for pmmintrin.h - found
-- Performing Test check_cxx_compiler_flag__mssse3
-- Performing Test check_cxx_compiler_flag__mssse3 - Success
-- Looking for tmmintrin.h
-- Looking for tmmintrin.h - found
-- Performing Test check_cxx_compiler_flag__msse4_1
-- Performing Test check_cxx_compiler_flag__msse4_1 - Success
-- Looking for smmintrin.h
-- Looking for smmintrin.h - found
-- Performing Test check_cxx_compiler_flag__msse4_2
-- Performing Test check_cxx_compiler_flag__msse4_2 - Success
-- Performing Test check_cxx_compiler_flag__mavx
-- Performing Test check_cxx_compiler_flag__mavx - Success
-- Looking for immintrin.h
-- Looking for immintrin.h - found
-- Performing Test check_cxx_compiler_flag__msse2avx
-- Performing Test check_cxx_compiler_flag__msse2avx - Success
-- Performing Test check_cxx_compiler_flag__mavx2
-- Performing Test check_cxx_compiler_flag__mavx2 - Success
-- Performing Test check_cxx_compiler_flag__mno_sse4a
-- Performing Test check_cxx_compiler_flag__mno_sse4a - Success
-- Performing Test check_cxx_compiler_flag__mno_xop
-- Performing Test check_cxx_compiler_flag__mno_xop - Success
-- Performing Test check_cxx_compiler_flag__mno_fma4
-- Performing Test check_cxx_compiler_flag__mno_fma4 - Success
...
</code>
The detected options will end up in the CMakeCache.txt file in the build
directory. The Makefile generated by cmake will automatically make use of
these options when invoking the C++ compiler.</p>

<p>The compiler options are not shown by default, but they can be made visible
by compiling with the option <code>VERBOSE=1</code>, e.g.</p>

<p><code>bash configuring and compiling a build
(mkdir -p build; cd build &amp;&amp; cmake -DCMAKE_BUILD_TYPE=Release ..)
(cd build &amp;&amp; make -j4 VERBOSE=1)
</code></p>

<p>Note that this will be <em>very verbose</em>, so you only want to set the <code>VERBOSE=1</code>
option to check that the compiler options were picked correctly.</p>

<p>On my local laptop, the architecture-specific compiler options that were automatically
detected and used were</p>

<p><code>bash compiler architecture options used
-march=core-avx2 -msse2 -msse3 -mssse3 -msse4.1 -msse4.2 -mavx -msse2avx -mavx2 -mno-sse4a -mno-xop -mno-fma4
</code></p>

<p>The build has detected <code>core-avx2</code>, which in my case is good &ndash; and a lot more
specific than the official packages which for example cannot assume the presence
of either SSE4 or AVX instructions.</p>

<p>And now that we can rely on the presence of specific CPU instructions, some code
parts such as JSON parsing can make use of SSE4.2 instructions, or the compiler
can use some optimized SIMD variants for operations such as memcpy, strlen etc.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using the Address Sanitizer (ASAN) in ArangoDB Development]]></title>
    <link href="http://jsteemann.github.io/blog/2016/06/09/using-the-address-sanitizer-asan-in-arangodb-development/"/>
    <updated>2016-06-09T20:07:29+02:00</updated>
    <id>http://jsteemann.github.io/blog/2016/06/09/using-the-address-sanitizer-asan-in-arangodb-development</id>
    <content type="html"><![CDATA[<p>Once you have set up a <a href="/blog/2016/06/09/compiling-a-debug-version-of-arangodb/">debug version of ArangoDB</a>,
it is quite helpful to also enable the <a href="https://en.wikipedia.org/wiki/AddressSanitizer">Address Sanitizer</a>
and its companion tools.</p>

<p>These sanitizers provide runtime instrumentation for executables and check
for common C++ programming errors such as buffer overflows, use-after-free
bugs and memory leaks. The sanitizers supported natively by recent versions
of g++ and clang++.</p>

<p>The general runtime overhead of the sanitizers is neglectable compared to
other instrumentation tools such as Valgrind, so it can well be used in the
day-to-day development process.</p>

<!-- more -->


<h2>Configuring the build to use ASAN</h2>

<p>To build with ASAN (Address Sanitizer) and UBSAN (Undefined Behavior Sanitizer),
the following environment variables need to be set when invoking cmake:</p>

<p><code>bash environment variables for ASAN and UBSAN
CXXFLAGS="-fsanitize=address -fsanitize=undefined -fno-sanitize=alignment -fno-sanitize=vptr"
</code></p>

<p>The full command to configure a debug build with ASAN and UBSAN support is:</p>

<p><code>bash configuring the build to use the sanitizers
(cd build &amp;&amp; CXXFLAGS="-fsanitize=address -fsanitize=undefined -fno-sanitize=alignment -fno-sanitize=vptr cmake -DCMAKE_BUILD_TYPE=Debug -DUSE_MAINTAINER_MODE=On ..)
</code></p>

<p>This will configure the build so it will pass the sanitizer options to the C++
compiler. Note that you&rsquo;ll need a recent version of g++ or clang++ for this
to work.</p>

<p>After that, build arangod normally. The binaries produced will be instrumented
by the sanitizers, allowing many nasty memory errors to be detected very early.</p>

<h2>Checking if an arangod binary is using ASAN</h2>

<p>Whether or not an ArangoDB binary is instrumented can be found out at any
time by calling the binary with the <code>--version</code> option. This will print some
version information for ArangoDB itself and the other required libraries,
and it will also print in the line starting with <code>asan</code> whether the binary
was compiled with ASAN support or not:</p>

<p>```bash checking the ASAN support of an arangod binary</p>

<blockquote><p>build/bin/arangod &mdash;version</p></blockquote>

<p>3.0.x-devel</p>

<p>architecture: 64bit
asan: true                       # !!!!
asm-crc32: true
boost-version: 1.61.0b1
build-date: 2016-06-09 12:07:07
compiler: gcc
cplusplus: 201103
endianness: little
fd-client-event-handler: poll
fd-setsize: 1024
icu-version: 54.1
jemalloc: false
libev-version: 4.22
maintainer-mode: true
openssl-version: OpenSSL 1.0.2g-fips  1 Mar 2016
rocksdb-version: 4.8.0
server-version: 3.0.x-devel
sizeof int: 4
sizeof void*: 8
sse42: true
tcmalloc: false
v8-version: 5.0.71.39
vpack-version: 0.1.30
zlib-version: 1.2.8
```</p>

<h2>Controlling ASAN runtime behavior</h2>

<p>ASAN behavior can also be controlled at runtime, after the binaries have
been produced, by adjusting the environment variable <code>ASAN_OPTIONS</code>.
The setting I use for this is:</p>

<p><code>bash adjusting ASAN options
ASAN_OPTIONS="handle_ioctl=true:check_initialization_order=true:detect_container_overflow=1:detect_stack_use_after_return=false:detect_odr_violation=1:allow_addr2line=true:strict_init_order=true"
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Compiling a Debug Version of ArangoDB]]></title>
    <link href="http://jsteemann.github.io/blog/2016/06/09/compiling-a-debug-version-of-arangodb/"/>
    <updated>2016-06-09T20:07:29+02:00</updated>
    <id>http://jsteemann.github.io/blog/2016/06/09/compiling-a-debug-version-of-arangodb</id>
    <content type="html"><![CDATA[<p>Compiling a debug version of ArangoDB is a must for everyone that
wants to modify the C++ ArangoDB source code and test their changes
locally.</p>

<p>How to do this is different in the 2.8 and 3.0 branches of ArangoDB,
but luckily it&rsquo;s really easy to achieve in both branches.</p>

<!-- more -->


<h2>ArangoDB 2.8</h2>

<p>For the 2.8 branch of ArangoDB, clone the 2.8 version of the ArangoDB
repository first:</p>

<p><code>bash cloning the 2.8 repository
git clone -b 2.8 https://github.com/arangodb/arangodb
cd ArangoDB
</code></p>

<p>And in that directory execute the following commands:</p>

<p><code>bash compiling a debug version of 2.8
make setup
export CFLAGS="-g -Og"
export CXXFLAGS="-g -Og"
./configure --enable-relative --enable-maintainer-mode
make -j4
</code></p>

<p>(note that you&rsquo;ll need a working C++11 compiler and some prerequisites
such as the OpenSSL library, GNU Bison and Flex installed for this to work).</p>

<p>This will compile ArangoDB and all of its dependencies, and finally
make them available in the <code>bin</code> subdirectory of the current directory.
There is no need to install ArangoDB using <code>make install</code>. arangod and
the client tools can be run locally using the following commands:</p>

<p><code>bash running arangod and arangosh
bin/arangod --console mydb # start arangod in console mode
bin/arangosh # starts an ArangoShell
</code></p>

<p>Now, after any modification to the ArangoDB C++ source code you can re-compile
using <code>make</code>. This will only rebuild the things that need to be rebuilt. If the
build is successful, the changes you have made should be visible when restarting
the binaries.</p>

<p>As the <code>-g</code> option used above will have configured a build with debug
symbols, it&rsquo;s also possible to use a debugger such as gdb for stepping
through the executables, attach to the while they are running, or to
obtain stack traces in case any of the executables crashed.</p>

<h2>ArangoDB 3.0</h2>

<p>For the 3.0 branch of ArangoDB, it&rsquo;s required to once clone that version
of the ArangoDB repository into a local directory:</p>

<p><code>bash cloning the 3.0 repository
git clone -b 3.0 https://github.com/arangodb/arangodb
cd ArangoDB
</code></p>

<p>In that directory execute the following commands to configure the build
for debugging:</p>

<p><code>bash configuring a debug version of 3.0
(mkdir -p build; cd build &amp;&amp; cmake -DCMAKE_BUILD_TYPE=Debug -DUSE_MAINTAINER_MODE=On ..)
</code></p>

<p>(again you&rsquo;ll need a working C++11 compiler and some prerequisites
such as the OpenSSL library installed for this to work).</p>

<p>This will configure the build to be a debug build, with debug symbols
but most optimizations disabled. To build ArangoDB, just execute:</p>

<p><code>bash compiling a debug version of 3.0
(cd build &amp;&amp; make -j4)
</code></p>

<p>To execute one of the binaries, run them from the checkout directory
as follows:</p>

<p><code>bash running arangod and arangosh
build/bin/arangod --console mydb # start arangod in console mode
build/bin/arangosh # starts an ArangoShell
</code></p>

<p>After any modification to the ArangoDB C++ source code, build again
using <code>(cd build &amp;&amp; make -j4)</code> to see the changes in effect.
The build is a debug build, meaning you can use a debugger and get
meaningful stack traces for core dumps produced by the binaries.</p>

<p>If you got, then I strongly recommend to also enable the
<a href="https://en.wikipedia.org/wiki/AddressSanitizer">Address Sanitizer</a>
(ASAN) for your debug build. This can greatly help finding common memory usage
errors during development. There is another<br/>
<a href="/blog/2016/06/09/using-the-address-sanitizer-asan-in-arangodb-development/">blog post about using ASAN in ArangoDB development</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Compiling ArangoDB 3.0 on Ubuntu]]></title>
    <link href="http://jsteemann.github.io/blog/2016/06/02/compiling-arangodb-3-dot-0-on-ubuntu/"/>
    <updated>2016-06-02T20:15:01+02:00</updated>
    <id>http://jsteemann.github.io/blog/2016/06/02/compiling-arangodb-3-dot-0-on-ubuntu</id>
    <content type="html"><![CDATA[<p>We have spent a lot of time working on ArangoDB 3.0. That
version will not only provide major functionality and performance
improvements, but will also come with an improved, CMake-based
build system.</p>

<p>This post explains how to use CMake to build ArangoDB 3.0 on a recent
Ubuntu Linux. For the impatient there&rsquo;s a command summary at the end of
this post.</p>

<!-- more -->


<h2>Installing prerequisites</h2>

<p>Here&rsquo;s how to build ArangoDB 3.0 with cmake on a recent Ubuntu Linux.</p>

<p>Ubuntu 15.x and 16.x should have recent enough packages so any missing
prerequisites can be installed via a simple <code>sudo apt-get install</code> command:</p>

<p><code>bash installing prerequisites
sudo apt-get install cmake make build-essential openssl python2.7 g++ gcc
</code></p>

<p>Older versions of Ubuntu can be convinced to work too, but this requires
a g++ version of at least 4.9. Ubuntu 14 ships with older g++
versions by default, so you will first need to install a newer g++ version
(see <a href="http://askubuntu.com/questions/466651/how-do-i-use-the-latest-gcc-on-ubuntu-14-04">here</a> or
<a href="http://askubuntu.com/questions/428198/getting-installing-gcc-g-4-9-on-ubuntu">here</a> for
some external instructions). Once the g++ and gcc compilers are recent enough,
install the other prerequisites.</p>

<h2>Cloning ArangoDB</h2>

<p>After having installed the prerequisites, clone the ArangoDB repository
from Github and then cd into the directory <code>arangodb</code> that the cloning
will have created:</p>

<p><code>bash cloning ArangoDB
git clone https://github.com/arangodb/arangodb
cd arangodb
</code></p>

<p>Then check out the 3.0 branch and pull the latest changes:
<code>bash cloning ArangoDB
git checkout 3.0
git pull
</code></p>

<h2>Building ArangoDB</h2>

<p>A convention when using CMake is to not build directly in the source
directory, but use a separate build directory instead. The benefit of
this is that building in a separate directory won&rsquo;t change the source
directory, and the build directory can be disposed easily.</p>

<p>To create an initial build directory named <code>build</code> and cd into it,
just type:</p>

<p><code>bash creating a build directory
mkdir -p build
cd build
</code></p>

<p>It&rsquo;s now time to invoke CMake. CMake should be executed from the build
directory, but needs to know where it&rsquo;s build instructions file
(named <code>CMakeLists.txt</code> is). This file is located in the source directory.
To run CMake without any specific options, we can use:</p>

<p><code>bash running CMake
cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo ..
</code></p>

<p>This will run CMake from inside the <code>build</code> directory and tell it to
look for <code>CMakeLists.txt</code> in the source directory. The
<code>-DCMAKE_BUILD_TYPE=RelWithDebInfo</code> part will tell CMake to build
binaries with optimizations and debug symbols. Other useful build
types are:</p>

<ul>
<li><code>-DCMAKE_BUILD_TYPE=Debug</code>: without optimizations, for debugging only</li>
<li><code>-DCMAKE_BUILD_TYPE=Release</code>: with optimizations, no debug symbols,
not useful for debugging</li>
</ul>


<p>Invoking CMake will perform some checks for required components, compiler
and platform features. If anything fails, it should print some error
message. If everything works well, the command should have created a
<code>Makefile</code> in the <code>build</code> directory.</p>

<p><em>side note: CMake on Linux will by default generate UNIX <code>Makefile</code>s,
but it can also be told to generate <a href="https://ninja-build.org/">ninja</a>
files instead. On Windows it can generate solution files for Visual
Studio.</em></p>

<p>Now that the <code>Makefile</code> is there, we can run <code>make</code> as usual (note that
the <code>-j4</code> means to build with 4 parallel processes &ndash; adjust as needed!):</p>

<p><code>bash running make
make -j4
</code></p>

<h2>Starting arangod and arangosh</h2>

<p>And that&rsquo;s already it for a normal build. Note that the build artefacts
and thus the binaries will also be created inside the <code>build</code> directory.
<code>arangod</code> and <code>arangosh</code> will be located in the <code>bin</code> subdirectory of
the <code>build</code> directory. There is no need to install these binaries, they
can be run without installing them first. However, starting them from
inside the build directory will not work, because they will complain
about missing files. It is better to cd one level up first and then
start them:</p>

<p><code>bash starting arangod
cd ..
build/bin/arangod ~/testdata --server.authentication false
</code></p>

<p>The former will start arangod with default configuration, with a fresh
database directory located in <code>~/testdata</code>.</p>

<p>If you ran all the commands on your local machine (127.0.0.1) then you
can now open a browser and point it to <a href="http://127.0.0.1:8529/">http://127.0.0.1:8529/</a>.
This should bring up ArangoDB&rsquo;s web interface.</p>

<p>You can alternatively start an ArangoShell to connect to the ArangoDB
server. In another terminal window, cd into the <code>arangodb</code> directory and
start an ArangoShell as follows:</p>

<p><code>bash starting arangosh
cd arangodb
build/bin/arangosh
</code></p>

<p>You should now see the ArangoShell prompt and be able to type some
commands!</p>

<h2>Command summary</h2>

<p>Note: in contrast to the above step-by-step instructions, some commands
here have been put together on a single line to make developer&rsquo;s life
easier.</p>

<p><code>bash installing prerequisites
sudo apt-get install cmake make build-essential openssl python2.7 g++ gcc
</code></p>

<p><code>bash initial checkout of the 3.0 branch and build configuration
git clone https://github.com/arangodb/arangodb
cd arangodb
git checkout 3.0
git pull
mkdir -p build
(cd build &amp;&amp; cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo ..)
</code></p>

<p><code>bash Update, build and run cycle
git pull
(cd build &amp;&amp; make -j4)
build/bin/arangod ~/testdata --server.authentication false
</code></p>
]]></content>
  </entry>
  
</feed>
