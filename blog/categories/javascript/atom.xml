<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: JavaScript | J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/blog/categories/javascript/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2014-11-08T02:16:58+01:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Handling Binary Data in Foxx]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/15/handling-binary-data-in-foxx/"/>
    <updated>2014-10-15T20:41:30+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/15/handling-binary-data-in-foxx</id>
    <content type="html"><![CDATA[<p>Handling binary data in JavaScript applications is a bit
tricky because JavaScript does not provide a data type for
binary data. This post explains how to use binary data in
JavaScript actions written using ArangoDB&rsquo;s <a href="http://docs.arangodb.org/Foxx/README.html">Foxx</a>.</p>

<!-- more -->


<h1>Strings vs. binary data</h1>

<p>Internally, JavaScript strings are <a href="http://ecma-international.org/ecma-262/5.1/#sec-4.3.16">sequences of 16 bit integer values</a>.
Furthermore, the ECMAScript standard requires that a JavaScript
implementation should interpret characters in conformance with the
Unicode standard, using either UCS-2 or UTF-16 encoding.</p>

<p>While this is fine for handling natural language, it becomes problematic
when trying to work with arbitrary binary data. Binary data cannot be
used safely in a JavaScript string because it may not be valid UTF-16
data.</p>

<p>To make it work anyway, binary data needs to be stored in a wrapper
object. I won&rsquo;t go into details about ES6 typed arrays here, but will
focus on <code>Buffer</code> objects.</p>

<h1>Binary data in Foxx actions</h1>

<p>A Foxx route that shall handle HTTP POST requests containing arbitrary
(binary) body in the request body should not use <code>req.body()</code>. The
reason is that <code>req.body()</code> will return the body as a JavaScript string,
and this isn&rsquo;t going to work with arbitrary binary data.</p>

<p>Instead, the <code>req.rawBodyBuffer()</code> should be used. This will return the
request body inside a buffer.
Here&rsquo;s an example that stores the received data in a file on the server:</p>

<p>```js Foxx action that can handle binary input
controller.post(&lsquo;/receive-binary&rsquo;, function (req, res) {
  // fetch request body into the buffer
  var body = req.rawBodyBuffer();
  // create an absolute filename, local to the Foxx application directory
  var filename = applicationContext.foxxFilename(&ldquo;body&rdquo;);</p>

<p>  require(&ldquo;fs&rdquo;).write(filename, body);
});
```</p>

<p>This action can be invoked as follows if the app is mounted with name <code>app</code>:</p>

<pre><code>curl -X POST http://localhost:8529/app/receive-binary --data-binary @filename
</code></pre>

<p>This will send the contents of the file <code>filename</code> to the server. The Foxx
action will then store the received data as is in a file name <code>body</code> in the
application directory.</p>

<p>Returning binary data from a Foxx action is simple, too. Here&rsquo;s a way that
returns the contents of the file named <code>body</code> in the application&rsquo;s directory:
<code>js Foxx action that returns contents of a file
controller.get('/provide-binary-file', function (req, res) {
  // create an absolute filename, local to the Foxx application directory
  var filename = applicationContext.foxxFilename("body");
  // send the contents, this will also set mime type "application/octet-stream"
  res.sendFile(filename);
});
</code></p>

<p>It is also possible to return data from an arbitrary buffer:
```js Foxx action that returns data in a buffer
controller.get(&lsquo;/provide-binary-buffer&rsquo;, function (req, res) {
  // create an absolute filename, local to the Foxx application directory
  var filename = applicationContext.foxxFilename(&ldquo;body&rdquo;);
  // read the file content into a buffer
  var fileContent = require(&ldquo;fs&rdquo;).readBuffer(filename);</p>

<p>  // TODO: modify the contents of buffer here&hellip;</p>

<p>  // send the contents, this will also set mime type &ldquo;application/octet-stream&rdquo;
  res.send(fileContent);
});
```</p>

<h1>Example application</h1>

<p>I quickly put together an example application that shows how to handle arbitrary
binary data in Foxx actions. The example app allows uploading files to the server.
The server will then list these files and allows downloading them again.</p>

<p>The application has no CSS at all. Its only purpose is to demo the server-side code.
The application can be downloaded <a href="/downloads/code/filelist-app.tar.gz">here</a>.</p>

<p>Please note that the example application requires ArangoDB 2.3, which is currently
in development.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Understanding Where Operations Are Executed]]></title>
    <link href="http://jsteemann.github.io/blog/2014/08/30/understanding-where-operations-are-executed/"/>
    <updated>2014-08-30T22:38:42+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/08/30/understanding-where-operations-are-executed</id>
    <content type="html"><![CDATA[<p>I recently had to deal with some data processing operation that took
about 20 minutes to complete. When looking into this, I found that the
easiest and most beneficial change to the whole setup was to make the
operation a <em>server-side</em> operation instead of executing it <em>client-side</em>.</p>

<p>This change reduced the operation&rsquo;s total execution time to a few seconds.</p>

<!-- more -->


<p>I can&rsquo;t show the original processing task here, so I&rsquo;ll start with a
contrived example. Imagine the following <em>for</em> loop inserting 100K documents
into a collection named <code>test</code>:
<code>js inserting 100k documents
for (i = 0; i &lt; 100000; ++i) {
  db.test.save({ value: i });
}
</code>
Now we only need a client application to execute the operation. As I don&rsquo;t
have a presentable client application right now, I will use the ArangoShell as
my client application.</p>

<h2>What&rsquo;s in a for loop?</h2>

<p>Running the above <em>for</em> loop inside the ArangoShell will lead to the loop being
executed inside the <em>arangosh</em> process.</p>

<p>In order to save a document in the collection, arangosh (our client) must make a
call to the ArangoDB server. This means issuing an HTTP POST request
to the server&rsquo;s REST API at <code>/_api/document/?collection=test</code>.
The server process will receive this request, insert the document, and
respond with an HTTP status code 201 or 202 to our client.
The client will then continue the loop until all documents have been inserted.</p>

<p>Now it&rsquo;s easy to see that the simple 3-line loop will issue 100,000 HTTP requests
in total. This means lots of data being pushed through the network stack(s).
It is pretty easy to imagine that this will come at a cost.</p>

<p>If we instead execute the above loop directly inside the ArangoDB server, we
can get rid of all the network overhead. The server has no need to send HTTP
calls to itself. It can simply execute the 100K inserts and is then done.
We therefore assume the loop to run somewhat faster when executed server-side.</p>

<p>A quick test on a crap laptop produced the following execution times for running
the loops:</p>

<ul>
<li>server-side execution (arangod): 1.34 seconds</li>
<li>client-side execution (arangosh): 17.32 seconds</li>
</ul>


<p><strong>Ouch</strong>. It looks like the client-server request-response overhead matters.</p>

<p>The following sections deal with how to get rid of some or even all the
client-server ping pong.</p>

<h2>Graph traversals</h2>

<p>The above <em>for</em> loop example was contrived, but imagine running
a client-side graph traversal instead. In fact, the original problem mentioned
in the introduction has been a graph traversal.</p>

<p>The problem of a graph traversal is that is often iterative and highly
dynamic. Decisions are made during the traversal as nodes are encountered,
leading to dynamic inclusion or exclusion etc. This means that it makes sense to
process nodes and edges only when needed, at the point when they are visited.</p>

<p>Even if the client can employ some sort of caching for already visited
nodes, the client still needs to ask the server about each visited
node&rsquo;s connections at least once. Otherwise it could not follow them.</p>

<p>This normally means lots of requests and responses. Compare this to the
<em>single</em> request-response alternative in which a client kicks off a server-side
traversal, and finally receives the overal result once it is assembled.</p>

<p><strong>Conclusion</strong>: traversals on anything but very small graphs should be run server-side.
A server-side action (see below) is a good way to do this. Please note that
running a server-side traversal does not mean giving up flexibility and
control flow functionality. Server-side traversals remain highly configurable
through custom JavaScript functions that allow implementation of user-defined
business logic.</p>

<h2>AQL queries</h2>

<p>We won&rsquo;t have your application send a series of 100,000 individual
insert statements to the relational database of our choice. We already
know from the past that this is going to be rather slow, so we have
learned to avoid this. In the relational context, we rather use SQL queries
that create or modify many rows in one go, e.g. an <code>INSERT INTO ... SELECT ...</code>,
bulk inserts etc.</p>

<p>ArangoDB is no different. In general, you should try to avoid issuing lots
of individual queries to the database from a client application. Instead and if
the queries look alike, try converting multiple individual operations into a
single AQL query. This will already save a lot of network overhead.</p>

<p>AQL provides multi-document operations to insert, update, and remove data. An
overview is given <a href="http://docs.arangodb.org/Aql/DataModification.html">here</a>.</p>

<p>The above 100K inserts from the contrived example can easily be transformed
into this single AQL query:
<code>
FOR i IN 1..100000 INSERT { value: i } INTO test
</code></p>

<h2>Bulk imports</h2>

<p>For importing larger amounts of documents from files, there is the specialized
<a href="http://docs.arangodb.org/Arangoimp/README.html">arangoimp</a> import tool. It can
load data from JSON and CSV files into ArangoDB. The tool is shipped with
ArangoDB.</p>

<p>ArangoDB also provides a REST API for <a href="http://docs.arangodb.org/HttpBulkImports/README.html">bulk imports</a>
of documents.</p>

<h2>Joins</h2>

<p>A special note about <em>joins</em>: the fact that several NoSQL databases do not
provide join functionality has driven some people to emulate join functionality
on the client-side, in their applications.</p>

<p>This can be a recipe for disaster: client-side join implementation might lead
to horrendous amounts of queries that might need to be sent to the database for
fetching all the records. More than that, if data are queried individually,
the overall result may lack consistency. By the way, the same is true for
fetching referenced or linked documents.</p>

<p>ArangoDB provides join functionality via AQL queries. Additionally, AQL queries
can be used to fetch other documents with the original documents. Note that
ArangoDB has no way of defining references or links between documents, but
still AQL allows combining arbitrary documents in one query.</p>

<p>In almost all cases it make more sense to use an AQL query that performs
joins or reference-fetching server-side and close to the data than having to
deal with that on the application-side of things.</p>

<p>AQL joins are described <a href="http://docs.arangodb.org/AqlExamples/Join.html">here</a>.</p>

<h2>Server-side actions</h2>

<p>With <em>stored procedures</em>, relational databases provide another way for an
application to trigger the execution of a large amount of queries. Stored
procedures are executed server-side, too, so they allow avoiding a lot of
request-response ping pong between the application and the database, at least
for defined tasks. Additionally, stored procedures provide control flow
functionality, which can also be handy when operations depend on each other.</p>

<p>Coming back to ArangoDB: complex data-processing tasks that need to execute
multiple operations or need control flow functionality might benefit if
converted from multiple application-side operations into a single server-side
action.</p>

<p>Server-side actions run inside the ArangoDB server, closer to the data, and
can be much faster than a series of client-side operations.
A server-side action is called with just one HTTP request from the application,
so it may lead to saving lots of request-response cycles and reduction in
network overhead. Apart from that, server-side actions in ArangoDB can employ
transactions and provide the necessary control over isolation and atomicity
when executing a series of operations.</p>

<p>Business logic and control flow functionality can be integrated
easily because server-side actions in ArangoDB are JavaScript functions,
with all of the language&rsquo;s programming features being available.</p>

<p>But there&rsquo;s even more to it: a single server-side operation can be written
to put together its result in a format most convenient for the client
application. This can also lead to better encapsulation, because all an
application needs to know about a server-side action is its API or contract.
Any internals of the action can be hidden from the client application. Overall,
this supports a service-oriented approach.</p>

<p>To learn more about how to write server-side actions, please have a look
at ArangoDB&rsquo;s <a href="http://docs.arangodb.org/Foxx/README.html">Foxx</a>. It is all
about making server-side actions available via REST APIs.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Speeding Up Server-side Operations]]></title>
    <link href="http://jsteemann.github.io/blog/2014/08/20/speeding-up-server-side-operations/"/>
    <updated>2014-08-20T22:02:09+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/08/20/speeding-up-server-side-operations</id>
    <content type="html"><![CDATA[<p>Sometimes it is easier to make server-side operations run a bit faster.
In the following post I&rsquo;ll show a few low-level optimizations that can
be applied to user-defined JavaScript code that is executed inside the
ArangoDB server.</p>

<!-- more -->


<h1>Scope</h1>

<p>Some data-access operations can be sped up by using the appropriate indexes,
but that&rsquo;s not what I am going to show here.
Instead, I want to demo a few easy optimizations that don&rsquo;t require any
changes to the data. Only JavaScript code needs to be minimally adjusted
to use them.</p>

<p>Note that I am not talking about code that is executed in the ArangoShell
here. I will only be looking at code that is executed inside the arangod
server instance. The natural places for using custom JavaScript code in
the ArangoDB server are for example:</p>

<ul>
<li><a href="http://docs.arangodb.org/Foxx/README.html">Foxx</a> controllers</li>
<li><a href="http://docs.arangodb.org/Transactions/TransactionInvocation.html">transactions</a></li>
<li><a href="http://docs.arangodb.org/ModuleTasks/README.html">tasks</a></li>
<li><a href="http://docs.arangodb.org/Traversals/README.html">traversals</a></li>
</ul>


<p>Of course it does not make much sense to optimize operations that are not
called very often. The code changes I show will only be useful for server-side
operations that are called very often, for example, from within loops or
from batch processing actions.</p>

<p>Before starting to change any code, please make sure that the code is executed
often and that it accounts for a significant part of the total execution time.</p>

<h2>Baseline</h2>

<p>Imagine the following custom JavaScript code running somewhere inside ArangoDB:
<code>js baseline
for (var i = 0; i &lt; 100000; ++i) {
  db.test.save({ value: 1 });
}
</code>
This code inserts 100,000 documents into a collection <code>test</code>. Each document has
one attribute only. These numbers are arbitrary, but good enough for a demo.</p>

<p>What can we do to improve the runtime of the above code?</p>

<h2>Non-optimizations</h2>

<p>The <em>for</em> statement itself is not worth optimizing. It won&rsquo;t matter much if we used
pre-increment or post-increment for the loop induction variable <code>i</code> or if we
turned the <em>for</em> loop into a <em>while</em> loop. Any changes here might only save us a
few nanoseconds in total, but are likely to make the code more unreadable.</p>

<p>Let&rsquo;s not do that!</p>

<h2>Avoiding accessors</h2>

<p>Clearly, we should be looking at the <code>save</code> operation.</p>

<p><code>db.test.save()</code> looks like a function call, and we learned that function are
expensive. In this case, we cannot avoid the function call to <code>save()</code>, but we
can avoid another <em>hidden function call</em>. Yes, <code>db.test</code> actually calls a function,
though it does not look like it does.</p>

<p>The <code>db</code> object has auto-magic member attributes. The <code>db</code> object will have a
member attribute for existing collection. The member will automatically vanish when
a collection gets dropped, and the member will rename itself when collections are
renamed.</p>

<p>This magic is made possible by late-binding attributes and using accessor functions
for attribute accesses on the <code>db</code> object: whenever the attributes of the <code>db</code> object
are queried, an accessor function (<em>property query</em>) is called internally to compile
them. Accessing a specific attribute of the <code>db</code> object will also call an accessor
function (<em>property get</em>). This is exactly what happens in our case when we access
<code>db.test</code>.</p>

<p>If this was too complicated, it may become more obvious if we modified the original
code to this:
<code>js using attribute lookup
for (var i = 0; i &lt; 100000; ++i) {
  db['test'].save({ value: 1 });
}
</code>
Now it should be obvious that accessing <code>test</code> requires an attribute lookup on the
<code>db</code> object, and behind the scenes the same will happen if we had written <code>db.test</code>
instead.</p>

<p>Let&rsquo;s avoid the repeated call to the accessor function inside the loop! This can
easily be achieved by assigning <code>db.test</code> to a variable once and forever outside
of the loop. This technique is called loop-invariant code motion, and it can be
applied in a lot of other situations, too:
<code>js loop-invariant code motion
var collection = db.test;
for (var i = 0; i &lt; 100000; ++i) {
  collection.save({ value: 1 });
}
</code>
(on a side note: you cannot assign <code>db.test.save</code> to a variable and call it as a
function)</p>

<h2>Enjoying the silence</h2>

<p>The <code>save</code> operation is chatty. Every time it is called, it will return some meta
data from the just-inserted document, e.g.:
<code>json save result
{
  "_id" : "test/11443981931568",
  "_rev" : "11443981931568",
  "_key" : "11443981931568"
}
</code>
In our case, we&rsquo;re not interested in these returned values, and we don&rsquo;t
capture them in a variable.
The <code>save</code> function doesn&rsquo;t know this and will happily assemble its
result array. The array consists of three string values (six when also counting
attribute names). Setting up the result definitely requires costly
memory allocations and string copying.</p>

<p>We can avoid all this by passing an <em>options</em> parameter into <code>save</code>, and setting
its <code>silent</code> attribute to <code>true</code>:
<code>js silence option
for (var i = 0; i &lt; 100000; ++i) {
  db.test.save({ value: 1 }, { silent: true });
}
</code>
Now <code>save()</code> will only return a boolean value, which is much quicker.</p>

<h2>Transactions</h2>

<p>Yet another alternative is use to wrap the operations in the loop into a
transaction. Transaction themselves won&rsquo;t buy us much feature-wise, so why use
them? The reason is simple: if we do not use a transaction ourselves, each
<code>save</code> operation will implicitly be executed in a transaction of its own.
For a loop with 100,000 operations, that will be 100K transactions!</p>

<p>So when we put all the operations into a single, now explicit transaction,
we can save the overhead of 99,999 transaction begin and commit operations.
Here&rsquo;s how to do it:
```js transaction
db._executeTransaction({
  collections: {</p>

<pre><code>write: "test"
</code></pre>

<p>  },
  action: function () {</p>

<pre><code>for (var i = 0; i &lt; 100000; ++i) { 
  db.test.save({ value: 1 });
}
</code></pre>

<p>  }
});
```</p>

<h1>Results</h1>

<p>How far have we got with these minimal code adjustments?</p>

<p>I have put together a <a href="/downloads/code/speeding-up-server.js">script</a>
that can be run in arangod. The script will run each version of the loop
10 times and time the execution. The minimum, maximum and
average execution times are printed (in seconds, less is better). Note that
the absolute times do not matter much here. Please have a look at the percentage
column, which shows the execution time of each variant in comparison to the
baseline.</p>

<p>Here&rsquo;s an excerpt of the script&rsquo;s output:</p>

<p>```plain results</p>

<h2>test name      |   total (s) |     min (s) |     max (s) |    avg2 (s) |       %</h2>

<p>baseline       |     13.0940 |      1.2907 |      1.3357 |      1.3084 |  100.00
loop-invariant |     10.6888 |      1.0506 |      1.1042 |      1.0667 |   81.53
silence        |     11.7186 |      1.1512 |      1.2247 |      1.1678 |   89.25
transaction    |     10.1521 |      0.9987 |      1.0346 |      1.0149 |   77.56
combined       |      7.8545 |      0.7768 |      0.7977 |      0.7850 |   59.99</p>

<p>```
As can be seen, moving the loop-invariant accessor function call outside of the
loop provided an almost 20% speedup (from 1.30 to 1.06 s). Using the silence
option did also provide some, but not the same speedup. Using transactions reduced
the execution time, and by putting all this together, a reduction of about 40 %
was achieved.</p>

<p>Your mileage may vary. Please feel free to adjust the test script and run your
own tests.</p>
]]></content>
  </entry>
  
</feed>
