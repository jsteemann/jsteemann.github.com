<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Performance | J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/blog/categories/performance/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2016-01-19T14:53:45+01:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AQL Optimizer Improvements for 2.8]]></title>
    <link href="http://jsteemann.github.io/blog/2015/12/22/aql-optimizer-improvements-for-28/"/>
    <updated>2015-12-22T22:39:30+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/12/22/aql-optimizer-improvements-for-28</id>
    <content type="html"><![CDATA[<p>With the 2.8 beta phase coming to an end it&rsquo;s time to shed some light
on the improvements in the 2.8 AQL optimizer. This blog post summarizes
a few of them, focusing on the query optimizer. There&rsquo;ll be a follow-up
post that will explain dedicated new AQL features soon.</p>

<!-- more -->


<h2>Array indexes</h2>

<p>2.8 allows creating hash and skiplist indexes on attributes which are arrays.
Creating such index works similar to creating a non-array index, with the
exception that the name of the array attribute needs to be followed by a <code>[*]</code>
in the index fields definition:</p>

<p><code>js creating an array index
db._create("posts");
db.posts.ensureIndex({ type: "hash", fields: [ "tags[*]" ] });
</code></p>

<p>Now if the <code>tags</code> attribute of a document in the <code>posts</code> collection is an array,
each array member will be inserted into the index:</p>

<p><code>js storing an array value
db.posts.insert({ tags: [ "arangodb", "database", "aql" ] });
db.posts.insert({ tags: [ "arangodb", "v8", "javascript" ] });
db.posts.insert({ tags: [ "javascript", "v8", "nodejs" ] });
</code></p>

<p>The index on <code>tags[*]</code> will now contain the values <code>arangodb</code>, <code>database</code>, <code>aql</code> and
<code>nosql</code> for the first document, <code>arangodb</code>, <code>v8</code> and <code>javascript</code> for the second, and
<code>javascript</code>, <code>v8</code> and <code>nodejs</code> for the third.</p>

<p>The following AQL will find any documents that have a value of <code>javascript</code> contained
in their <code>tags</code> value:</p>

<p><code>plain array index query
FOR doc IN posts
  FILTER 'javascript' IN doc.tags[*]
  RETURN doc
</code></p>

<p>This will use the array index on <code>tags[*]</code>.</p>

<p>The array index works by inserting all members from an array into the index
separately. Duplicates are removed automatically when populating the index.</p>

<p>An array index can also be created on a sub-attribute of array members. For
example, the following definition will make sure the <code>name</code> sub-attributes of
the <code>tags</code> array values will make it into the index:</p>

<p><code>js creating an array index on a sub-attribute
db.posts.ensureIndex({ type: "hash", fields: [ "tags[*].name" ] });
</code></p>

<p>That will allow storing data as follows:</p>

<p><code>js storing an array value
db.posts.insert({ tags: [ { name: "arangodb" }, { name: "database" }, { name: "aql" } ] });
db.posts.insert({ tags: [ { name: "arangodb" }, { name: "v8" }, { name: "javascript" } ] });
db.posts.insert({ tags: [ { name: "javascript" }, { name: "v8" }, { name: "nodejs" } ] });
</code></p>

<p>The (index-based) selection query for this data structure then becomes</p>

<p><code>plain array index query using sub-attributes
FOR doc IN posts
  FILTER 'javascript' IN doc.tags[*].name
  RETURN doc
</code></p>

<p>Contrary to MongoDB, there is no automatic conversion to array values when
inserting non-array values in ArangoDB. For example, the following plain strings
will not be inserted into an array index, simply because the value of the index
attribute is not an array:</p>

<p><code>js storing non array values without indexing
db.posts.insert({ tags: "arangodb" });
db.posts.insert({ tags: "javascript" });
db.posts.insert({ tags: "nodejs" });
</code></p>

<p>Note that in this case a non-array index can still be used.</p>

<h2>Use of multiple indexes per collection</h2>

<p>The query optimizer can now make use of multiple indexes if multiple filter
conditions are combined with logical ORs, and all of them are covered by
indexes of the same collection.</p>

<p>Provided there are separate indexes present on <code>name</code> and <code>status</code>, the
following query can make use of index scans in 2.8, as opposed to full
collection scans in 2.7:</p>

<p><code>plain using multiple indexes
FOR doc IN users
  FILTER doc.name == 'root' || doc.status == 'active'
  RETURN doc
</code></p>

<p><img src="/downloads/screenshots/multiple-indexes.png"></p>

<p>If multiple filter conditions match for the same document, the result will
automatically be deduplicated, so each document is still returned at most once.</p>

<h2>Sorted IN comparison</h2>

<p>Another improvement for the optimizer is to pre-sort comparison values for <code>IN</code> and
<code>NOT IN</code> so these operators can use a (much faster) binary search instead of a linear search.</p>

<p>The optimization will be applied automatically for <code>IN</code> / <code>NOT IN</code> comparison values used
in filters, which are used inside of a <code>FOR</code> loop, and depend on runtime values. For example,
the optimization will be applied for the following query:</p>

<p><code>
LET values = /* some runtime expression here */
FOR doc IN collection
  FILTER doc.value IN values
  RETURN doc
</code></p>

<p>The optimization will not be applied for <code>IN</code> comparison values that are value
literals and those that are used in index lookups. For these cases the comparison values
were already deduplicated and sorted.</p>

<p>&ldquo;sort-in-values&rdquo; will appear in the list of applied optimizer rules if the optimizer
could apply the optimization:</p>

<p><img src="/downloads/screenshots/sorted-in.png"></p>

<h2>Optimization for LENGTH(collection)</h2>

<p>There are multiple ways for counting the total number of documents in a collection from
inside an AQL query. One obvious way is to use <code>RETURN LENGTH(collection)</code>.</p>

<p>That variant however was inefficient as it fully materialized the documents before
counting them. In 2.8 calling <code>LENGTH()</code> for a collection will get automatically replaced
by a call to a special function that can efficiently determine the number of documents.
For larger collections, this can be several thousand times faster than the naive 2.7
solution.</p>

<h2>C++ implementation for many AQL functions</h2>

<p>Many existing AQL functions have been backed with a C++ implementation that removes
the need for some data conversion that would otherwise happen if the function were
implemented in V8/JavaScript only. More than 30+ functions have been changed, including
several that may produce bigger result sets (such as <code>EDGES()</code>, <code>FULLTEXT()</code>, <code>WITHIN()</code>,
<code>NEAR()</code>) and that will hugely benefit from this.</p>

<h2>Improved skip performance</h2>

<p>2.8 improves the performance of skipping over many documents in case no indexes and no
filters are used. This might sound like an edge case, but it is quite common when the
task is to fetch documents from a big collection in chunks and there is certainty that
there will be no parallel modifications.</p>

<p>For example, the following query runs about 3 to 5 times faster in 2.8, and this
improvements can easily sum up to notable speedups if the query is called repeatedly
with increasing offset values for <code>LIMIT</code>:</p>

<p><code>plain query with huge skip
FOR doc IN collection
  LIMIT 1000000, 10
  RETURN doc
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AQL Function Speedups]]></title>
    <link href="http://jsteemann.github.io/blog/2015/11/20/aql-function-speedups/"/>
    <updated>2015-11-20T16:55:34+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/11/20/aql-function-speedups</id>
    <content type="html"><![CDATA[<p>While working on the upcoming ArangoDB 2.8, we have reimplemented some AQL
functions in C++ for improved performance. AQL queries using these functions
may benefit from using the new implementation of the function.</p>

<p>The following list shows the AQL functions for which a C++ implementation has
been added in 2.8. The other C++-based AQL function implementations added since
ArangoDB 2.5 are also still available. Here&rsquo;s the list of functions added in 2.8:</p>

<!-- more -->


<ul>
<li>document-related functions: DOCUMENT, EDGES, PARSE_IDENTIFIER</li>
<li>numerical functions: ABS, FLOOR, RAND, ROUND, SQRT</li>
<li>statistical functions: MEDIAN, PERCENTILE, STDDEV_POPULATION, STDDEV_SAMPLE, VARIANCE_POPULATION, VARIANCE_SAMPLE</li>
<li>geo functions: NEAR, WITHIN</li>
<li>array functions: APPEND, FIRST, FLATTEN, LAST, MINUS, NTH, POP, POSITION, PUSH, REMOVE_NTH, REMOVE_VALUE, REMOVE_VALUES, SHIFT, UNSHIFT</li>
<li>informational functions: COLLECTIONS, CURRENT_DATABASE, FIRST_DOCUMENT, FIRST_LIST, NOT_NULL</li>
<li>object-related functions: MERGE_RECURSIVE, ZIP</li>
</ul>


<p>Following are a few example queries that benefit from using the C++ variants of some
of the above functions:</p>

<h3>Fetching documents programmatically using the <code>DOCUMENT</code> function:</h3>

<ul>
<li>query: <code>FOR i IN 1..10000 RETURN DOCUMENT(test, CONCAT('test', i))</code></li>
<li>2.7: 0.3005 s</li>
<li>2.8: 0.1050 s</li>
</ul>


<h3>Fetching edges programmatically using the <code>EDGES</code> function:</h3>

<ul>
<li>query: <code>FOR i IN 1..100000 RETURN EDGES(edges, CONCAT('test/test', i), 'outbound')</code>:</li>
<li>2.7: 4.3590 s</li>
<li>2.8: 1.4469 s</li>
</ul>


<h3>Fetching many documents from a geo index, post-filtering most of them:</h3>

<ul>
<li>query: <code>FOR doc IN WITHIN(locations, 0, 0, 100000) FILTER doc.value2 == 'test1001' LIMIT 1 RETURN doc</code></li>
<li>2.7: 2.9876 s</li>
<li>2.8: 0.4087 s</li>
</ul>


<h3>Generating random numbers:</h3>

<ul>
<li>query: <code>FOR value IN 1..100000 RETURN RAND() * 50</code></li>
<li>2.7: 0.1743 s</li>
<li>2.8: 0.1364 s</li>
</ul>


<p>Please note that not in every case there will be a tremendous speedup. As usual,
it depends on how often a function is called inside a query and what other constructs
are used. Your mileage may vary.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Multiple Indexes Per Collection]]></title>
    <link href="http://jsteemann.github.io/blog/2015/11/20/using-multiple-indexes-per-collection/"/>
    <updated>2015-11-20T15:30:05+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/11/20/using-multiple-indexes-per-collection</id>
    <content type="html"><![CDATA[<p>The query optimizer in ArangoDB 2.8 has been improved in terms of how it can
make use of indexes. In previous versions of ArangoDB, the query optimizer could
use only one index per collection used in an AQL query. When using a logical OR
in a FILTER condition, the optimizer did not use any index for the collection in
order to ensure the result is still correct.</p>

<p>This is much better in 2.8. Now the query optimizer can use multiple indexes on
the same collection for FILTER conditions that are combined with a logical OR.</p>

<!-- more -->


<p>For all following queries, I have set up a collection named <code>test</code>, which has
two isolated hash indexes on the attributes <code>value1</code> and <code>value2</code>, and a skiplist
index on attribute <code>value3</code>.</p>

<p>Let&rsquo;s first try an AQL queries that uses a logical OR on two different attributes of the
collection:</p>

<p><code>plain example query
FOR doc IN test
  FILTER doc.value1 == 11 || doc.value2 == 19
  RETURN doc
</code></p>

<p>The execution plan for this query in 2.7 reveals that query will perform a full
collection scan and cannot use indexes because of the logical OR on two different
attributes:</p>

<p><code>``plain 2.7 query execution plan
Execution plan:
 Id   NodeType                  Est.   Comment
  1   SingletonNode                1   * ROOT
  2   EnumerateCollectionNode      0     - FOR doc IN test   /* full collection scan */
  3   CalculationNode              0       - LET #1 = doc.</code>value1<code>== 11 || doc.</code>value2` == 19
  4   FilterNode                   0       &ndash; FILTER #1
  5   ReturnNode                   0       &ndash; RETURN doc</p>

<p>Indexes used:
 none</p>

<p>Optimization rules applied:
 none
```</p>

<p>Running the same query in 2.8 / devel will produce a much better execution plan:</p>

<p><code>``plain 2.8 query execution plan
Execution plan:
 Id   NodeType          Est.   Comment
  1   SingletonNode        1   * ROOT
  6   IndexNode            2     - FOR doc IN test   /* hash index scan, hash index scan */
  3   CalculationNode      2       - LET #1 = doc.</code>value1<code>== 11 || doc.</code>value2` == 19<br/>
  4   FilterNode           2       &ndash; FILTER #1
  5   ReturnNode           2       &ndash; RETURN doc</p>

<p>Indexes used:
 By   Type   Collection   Unique   Sparse   Selectivity   Fields         Ranges
  6   hash   test         false    false       100.00 %   [ <code>value1</code> ]   doc.<code>value1</code> == 11
  6   hash   test         false    false       100.00 %   [ <code>value2</code> ]   doc.<code>value2</code> == 19</p>

<p>Optimization rules applied:
 Id   RuleName
  1   use-indexes
```</p>

<p>Multiple indexes will also be used if different index types are accessed, or for non-equality
filter conditions. For example, the following query will make use of the two hash indexes
and also the skiplist index:</p>

<p><code>plain example query
FOR doc IN test
  FILTER doc.value1 == 11 || doc.value2 == 19 || doc.value3 &gt; 42
  RETURN doc
</code></p>

<p>Here is its execution plan from 2.8:</p>

<p><code>``plain 2.8 query execution plan
Execution plan:
 Id   NodeType          Est.   Comment
  1   SingletonNode        1   * ROOT
  6   IndexNode            3     - FOR doc IN test   /* hash index scan, hash index scan, skiplist index scan */
  3   CalculationNode      3       - LET #1 = doc.</code>value1<code>== 11 || doc.</code>value2<code>== 19 || doc.</code>value3` > 42
  4   FilterNode           3       &ndash; FILTER #1
  5   ReturnNode           3       &ndash; RETURN doc</p>

<p>Indexes used:
 By   Type       Collection   Unique   Sparse   Selectivity   Fields         Ranges
  6   hash       test         false    false       100.00 %   [ <code>value1</code> ]   doc.<code>value1</code> == 11
  6   hash       test         false    false       100.00 %   [ <code>value2</code> ]   doc.<code>value2</code> == 19
  6   skiplist   test         false    false            n/a   [ <code>value3</code> ]   doc.<code>value3</code> > 42</p>

<p>Optimization rules applied:
 Id   RuleName
  1   use-indexes
```</p>

<p>For comparison, here is the non-optimized plan from 2.7 for the same query:</p>

<p><code>``plain 2.7 query execution plan
Execution plan:
 Id   NodeType                  Est.   Comment
  1   SingletonNode                1   * ROOT
  2   EnumerateCollectionNode      0     - FOR doc IN test   /* full collection scan */
  3   CalculationNode              0       - LET #1 = doc.</code>value1<code>== 11 || doc.</code>value2<code>== 19 || doc.</code>value3` > 42
  4   FilterNode                   0       &ndash; FILTER #1
  5   ReturnNode                   0       &ndash; RETURN doc</p>

<p>Indexes used:
 none</p>

<p>Optimization rules applied:
 none
```</p>

<p>Still the query optimizer will not be able to use any indexes on a collection when
there are multiple FILTER conditions combined with logical OR and at least one of them
is not satisfisable by an index of the collection. In this case it has no other choice
but to do a full collection scan.</p>

<p>For queries that combine multiple FILTER conditions with a logical AND, the optimizer
will still try to pick the most selective index for the query and use it for the collection.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Index Speedups in 2.8]]></title>
    <link href="http://jsteemann.github.io/blog/2015/11/20/index-speedups-for-28/"/>
    <updated>2015-11-20T15:11:00+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/11/20/index-speedups-for-28</id>
    <content type="html"><![CDATA[<p>The upcoming 2.8 version of ArangoDB will provide several improvements in
the area of index usage and query optimization.</p>

<p>First of all, hash and skiplist indexes can now index individual array values.
A dedicated post on this will follow shortly. Second, the query optimizer can
make use multiple indexes per collection for queries with OR-combined filter
conditions. This again is a subject for <a href="/blog/2015/11/20/using-multiple-indexes-per-collection/">another post</a>.
Third, there have been some speed improvements due to changes in the general
index handling code. This is what this post is about.</p>

<!-- more -->


<p>In order to assess the speedups in 2.8, I have run some already existing performance
tests that I initially ran when comparing ArangoDB 2.5 with 2.6. The test cases and
methodology are detailed in <a href="/blog/2015/05/20/the-great-aql-shootout-arangodb-25-vs-26/">this earlier blog post</a>.</p>

<p>For measuring the index-related performance improvements, I simply re-ran the
index related tests in 2.7 and in 2.8 / devel. I did not bother re-running all
tests from the original blog article because only some are index-related. In
particular, I only ran these tests again:</p>

<ul>
<li><em>join-key</em>: for each document in the collection, perform a join on the <code>_key</code> attribute on the collection
 itself (i.e. <code>FOR c1 IN @@c FOR c2 IN @@c FILTER c1._key == c2._key RETURN c1</code>)</li>
<li><em>join-id</em>: ditto, but perform the join using the <code>_id</code> attribute</li>
<li><em>join-hash-number</em> and <em>join-hash-string</em>: ditto, but join using a hash index on a numeric or string
 attribute</li>
<li><em>join-skiplist-number</em> and <em>join-skiplist-string</em>: ditto, but join using a skiplist index on a numeric or
 string attribute</li>
<li><em>lookup-key</em>, <em>lookup-hash-number</em>, <em>lookup-hash-string</em>, <em>lookup-skiplist-number</em>, <em>lookup-skiplist-string</em>:
 compile an IN-list of 10,000 lookup values and search these 10,000 documents in the collection using
 either the primary index (<code>_key</code> attribute), a hash index or a skiplist index. The latter two are tested
 on numeric and string attributes.</li>
</ul>


<p>The test queries were run 5 times each on collections containing 10,000, 100,000 and
1,000,000 documents.</p>

<p>Here are the query execution times from 2.7 and 2.8 for the individual tests, in
seconds (less is better):</p>

<p>```plain test results</p>

<h2>test name                collection     avg 2.7 (s)      avg 2.8 (s)</h2>

<p>join-key                 10k                 0.0997           0.0612
join-key                 100k                1.0611           0.6538
join-key                 1000k              10.2975           6.2507
join-id                  10k                 0.1088           0.0606
join-id                  100k                1.1126           0.6694
join-id                  1000k              10.8180           6.5336
join-hash-number         10k                 0.1044           0.0679
join-hash-number         100k                1.1137           0.7430
join-hash-number         1000k              10.7923           7.1534
join-hash-string         10k                 0.1193           0.0712
join-hash-string         100k                1.2656           0.7915
join-hash-string         1000k              12.3075           7.6667
join-skiplist-number     10k                 0.1387           0.1030
join-skiplist-number     100k                1.6693           1.3062
join-skiplist-number     1000k              18.0406          15.5203
join-skiplist-string     10k                 0.1928           0.1469
join-skiplist-string     100k                2.3166           1.8997
join-skiplist-string     1000k              27.1513          23.2058
lookup-key               10k                 1.4996           1.5245
lookup-key               100k                1.4951           1.5189
lookup-key               1000k               1.5545           1.5662
lookup-hash-number       10k                 1.5572           1.5526
lookup-hash-number       100k                1.5595           1.5435
lookup-hash-number       1000k               1.5436           1.5648
lookup-hash-string       10k                 1.6023           1.5623
lookup-hash-string       100k                1.5892           1.5741
lookup-hash-string       1000k               1.5841           1.5770
lookup-skiplist-number   10k                 1.5978           1.6145
lookup-skiplist-number   100k                1.5782           1.6269
lookup-skiplist-number   1000k               1.5891           1.6258
lookup-skiplist-string   10k                 1.6443           1.6840
lookup-skiplist-string   100k                1.6787           1.6985
lookup-skiplist-string   1000k               1.7319           1.7562
in-key                   10k                 0.1076           0.0754
in-key                   100k                0.1083           0.0775
in-key                   1000k               0.1104           0.0773
in-hash-number           10k                 0.0898           0.0696
in-hash-number           100k                0.0889           0.0674
in-hash-number           1000k               0.0877           0.0675
in-hash-string           10k                 0.1174           0.0867
in-hash-string           100k                0.1188           0.0878
in-hash-string           1000k               0.1174           0.0853
in-skiplist-number       10k                 0.1095           0.0849
in-skiplist-number       100k                0.1110           0.0873
in-skiplist-number       1000k               0.1106           0.0910
in-skiplist-string       10k                 0.1744           0.1315
in-skiplist-string       100k                0.1990           0.1594
in-skiplist-string       1000k               0.2369           0.1968
```</p>

<p>It looks like joins and IN list lookups got significantly faster in 2.8, whereas
the performance for point lookups is more or less the same as in 2.7.</p>

<p>Note that the changes to the index code in 2.8 only affect how indexes are accessed
from within AQL queries and how filtering works. No changes have been made for other
index operations such as insert, updates, and removals.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ArangoDB-PHP Driver Improvements]]></title>
    <link href="http://jsteemann.github.io/blog/2015/09/10/arangodb-php-driver-improvements/"/>
    <updated>2015-09-10T14:05:40+02:00</updated>
    <id>http://jsteemann.github.io/blog/2015/09/10/arangodb-php-driver-improvements</id>
    <content type="html"><![CDATA[<p>While preparing the release of ArangoDB 2.7, some improvements were made for the
<a href="https://github.com/arangodb/arangodb-php">PHP driver for ArangoDB</a>.</p>

<p>The 2.7 version of the PHP driver now supports the AQL query results cache. The
cache can be turned on or off globally, or be set to demand mode. The demand mode will
allow controlling caching on a per-AQL-query basis.</p>

<p>Additionally, the HTTP transport layer in the PHP driver was improved. Some internal
string handling methods were optimized so that the transport part becomes cheaper. All
driver operations that communicate with the ArangoDB server will benefit from this.</p>

<p>For a demonstration of the improvements, here is a script that creates 100,000
documents in a local ArangoDB database via the PHP driver. As we&rsquo;re interested in assessing
the HTTP layer improvements, the script intentionally issues 100,000 HTTP requests
instead of using the specialized <code>import</code> method provided by the driver.</p>

<p>The script code can be found <a href="https://github.com/arangodb/arangodb-php/blob/devel/examples/http-test.php">here</a>.</p>

<p>The baseline for the improvments is the (non-optimized) 2.6 version of the PHP
driver. Here are the results for issuing 100,000 requests with the 2.6 driver
(script was run twice to see if there are variations in execution time):</p>

<p>```plain execution times with 2.6 driver
creating 100000 documents
creating documents took 55.144556999207 s</p>

<p>creating 100000 documents
creating documents took 54.476955890656 s
```</p>

<p>Running it with the 2.7 version of the PHP driver now shows the improvements.
Execution time for the same script goes down from 54 seconds to 42 seconds:
```plain execution times with 2.7 driver
creating 100000 documents
creating documents took 42.886090040207 s</p>

<p>creating 100000 documents
creating documents took 42.578990936279 s
```</p>

<p>The PHP version used here was:
```plain PHP version details
PHP 5.5.12-2ubuntu4.6 (cli) (built: Jul  2 2015 15:27:14)
Copyright &copy; 1997-2014 The PHP Group
Zend Engine v2.5.0, Copyright &copy; 1998-2014 Zend Technologies</p>

<pre><code>with Zend OPcache v7.0.4-dev, Copyright (c) 1999-2014, by Zend Technologies
</code></pre>

<p>```</p>

<p>Following are the results from a different machine, this time using PHP 5.6:
```plain execution times with 2.6 driver
creating 100000 documents
creating documents took 48.394731044769 s</p>

<p>creating 100000 documents
creating documents took 47.618598937988 s
```</p>

<p>```plain execution times with 2.7 driver
creating 100000 documents
creating documents took 40.535583972931 s</p>

<p>creating 100000 documents
creating documents took 40.041265010834 s
```</p>

<p>The PHP version details for this machine were:
```plain PHP version details
PHP 5.6.4-4ubuntu6.2 (cli) (built: Jul  2 2015 15:29:28)
Copyright &copy; 1997-2014 The PHP Group
Zend Engine v2.6.0, Copyright &copy; 1998-2014 Zend Technologies</p>

<pre><code>with Zend OPcache v7.0.4-dev, Copyright (c) 1999-2014, by Zend Technologies
</code></pre>

<p>```</p>

<p>The actual improvements depend on many factors, so your exact mileage may vary.
The improvements may not be noticable for applications that issue only a few
requests with the driver, but they will be significant when performing lots of
requests, as in the above examples.</p>
]]></content>
  </entry>
  
</feed>
