<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Concepts | J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/blog/categories/concepts/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2014-08-07T01:43:46+02:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How ArangoDB's Write-ahead Log Works]]></title>
    <link href="http://jsteemann.github.io/blog/2014/08/06/how-arangodbs-write-ahead-log-works/"/>
    <updated>2014-08-06T21:14:00+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/08/06/how-arangodbs-write-ahead-log-works</id>
    <content type="html"><![CDATA[<p>Since version 2.2, ArangoDB stores all data-modification operations in its
<em>write-ahead log</em> (abbreviated <em>WAL</em>). The introduction of the WAL massively
changed how data are stored in ArangoDB.</p>

<h2>What&rsquo;s in the WAL?</h2>

<p>The WAL contains data of all data-modification operations that were executed in
the ArangoDB server instance. Operations are written to the WAL in the order of
execution. The following types of operations are logged to the WAL:</p>

<ul>
<li>creating, updating, replacing or removing documents</li>
<li>creating, modifying or dropping collections and their indexes</li>
<li>creating or dropping databases</li>
</ul>


<p>The WAL is used for all databases of an ArangoDB server. Database ids are stored
in the WAL in order to tell data from different databases apart.</p>

<h2>Recovery using the WAL</h2>

<p>Should the ArangoDB server crash, it will replay its write-ahead
logs at restart. Replaying the logs will make the server recover the same
state of data as before the crash.</p>

<p>Any document-modification operations might belong to a transaction. Transaction
data are also stored in the write-ahead log, allowing the recovery of committed
transactions and preventing the recovery of aborted or unfinished transactions.</p>

<p>Let&rsquo;s assume the following operations are executed in an ArangoDB server in this
order&hellip;
<code>
Seq#  |  Operation type       |  Transaction#  |  Context
------+-----------------------+----------------+---------------------------------------
   1  |  start transaction    |           773  |  database "_system"
   2  |  insert document      |           773  |  collection "test", key "foo"
   3  |  start transaction    |           774  |  database "_system"
   4  |  insert document      |           774  |  collection "mycollection", key "bar"
   5  |  start transaction    |           775  |  database "_system"
   6  |  update document      |           775  |  collection "boom", key "test"
   7  |  abort transaction    |           774  |  -                
   8  |  remove document      |           773  |  collection "test", key "baz"
   9  |  commit transaction   |           773  |  -     
</code>
&hellip;and then the server goes down due to a power outage.</p>

<p>On server restart, the WAL contents will be replayed, so the server will redo the
above operations. It will find out that operations #2 and #8 belong to transaction #773.
Transaction #773 was already committed, so all of its operations must and will be
recovered.</p>

<p>Further it will find out that operation #4 belongs to transaction #774, which was
aborted by the user. Therefore, this operation will not be replayed but ignored.</p>

<p>Finally, it will find operation #6 belongs to transaction #775. For this transaction,
there is neither an abort nor a commit operation in the log. Because the transaction
was never committed, all of its operations are not replayed at restart and the server
will behave as if the transaction never happened.</p>

<h2>WAL and replication</h2>

<p>A side-effect of having a write-ahead log is that it can also be used for replication.
When a slave server fetches the latest changes from the master, the master can simply
read the operations from its WAL. Data in the WAL are self-contained, meaning the
master can efficiently compile the list of changes using only the WAL and without
performing lookups elsewhere.</p>

<p>The WAL is there and will be used anyway, enabling any ArangoDB server to be used as
a replication master without any configuration. Previous versions of ArangoDB (without
the WAL) required setting up an extra component for replication logging. This
requirement is now gone.</p>

<h2>Organization of the WAL</h2>

<p>The WAL is actually a collection of logfiles. Logfiles are named <code>logfile-xxxx.db</code>
(with xxxx being the logfile&rsquo;s id). Logfiles with lower ids are older than logfiles
with higher ids. By default, the logfiles reside in the <em>journals</em> sub-directory of
ArangoDB&rsquo;s database directory.</p>

<p>At any point in time, one of the logfiles will be the <em>active</em> logfile. ArangoDB will
write all data-modifications to the active logfile. Writing is append-only, meaning
ArangoDB will never overwrite existing logfile data. To ensure logfile integrity,
a CRC32 checksum is calculated for each logfile entry. This checksum is validated when
a logfile is replayed. When there is a checksum mismatch, this indicates a disk error
or an incompletely written operation &ndash; in both cases it won&rsquo;t be safe to recover and
replay the operation.</p>

<p>If an operation can&rsquo;t be written into the active logfile due to lack of space, the
active logfile will be closed and a new logfile will become the active logfile.</p>

<p>A background thread will open new logfiles before the current active one is fully
filled up. This is done to ensure that no waiting is required when there is a switch
of the active logfile.</p>

<p>By default, each logfile has a size of 32 MB, allowing lots of operations to be stored
in it. If you want to adjust the default size, the option <code>--wal.logfile-size</code> is for you.</p>

<h2>Logfile synchronization</h2>

<p>Writes to logfiles are synchronized to disk automatically in a configurable interval
(the option to look for is <code>--wal.sync-interval</code>). To get immediate synchronization
of operations, operations can be run with the <code>waitForSync</code> attribute set to <code>true</code>,
or on collections with the <code>waitForSync</code> attribute being set.</p>

<p>For example, the following operations will have been synchronized to disk when the
operations return:</p>

<p><code>``js
// operation will be synchronized because the</code>waitForSync` attribute
// is set on operation level
db.test.save({ foo: &ldquo;bar&rdquo; }, { waitForSync: true });</p>

<p>// operation will be synchronized because the <code>waitForSync</code> attribute
// is set on collection level
db.mycollection.properties({ waitForSync: true });
db.mycollection.save({ foo: &ldquo;bar&rdquo; });
```</p>

<p>When no immediate synchronization has been requested, ArangoDB will have a background
thread periodically call <code>msync</code> for not-yet synchronized logfile regions. Multiple
operations are synchronized together because they reside in adjacent memory regions.
That means automatic synchronization can get away with far less calls to <code>msync</code> than
there are operations.</p>

<h2>Storage overhead</h2>

<p>Documents stored in the WAL (as part of an insert, update or replace operation) are
stored in a format that contains the document values plus the document&rsquo;s shape.
This allows reading a document fully from a WAL entry without looking up shape
information elsewhere, making it faster and also more reliable.</p>

<p>Storing shape information in the WAL has a storage space overhead though. The overhead
should not matter much if a logfile contains a lot of documents with identical shapes.
ArangoDB will make sure each shape is only stored once per WAL logfile. This has
turned out to be a rather good solution: it reduces WAL storage space requirements
greatly, and still is reliable and fast, as shape lookups are local to the current
WAL logfile only.</p>

<p>The overhead of storing shape information in the WAL will matter most when documents
have completely different shapes. In this case, no shape information will ever be
re-used. While this may happen in benchmarks with synthetic data, we found that in
reality there are often lots of identically-structured documents and thus a lot of
potential for re-using shapes.</p>

<p>Note that storing shape information in the WAL can be turned off to reduce overhead.
ArangoDB provides the option <code>--wal.suppress-shape-information</code> for this purpose.
When set to <code>true</code>, no shape information will be written to the WAL. Note that by
default, the option is set to <code>false</code> and that the option shouldn&rsquo;t be changed if
the server is to be used as a replication master. If documents aren&rsquo;t too heterogenous,
setting the option to <code>true</code> won&rsquo;t help much. It will help a lot if all documents
that are stored have different shapes (which we consider unrealistic, but we still
provide the option to reduce overhead in this case).</p>

<h2>WAL cleanup</h2>

<p>WAL logfiles that are completely filled are subject to garbage collection. WAL
garbage collection is performed by a separate garbage collector thread. The thread
will copy over the still-relevant operations into the collection datafiles.
After that, indexes will be adjusted to point to the new storage locations.
Documents that have become obsolete due to later changes will not be copied from
the WAL into the collection datafiles at all.</p>

<p>Garbage-collected logfiles are deleted by ArangoDB automatically if there exist
more of these &ldquo;historic&rdquo; logfiles than configured. The number of historic logfiles
to keep before deletion is configured using the option <code>--wal.historic-logfiles</code>.</p>

<p>If no replication is to be used, there is no need to keep any historic logfiles.
They have no purpose but to provide a history of recent changes. The more history
there is on a master server, the longer is the period for which slave servers can
request changes for.
How much history is needed depends on how reliable the network connection between
a replication slave and the master is. If the network connection is known to fail
periodically, it may be wise to keep a few historic logfiles on the master, so the
slave can catch up from the point it stopped when the network connection is
re-established.</p>

<p>If network connections are reliable or no replication is to be used at all, the
number of historic logfiles can be set to a low value to save disk space.</p>

<h2>Side-effects of the WAL</h2>

<p>The WAL can be used for replication, removing the requirement to explicitly turn
on the separate logging of operations for replication purposes. This is a clear
improvement over previous versions of ArangoDB.</p>

<p>The introduction of the WAL also caused a few other minor changes:</p>

<p>While documents are stored in a WAL logfile, their sizes won&rsquo;t be included in
the output of the <code>figures</code> method of the collection. When a WAL logfile gets
garbage-collected, documents will physically be moved into the collection logfiles
and the figures will be updated.</p>

<p>Note that the output of the <code>count</code> method is not affected by whether a document
is stored in the WAL or in a collection logfile.</p>

<p>Another side-effect of storing operations in the WAL first is that no collection
logfiles will be created when the first document is inserted. So there will be
collections with documents but without any logfiles, at least temporarily until
the WAL garbage collection kicks in and will transfer data from the WAL to the
collection logfiles.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Schema Handling in ArangoDB]]></title>
    <link href="http://jsteemann.github.io/blog/2014/06/03/schema-handling-in-arangodb/"/>
    <updated>2014-06-03T22:57:58+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/06/03/schema-handling-in-arangodb</id>
    <content type="html"><![CDATA[<h2>Schemas vs. schema-free</h2>

<p>In a relational database, all rows in a table have the same structure.
The structure is saved once for the table, and the invidiual rows only
contain the row&rsquo;s values. This is an efficient approach if all records
have the exact same structure, i.e. the same attributes (same names and
same data types):</p>

<p><code>
firstName (varchar)  |  lastName (varchar)  |  status (varchar)
---------------------+----------------------+------------------
"fred"               |  "foxx"              |  "active"
"john"               |  "doe"               |  "inactive"
</code></p>

<p>This is not a good fit if the data structure changes. In this case, an
<code>ALTER TABLE</code> command would need to be issued in the relational database,
converting all existing rows into the new structure. This is an expensive
operation because it normally requires rewriting all existing rows.</p>

<p>The situation becomes really difficult when there is no definite structure
for a table &ndash; if rows shall have a dynamic or variable structure, then
it can be quite hard to define a sensible relational table schema!</p>

<p>This is where NoSQL databases enter the game &ndash; mostly they don&rsquo;t require
defining a schema for a &ldquo;table&rdquo; at all. Instead, each individual record
will not only contain its data values, but also its own schema. This means
much higher flexibility as every record can its completely own data
structure.</p>

<p>This flexibility has a disadvantage though: storing schemas in individual
records requires more storage space than storing the schema only once for
the complete table. This is especially true if most (or even all) records
in the table do have the same structure. A lot of storage space can be
wasted while storing the same structure information again and again and again&hellip;</p>

<h2>Schemas in ArangoDB</h2>

<p>ArangoDB tries to be different in this respect: on the one hand it is a
schema-free database and thus allows <em>flexible storage</em>. All documents in a
collection (the ArangoDB lingo for <em>record</em> and <em>table</em>) can have the same
or totally different structures. We leave this choice up to the user.</p>

<p>On the other hand, ArangoDB will exploit the similarities in document
structures to <em>save storage space</em>. It will detect identical document
schemas, and only save each unique schema once.
We optimized ArangoDB for this use case because we found that in reality, the
documents in a collection will either have absolutely the same schema, or
there will only be a few different schemas in use.</p>

<p>From the user perspective there are no schemas in ArangoDB: there is no way
to create or alter the schema of a collection at all. Instead, ArangoDB
will use the attribute names and data types contained in the JSON data of
each document. All of this happens automatically.</p>

<p>For each new document in a collection, ArangoDB will first figure out the
schema. It will then check if it has already processed a document with the
same schema. If yes, then there is no need to save the schema information
again. Instead, the new document will only contain a pointer to an already
existing schema. This does not require much storage space.</p>

<p>If ArangoDB figures out that it has not yet processed a document with the
same schema, it will store the document schema once, and store a pointer
to the schema in the new document. This is a slightly more expensive
operation, but it pays out when there are multiple documents in a
collection with the same structure.</p>

<p>When ArangoDB looks at document schemas, it takes into account the attribute
names and the attribute value data types contained in a document. All
attribute names and data types in a document make the so-called <em>shape</em>.</p>

<p>Each shape is only stored once for each collection. Any attribute name used
in a collection is also stored only once, and then reused from any shape that
contains the attribute name.</p>

<h2>Examples</h2>

<p>The following documents do have different values but still their schemas are
identical:</p>

<p><code>json
{ "name" : { "first" : "fred", "last" : "foxx" }, "status" : "active" }
{ "name" : { "first" : "john", "last" : "doe" }, "status" : "inactive" }
</code></p>

<p>Both documents contain attributes named <code>name</code> and <code>status</code>. <code>name</code> is an
array with two sub-attributes <code>first</code> and <code>last</code>, which are strings.
<code>status</code> is also a string in both documents.</p>

<p>ArangoDB will save this schema only once in a so-called <em>shape</em>. The documents
will store their own data values plus a pointer to this (same) shape.</p>

<p>The next two documents have different, yet unknown schemas. ArangoDB will
therefore store these two schemas in two new shapes:</p>

<p><code>json
{ "firstName" : "jack", "lastName" : "black", "status" : "inactive" }
{ "name" : "username", "status" : "unknown" }
</code></p>

<p>We would end up with three diferent <em>shapes</em> for the four documents. This
might not sound impressive, but if more documents are saved with one of the
existing shapes, then storing each shape just once might really pay out.</p>

<h2>A note on attribute names</h2>

<p>Even though the latter two example documents had unique schemas, we saw in
the examples that attribute names were already repeating. For example, all
documents shown so far had an attribute named <code>status</code>, and some also
had a <code>name</code> attribute.</p>

<p>ArangoDB figures out when attribute names repeat, and it will not store the
same attribute name more than once in a collection. Given that many
documents in a collection use a fixed set of repeating attribute names,
this approach can lead to considerable storage space reductions.</p>

<p>As an aside, reusing attribute name information allows using descriptive
(read: long) attribute names in ArangoDB with very low storage overhead.</p>

<p>For example, in ArangoDB it will not cost much extra space to use long
attribute names like these in lots of documents:
<code>json
{ "firstNameOfTheUser" : "jack", "lastNameOfTheUser" : "black" }
</code></p>

<p>As each unique attribute name is only stored once per collection, there
is no need to <em>artifically</em> shorten the attribute names just for storage
space reduction like it is in other schema-free databases:
<code>json
{ "fn" : "jack", "ln" : "black" }
</code></p>
]]></content>
  </entry>
  
</feed>
