<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: AQL | J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/blog/categories/aql/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2016-01-26T23:09:26+01:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Small Things in 2.8: Explain Improvements]]></title>
    <link href="http://jsteemann.github.io/blog/2016/01/26/small-things-in-28-explain-improvements/"/>
    <updated>2016-01-26T22:08:11+01:00</updated>
    <id>http://jsteemann.github.io/blog/2016/01/26/small-things-in-28-explain-improvements</id>
    <content type="html"><![CDATA[<p>Explaining AQL queries becomes even easier in ArangoDB 2.8.</p>

<p>While previous versions required writing a hard-to-memoize command like</p>

<p><code>js explaining a query in 2.7
require("org/arangodb/aql/explainer").explain(query);
</code></p>

<p>to explain an AQL query from the ArangoShell, 2.8 reduces this task to
a mere</p>

<p><code>js explaining a query in 2.8
db._explain(query);
</code></p>

<p>Apart from that, explain in 2.8 is smarter when confronted with very lengthy
query strings, and with queries that contain huge hard-coded string, array,
or object values.</p>

<!-- more -->


<p>For example, when creating an array bind variable with 1,000 values and
using them in an explained query, 2.7 would print the entire 1,000 array values
in the explain output:</p>

<p>```js explaining a query with 1000 array values
var keys = [];
for (var i = 0; i &lt; 1000; ++i) {
  keys.push(&ldquo;test&rdquo; + i);
}</p>

<p>var query = &ldquo;FOR i IN @keys RETURN i&rdquo;;
require(&ldquo;org/arangodb/aql/explainer&rdquo;).explain({
  query: query,
  bindVars: {</p>

<pre><code>keys: keys 
</code></pre>

<p>  }
});
```</p>

<p><img src="/downloads/screenshots/explain-27.png"></p>

<p>2.8 will instead truncate longer arrays and objects in the explain output for
much improved readability:</p>

<p><img src="/downloads/screenshots/explain-28.png"></p>

<p>Automatic value truncation will occur for array and object values with
more than 20 elements or for string values longer than 1,024 characters. The
truncation for explain will occur if these values are hard-coded into the
query or are passed via bind parameters.</p>

<p>Truncation only happens inside the explain results processing and thus
cannot affect the actual query results.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Small Things in 2.8: POW]]></title>
    <link href="http://jsteemann.github.io/blog/2016/01/26/small-things-in-28-pow/"/>
    <updated>2016-01-26T21:59:17+01:00</updated>
    <id>http://jsteemann.github.io/blog/2016/01/26/small-things-in-28-pow</id>
    <content type="html"><![CDATA[<p>ArangoDB 2.8 now provides a dedicated AQL function for exponentiation.
This will save users a lot of trouble in case exponentiation is needed
inside an AQL query, which up to 2.7 required writing and registering an
AQL user-defined function.</p>

<p>With 2.8 it becomes as simple as <code>RETURN POW(2, 16)</code> to raise <em>2</em>
to the power of <em>16</em> from inside AQL.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AQL Optimizer Improvements for 2.8]]></title>
    <link href="http://jsteemann.github.io/blog/2015/12/22/aql-optimizer-improvements-for-28/"/>
    <updated>2015-12-22T22:39:30+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/12/22/aql-optimizer-improvements-for-28</id>
    <content type="html"><![CDATA[<p>With the 2.8 beta phase coming to an end it&rsquo;s time to shed some light
on the improvements in the 2.8 AQL optimizer. This blog post summarizes
a few of them, focusing on the query optimizer. There&rsquo;ll be a follow-up
post that will explain dedicated new AQL features soon.</p>

<!-- more -->


<h2>Array indexes</h2>

<p>2.8 allows creating hash and skiplist indexes on attributes which are arrays.
Creating such index works similar to creating a non-array index, with the
exception that the name of the array attribute needs to be followed by a <code>[*]</code>
in the index fields definition:</p>

<p><code>js creating an array index
db._create("posts");
db.posts.ensureIndex({ type: "hash", fields: [ "tags[*]" ] });
</code></p>

<p>Now if the <code>tags</code> attribute of a document in the <code>posts</code> collection is an array,
each array member will be inserted into the index:</p>

<p><code>js storing an array value
db.posts.insert({ tags: [ "arangodb", "database", "aql" ] });
db.posts.insert({ tags: [ "arangodb", "v8", "javascript" ] });
db.posts.insert({ tags: [ "javascript", "v8", "nodejs" ] });
</code></p>

<p>The index on <code>tags[*]</code> will now contain the values <code>arangodb</code>, <code>database</code>, <code>aql</code> and
<code>nosql</code> for the first document, <code>arangodb</code>, <code>v8</code> and <code>javascript</code> for the second, and
<code>javascript</code>, <code>v8</code> and <code>nodejs</code> for the third.</p>

<p>The following AQL will find any documents that have a value of <code>javascript</code> contained
in their <code>tags</code> value:</p>

<p><code>plain array index query
FOR doc IN posts
  FILTER 'javascript' IN doc.tags[*]
  RETURN doc
</code></p>

<p>This will use the array index on <code>tags[*]</code>.</p>

<p>The array index works by inserting all members from an array into the index
separately. Duplicates are removed automatically when populating the index.</p>

<p>An array index can also be created on a sub-attribute of array members. For
example, the following definition will make sure the <code>name</code> sub-attributes of
the <code>tags</code> array values will make it into the index:</p>

<p><code>js creating an array index on a sub-attribute
db.posts.ensureIndex({ type: "hash", fields: [ "tags[*].name" ] });
</code></p>

<p>That will allow storing data as follows:</p>

<p><code>js storing an array value
db.posts.insert({ tags: [ { name: "arangodb" }, { name: "database" }, { name: "aql" } ] });
db.posts.insert({ tags: [ { name: "arangodb" }, { name: "v8" }, { name: "javascript" } ] });
db.posts.insert({ tags: [ { name: "javascript" }, { name: "v8" }, { name: "nodejs" } ] });
</code></p>

<p>The (index-based) selection query for this data structure then becomes</p>

<p><code>plain array index query using sub-attributes
FOR doc IN posts
  FILTER 'javascript' IN doc.tags[*].name
  RETURN doc
</code></p>

<p>Contrary to MongoDB, there is no automatic conversion to array values when
inserting non-array values in ArangoDB. For example, the following plain strings
will not be inserted into an array index, simply because the value of the index
attribute is not an array:</p>

<p><code>js storing non array values without indexing
db.posts.insert({ tags: "arangodb" });
db.posts.insert({ tags: "javascript" });
db.posts.insert({ tags: "nodejs" });
</code></p>

<p>Note that in this case a non-array index can still be used.</p>

<h2>Use of multiple indexes per collection</h2>

<p>The query optimizer can now make use of multiple indexes if multiple filter
conditions are combined with logical ORs, and all of them are covered by
indexes of the same collection.</p>

<p>Provided there are separate indexes present on <code>name</code> and <code>status</code>, the
following query can make use of index scans in 2.8, as opposed to full
collection scans in 2.7:</p>

<p><code>plain using multiple indexes
FOR doc IN users
  FILTER doc.name == 'root' || doc.status == 'active'
  RETURN doc
</code></p>

<p><img src="/downloads/screenshots/multiple-indexes.png"></p>

<p>If multiple filter conditions match for the same document, the result will
automatically be deduplicated, so each document is still returned at most once.</p>

<h2>Sorted IN comparison</h2>

<p>Another improvement for the optimizer is to pre-sort comparison values for <code>IN</code> and
<code>NOT IN</code> so these operators can use a (much faster) binary search instead of a linear search.</p>

<p>The optimization will be applied automatically for <code>IN</code> / <code>NOT IN</code> comparison values used
in filters, which are used inside of a <code>FOR</code> loop, and depend on runtime values. For example,
the optimization will be applied for the following query:</p>

<p><code>
LET values = /* some runtime expression here */
FOR doc IN collection
  FILTER doc.value IN values
  RETURN doc
</code></p>

<p>The optimization will not be applied for <code>IN</code> comparison values that are value
literals and those that are used in index lookups. For these cases the comparison values
were already deduplicated and sorted.</p>

<p>&ldquo;sort-in-values&rdquo; will appear in the list of applied optimizer rules if the optimizer
could apply the optimization:</p>

<p><img src="/downloads/screenshots/sorted-in.png"></p>

<h2>Optimization for LENGTH(collection)</h2>

<p>There are multiple ways for counting the total number of documents in a collection from
inside an AQL query. One obvious way is to use <code>RETURN LENGTH(collection)</code>.</p>

<p>That variant however was inefficient as it fully materialized the documents before
counting them. In 2.8 calling <code>LENGTH()</code> for a collection will get automatically replaced
by a call to a special function that can efficiently determine the number of documents.
For larger collections, this can be several thousand times faster than the naive 2.7
solution.</p>

<h2>C++ implementation for many AQL functions</h2>

<p>Many existing AQL functions have been backed with a C++ implementation that removes
the need for some data conversion that would otherwise happen if the function were
implemented in V8/JavaScript only. More than 30+ functions have been changed, including
several that may produce bigger result sets (such as <code>EDGES()</code>, <code>FULLTEXT()</code>, <code>WITHIN()</code>,
<code>NEAR()</code>) and that will hugely benefit from this.</p>

<h2>Improved skip performance</h2>

<p>2.8 improves the performance of skipping over many documents in case no indexes and no
filters are used. This might sound like an edge case, but it is quite common when the
task is to fetch documents from a big collection in chunks and there is certainty that
there will be no parallel modifications.</p>

<p>For example, the following query runs about 3 to 5 times faster in 2.8, and this
improvements can easily sum up to notable speedups if the query is called repeatedly
with increasing offset values for <code>LIMIT</code>:</p>

<p><code>plain query with huge skip
FOR doc IN collection
  LIMIT 1000000, 10
  RETURN doc
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AQL Function Speedups]]></title>
    <link href="http://jsteemann.github.io/blog/2015/11/20/aql-function-speedups/"/>
    <updated>2015-11-20T16:55:34+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/11/20/aql-function-speedups</id>
    <content type="html"><![CDATA[<p>While working on the upcoming ArangoDB 2.8, we have reimplemented some AQL
functions in C++ for improved performance. AQL queries using these functions
may benefit from using the new implementation of the function.</p>

<p>The following list shows the AQL functions for which a C++ implementation has
been added in 2.8. The other C++-based AQL function implementations added since
ArangoDB 2.5 are also still available. Here&rsquo;s the list of functions added in 2.8:</p>

<!-- more -->


<ul>
<li>document-related functions: DOCUMENT, EDGES, PARSE_IDENTIFIER</li>
<li>numerical functions: ABS, FLOOR, RAND, ROUND, SQRT</li>
<li>statistical functions: MEDIAN, PERCENTILE, STDDEV_POPULATION, STDDEV_SAMPLE, VARIANCE_POPULATION, VARIANCE_SAMPLE</li>
<li>geo functions: NEAR, WITHIN</li>
<li>array functions: APPEND, FIRST, FLATTEN, LAST, MINUS, NTH, POP, POSITION, PUSH, REMOVE_NTH, REMOVE_VALUE, REMOVE_VALUES, SHIFT, UNSHIFT</li>
<li>informational functions: COLLECTIONS, CURRENT_DATABASE, FIRST_DOCUMENT, FIRST_LIST, NOT_NULL</li>
<li>object-related functions: MERGE_RECURSIVE, ZIP</li>
</ul>


<p>Following are a few example queries that benefit from using the C++ variants of some
of the above functions:</p>

<h3>Fetching documents programmatically using the <code>DOCUMENT</code> function:</h3>

<ul>
<li>query: <code>FOR i IN 1..10000 RETURN DOCUMENT(test, CONCAT('test', i))</code></li>
<li>2.7: 0.3005 s</li>
<li>2.8: 0.1050 s</li>
</ul>


<h3>Fetching edges programmatically using the <code>EDGES</code> function:</h3>

<ul>
<li>query: <code>FOR i IN 1..100000 RETURN EDGES(edges, CONCAT('test/test', i), 'outbound')</code>:</li>
<li>2.7: 4.3590 s</li>
<li>2.8: 1.4469 s</li>
</ul>


<h3>Fetching many documents from a geo index, post-filtering most of them:</h3>

<ul>
<li>query: <code>FOR doc IN WITHIN(locations, 0, 0, 100000) FILTER doc.value2 == 'test1001' LIMIT 1 RETURN doc</code></li>
<li>2.7: 2.9876 s</li>
<li>2.8: 0.4087 s</li>
</ul>


<h3>Generating random numbers:</h3>

<ul>
<li>query: <code>FOR value IN 1..100000 RETURN RAND() * 50</code></li>
<li>2.7: 0.1743 s</li>
<li>2.8: 0.1364 s</li>
</ul>


<p>Please note that not in every case there will be a tremendous speedup. As usual,
it depends on how often a function is called inside a query and what other constructs
are used. Your mileage may vary.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Multiple Indexes Per Collection]]></title>
    <link href="http://jsteemann.github.io/blog/2015/11/20/using-multiple-indexes-per-collection/"/>
    <updated>2015-11-20T15:30:05+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/11/20/using-multiple-indexes-per-collection</id>
    <content type="html"><![CDATA[<p>The query optimizer in ArangoDB 2.8 has been improved in terms of how it can
make use of indexes. In previous versions of ArangoDB, the query optimizer could
use only one index per collection used in an AQL query. When using a logical OR
in a FILTER condition, the optimizer did not use any index for the collection in
order to ensure the result is still correct.</p>

<p>This is much better in 2.8. Now the query optimizer can use multiple indexes on
the same collection for FILTER conditions that are combined with a logical OR.</p>

<!-- more -->


<p>For all following queries, I have set up a collection named <code>test</code>, which has
two isolated hash indexes on the attributes <code>value1</code> and <code>value2</code>, and a skiplist
index on attribute <code>value3</code>.</p>

<p>Let&rsquo;s first try an AQL queries that uses a logical OR on two different attributes of the
collection:</p>

<p><code>plain example query
FOR doc IN test
  FILTER doc.value1 == 11 || doc.value2 == 19
  RETURN doc
</code></p>

<p>The execution plan for this query in 2.7 reveals that query will perform a full
collection scan and cannot use indexes because of the logical OR on two different
attributes:</p>

<p><code>``plain 2.7 query execution plan
Execution plan:
 Id   NodeType                  Est.   Comment
  1   SingletonNode                1   * ROOT
  2   EnumerateCollectionNode      0     - FOR doc IN test   /* full collection scan */
  3   CalculationNode              0       - LET #1 = doc.</code>value1<code>== 11 || doc.</code>value2` == 19
  4   FilterNode                   0       &ndash; FILTER #1
  5   ReturnNode                   0       &ndash; RETURN doc</p>

<p>Indexes used:
 none</p>

<p>Optimization rules applied:
 none
```</p>

<p>Running the same query in 2.8 / devel will produce a much better execution plan:</p>

<p><code>``plain 2.8 query execution plan
Execution plan:
 Id   NodeType          Est.   Comment
  1   SingletonNode        1   * ROOT
  6   IndexNode            2     - FOR doc IN test   /* hash index scan, hash index scan */
  3   CalculationNode      2       - LET #1 = doc.</code>value1<code>== 11 || doc.</code>value2` == 19<br/>
  4   FilterNode           2       &ndash; FILTER #1
  5   ReturnNode           2       &ndash; RETURN doc</p>

<p>Indexes used:
 By   Type   Collection   Unique   Sparse   Selectivity   Fields         Ranges
  6   hash   test         false    false       100.00 %   [ <code>value1</code> ]   doc.<code>value1</code> == 11
  6   hash   test         false    false       100.00 %   [ <code>value2</code> ]   doc.<code>value2</code> == 19</p>

<p>Optimization rules applied:
 Id   RuleName
  1   use-indexes
```</p>

<p>Multiple indexes will also be used if different index types are accessed, or for non-equality
filter conditions. For example, the following query will make use of the two hash indexes
and also the skiplist index:</p>

<p><code>plain example query
FOR doc IN test
  FILTER doc.value1 == 11 || doc.value2 == 19 || doc.value3 &gt; 42
  RETURN doc
</code></p>

<p>Here is its execution plan from 2.8:</p>

<p><code>``plain 2.8 query execution plan
Execution plan:
 Id   NodeType          Est.   Comment
  1   SingletonNode        1   * ROOT
  6   IndexNode            3     - FOR doc IN test   /* hash index scan, hash index scan, skiplist index scan */
  3   CalculationNode      3       - LET #1 = doc.</code>value1<code>== 11 || doc.</code>value2<code>== 19 || doc.</code>value3` > 42
  4   FilterNode           3       &ndash; FILTER #1
  5   ReturnNode           3       &ndash; RETURN doc</p>

<p>Indexes used:
 By   Type       Collection   Unique   Sparse   Selectivity   Fields         Ranges
  6   hash       test         false    false       100.00 %   [ <code>value1</code> ]   doc.<code>value1</code> == 11
  6   hash       test         false    false       100.00 %   [ <code>value2</code> ]   doc.<code>value2</code> == 19
  6   skiplist   test         false    false            n/a   [ <code>value3</code> ]   doc.<code>value3</code> > 42</p>

<p>Optimization rules applied:
 Id   RuleName
  1   use-indexes
```</p>

<p>For comparison, here is the non-optimized plan from 2.7 for the same query:</p>

<p><code>``plain 2.7 query execution plan
Execution plan:
 Id   NodeType                  Est.   Comment
  1   SingletonNode                1   * ROOT
  2   EnumerateCollectionNode      0     - FOR doc IN test   /* full collection scan */
  3   CalculationNode              0       - LET #1 = doc.</code>value1<code>== 11 || doc.</code>value2<code>== 19 || doc.</code>value3` > 42
  4   FilterNode                   0       &ndash; FILTER #1
  5   ReturnNode                   0       &ndash; RETURN doc</p>

<p>Indexes used:
 none</p>

<p>Optimization rules applied:
 none
```</p>

<p>Still the query optimizer will not be able to use any indexes on a collection when
there are multiple FILTER conditions combined with logical OR and at least one of them
is not satisfisable by an index of the collection. In this case it has no other choice
but to do a full collection scan.</p>

<p>For queries that combine multiple FILTER conditions with a logical AND, the optimizer
will still try to pick the most selective index for the query and use it for the collection.</p>
]]></content>
  </entry>
  
</feed>
