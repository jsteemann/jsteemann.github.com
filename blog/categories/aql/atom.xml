<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: AQL | J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/blog/categories/aql/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2015-11-20T16:20:12+01:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using Multiple Indexes Per Collection]]></title>
    <link href="http://jsteemann.github.io/blog/2015/11/20/using-multiple-indexes-per-collection/"/>
    <updated>2015-11-20T15:30:05+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/11/20/using-multiple-indexes-per-collection</id>
    <content type="html"><![CDATA[<p>The query optimizer in ArangoDB 2.8 has been improved in terms of how it can
make use of indexes. In previous versions of ArangoDB, the query optimizer could
use only one index per collection used in an AQL query. When using a logical OR
in a FILTER condition, the optimizer did not use any index for the collection in
order to ensure the result is still correct.</p>

<p>This is much better in 2.8. Now the query optimizer can use multiple indexes on
the same collection for FILTER conditions that are combined with a logical OR.</p>

<!-- more -->


<p>For all following queries, I have set up a collection named <code>test</code>, which has
two isolated hash indexes on the attributes <code>value1</code> and <code>value2</code>, and a skiplist
index on attribute <code>value3</code>.</p>

<p>Let&rsquo;s first try an AQL queries that uses a logical OR on two different attributes of the
collection:</p>

<p><code>plain example query
FOR doc IN test
  FILTER doc.value1 == 11 || doc.value2 == 19
  RETURN doc
</code></p>

<p>The execution plan for this query in 2.7 reveals that query will perform a full
collection scan and cannot use indexes because of the logical OR on two different
attributes:</p>

<p><code>``plain 2.7 query execution plan
Execution plan:
 Id   NodeType                  Est.   Comment
  1   SingletonNode                1   * ROOT
  2   EnumerateCollectionNode      0     - FOR doc IN test   /* full collection scan */
  3   CalculationNode              0       - LET #1 = doc.</code>value1<code>== 11 || doc.</code>value2` == 19
  4   FilterNode                   0       &ndash; FILTER #1
  5   ReturnNode                   0       &ndash; RETURN doc</p>

<p>Indexes used:
 none</p>

<p>Optimization rules applied:
 none
```</p>

<p>Running the same query in 2.8 / devel will produce a much better execution plan:</p>

<p><code>``plain 2.8 query execution plan
Execution plan:
 Id   NodeType          Est.   Comment
  1   SingletonNode        1   * ROOT
  6   IndexNode            2     - FOR doc IN test   /* hash index scan, hash index scan */
  3   CalculationNode      2       - LET #1 = doc.</code>value1<code>== 11 || doc.</code>value2` == 19<br/>
  4   FilterNode           2       &ndash; FILTER #1
  5   ReturnNode           2       &ndash; RETURN doc</p>

<p>Indexes used:
 By   Type   Collection   Unique   Sparse   Selectivity   Fields         Ranges
  6   hash   test         false    false       100.00 %   [ <code>value1</code> ]   doc.<code>value1</code> == 11
  6   hash   test         false    false       100.00 %   [ <code>value2</code> ]   doc.<code>value2</code> == 19</p>

<p>Optimization rules applied:
 Id   RuleName
  1   use-indexes
```</p>

<p>Multiple indexes will also be used if different index types are accessed, or for non-equality
filter conditions. For example, the following query will make use of the two hash indexes
and also the skiplist index:</p>

<p><code>plain example query
FOR doc IN test
  FILTER doc.value1 == 11 || doc.value2 == 19 || doc.value3 &gt; 42
  RETURN doc
</code></p>

<p>Here is its execution plan from 2.8:</p>

<p><code>``plain 2.8 query execution plan
Execution plan:
 Id   NodeType          Est.   Comment
  1   SingletonNode        1   * ROOT
  6   IndexNode            3     - FOR doc IN test   /* hash index scan, hash index scan, skiplist index scan */
  3   CalculationNode      3       - LET #1 = doc.</code>value1<code>== 11 || doc.</code>value2<code>== 19 || doc.</code>value3` > 42
  4   FilterNode           3       &ndash; FILTER #1
  5   ReturnNode           3       &ndash; RETURN doc</p>

<p>Indexes used:
 By   Type       Collection   Unique   Sparse   Selectivity   Fields         Ranges
  6   hash       test         false    false       100.00 %   [ <code>value1</code> ]   doc.<code>value1</code> == 11
  6   hash       test         false    false       100.00 %   [ <code>value2</code> ]   doc.<code>value2</code> == 19
  6   skiplist   test         false    false            n/a   [ <code>value3</code> ]   doc.<code>value3</code> > 42</p>

<p>Optimization rules applied:
 Id   RuleName
  1   use-indexes
```</p>

<p>For comparison, here is the non-optimized plan from 2.7 for the same query:</p>

<p><code>``plain 2.7 query execution plan
Execution plan:
 Id   NodeType                  Est.   Comment
  1   SingletonNode                1   * ROOT
  2   EnumerateCollectionNode      0     - FOR doc IN test   /* full collection scan */
  3   CalculationNode              0       - LET #1 = doc.</code>value1<code>== 11 || doc.</code>value2<code>== 19 || doc.</code>value3` > 42
  4   FilterNode                   0       &ndash; FILTER #1
  5   ReturnNode                   0       &ndash; RETURN doc</p>

<p>Indexes used:
 none</p>

<p>Optimization rules applied:
 none
```</p>

<p>Still the query optimizer will not be able to use any indexes on a collection when
there are multiple FILTER conditions combined with logical OR and at least one of them
is not satisfisable by an index of the collection. In this case it has no other choice
but to do a full collection scan.</p>

<p>For queries that combine multiple FILTER conditions with a logical AND, the optimizer
will still try to pick the most selective index for the query and use it for the collection.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Index Speedups in 2.8]]></title>
    <link href="http://jsteemann.github.io/blog/2015/11/20/index-speedups-for-28/"/>
    <updated>2015-11-20T15:11:00+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/11/20/index-speedups-for-28</id>
    <content type="html"><![CDATA[<p>The upcoming 2.8 version of ArangoDB will provide several improvements in
the area of index usage and query optimization.</p>

<p>First of all, hash and skiplist indexes can now index individual array values.
A dedicated post on this will follow shortly. Second, the query optimizer can
make use multiple indexes per collection for queries with OR-combined filter
conditions. This again is a subject for <a href="/blog/2015/11/20/using-multiple-indexes-per-collection/">another post</a>.
Third, there have been some speed improvements due to changes in the general
index handling code. This is what this post is about.</p>

<!-- more -->


<p>In order to assess the speedups in 2.8, I have run some already existing performance
tests that I initially ran when comparing ArangoDB 2.5 with 2.6. The test cases and
methodology are detailed in <a href="/blog/2015/05/20/the-great-aql-shootout-arangodb-25-vs-26/">this earlier blog post</a>.</p>

<p>For measuring the index-related performance improvements, I simply re-ran the
index related tests in 2.7 and in 2.8 / devel. I did not bother re-running all
tests from the original blog article because only some are index-related. In
particular, I only ran these tests again:</p>

<ul>
<li><em>join-key</em>: for each document in the collection, perform a join on the <code>_key</code> attribute on the collection
 itself (i.e. <code>FOR c1 IN @@c FOR c2 IN @@c FILTER c1._key == c2._key RETURN c1</code>)</li>
<li><em>join-id</em>: ditto, but perform the join using the <code>_id</code> attribute</li>
<li><em>join-hash-number</em> and <em>join-hash-string</em>: ditto, but join using a hash index on a numeric or string
 attribute</li>
<li><em>join-skiplist-number</em> and <em>join-skiplist-string</em>: ditto, but join using a skiplist index on a numeric or
 string attribute</li>
<li><em>lookup-key</em>, <em>lookup-hash-number</em>, <em>lookup-hash-string</em>, <em>lookup-skiplist-number</em>, <em>lookup-skiplist-string</em>:
 compile an IN-list of 10,000 lookup values and search these 10,000 documents in the collection using
 either the primary index (<code>_key</code> attribute), a hash index or a skiplist index. The latter two are tested
 on numeric and string attributes.</li>
</ul>


<p>The test queries were run 5 times each on collections containing 10,000, 100,000 and
1,000,000 documents.</p>

<p>Here are the query execution times from 2.7 and 2.8 for the individual tests, in
seconds (less is better):</p>

<p>```plain test results</p>

<h2>test name                collection     avg 2.7 (s)      avg 2.8 (s)</h2>

<p>join-key                 10k                 0.0997           0.0612
join-key                 100k                1.0611           0.6538
join-key                 1000k              10.2975           6.2507
join-id                  10k                 0.1088           0.0606
join-id                  100k                1.1126           0.6694
join-id                  1000k              10.8180           6.5336
join-hash-number         10k                 0.1044           0.0679
join-hash-number         100k                1.1137           0.7430
join-hash-number         1000k              10.7923           7.1534
join-hash-string         10k                 0.1193           0.0712
join-hash-string         100k                1.2656           0.7915
join-hash-string         1000k              12.3075           7.6667
join-skiplist-number     10k                 0.1387           0.1030
join-skiplist-number     100k                1.6693           1.3062
join-skiplist-number     1000k              18.0406          15.5203
join-skiplist-string     10k                 0.1928           0.1469
join-skiplist-string     100k                2.3166           1.8997
join-skiplist-string     1000k              27.1513          23.2058
lookup-key               10k                 1.4996           1.5245
lookup-key               100k                1.4951           1.5189
lookup-key               1000k               1.5545           1.5662
lookup-hash-number       10k                 1.5572           1.5526
lookup-hash-number       100k                1.5595           1.5435
lookup-hash-number       1000k               1.5436           1.5648
lookup-hash-string       10k                 1.6023           1.5623
lookup-hash-string       100k                1.5892           1.5741
lookup-hash-string       1000k               1.5841           1.5770
lookup-skiplist-number   10k                 1.5978           1.6145
lookup-skiplist-number   100k                1.5782           1.6269
lookup-skiplist-number   1000k               1.5891           1.6258
lookup-skiplist-string   10k                 1.6443           1.6840
lookup-skiplist-string   100k                1.6787           1.6985
lookup-skiplist-string   1000k               1.7319           1.7562
in-key                   10k                 0.1076           0.0754
in-key                   100k                0.1083           0.0775
in-key                   1000k               0.1104           0.0773
in-hash-number           10k                 0.0898           0.0696
in-hash-number           100k                0.0889           0.0674
in-hash-number           1000k               0.0877           0.0675
in-hash-string           10k                 0.1174           0.0867
in-hash-string           100k                0.1188           0.0878
in-hash-string           1000k               0.1174           0.0853
in-skiplist-number       10k                 0.1095           0.0849
in-skiplist-number       100k                0.1110           0.0873
in-skiplist-number       1000k               0.1106           0.0910
in-skiplist-string       10k                 0.1744           0.1315
in-skiplist-string       100k                0.1990           0.1594
in-skiplist-string       1000k               0.2369           0.1968
```</p>

<p>It looks like joins and IN list lookups got significantly faster in 2.8, whereas
the performance for point lookups is more or less the same as in 2.7.</p>

<p>Note that the changes to the index code in 2.8 only affect how indexes are accessed
from within AQL queries and how filtering works. No changes have been made for other
index operations such as insert, updates, and removals.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improved Deadlock Detection]]></title>
    <link href="http://jsteemann.github.io/blog/2015/11/18/improved-deadlock-detection/"/>
    <updated>2015-11-18T19:24:24+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/11/18/improved-deadlock-detection</id>
    <content type="html"><![CDATA[<p>The upcoming ArangoDB version 2.8 (currently in devel) will
provide a much better deadlock detection mechanism than its
predecessors.</p>

<p>The new deadlock detection mechanism will kick in automatically
when it detects operations that are mutually waiting for each other.
In case it finds such deadlock, it will abort one of the operations
so that the others can continue and overall progress can be made.</p>

<!-- more -->


<p>In previous versions of ArangoDB, deadlocks could make operations
wait forever, requiring the server to be stopped and restarted.</p>

<h2>How deadlocks can occur</h2>

<p>Here&rsquo;s a simple example for getting into a deadlock state:</p>

<p>Transaction A wants to write to collection c1 and to read from collection
c2. In parallel, transaction B wants to write to collection c2 and read
from collection c1. If the sequence of operations is interleaved as follows,
then the two transactions prevent each other from making progress:</p>

<ul>
<li>transaction A successfully acquires write-lock on c1</li>
<li>transaction B sucessfull acquires write-lock on c2</li>
<li>transaction A tries to acquire read-lock on c2 (and must wait for B)</li>
<li>transaction B tries to acquire read-lock on c1 (and must wait for A)</li>
</ul>


<p>Here&rsquo;s these such two transactions being started from two ArangoShell
instances in parallel (left is A, right is B):</p>

<p><img src="/downloads/screenshots/deadlock.png"></p>

<p>(note that this screenshot is from 2.8 and the automatic deadlock detection
had already detected the deadlock and aborted one of the transactions)</p>

<p>In general, deadlocks can occur only when multiple operations (AQL
queries or other transactions) try to access the same resources
(collections) at the same time, and only if the operations already
have already acquired some locks on these resources. And finally
each operation needs to involve more than one collection, so there
is the potential for already having acquired some locks but having
to wait for others.</p>

<h2>Dynamically added collections</h2>

<p>Most operations will just work fine and will not cause any deadlocks.
This is especially true for all operations that involve only a single
collection. This leaves multi-collection AQL queries and multi-collection
userland transactions.</p>

<p>Normally these will also work fine. This is because when a query or
transaction starts, it will tell the transaction manager about the resources
(collections) it will need. The transaction manager can then acquire the
required resources in a deterministic fashion that prevents deadlocks.
If all queries and transactions properly announce upfront which collections
they will access, there will also be no deadlocks.</p>

<p>But for some operations its hard to predict at transaction start which
collections will be accessed. This includes some AQL functions that
can dynamically access collection data without having to specify the
collection name anywhere in the query.</p>

<p>A good example for this is the <code>GRAPH_EDGES</code> AQL function, which will get
a graph name as its first input parameter, but not the names of the underlying
edge collection(s). When this function is used in an AQL query, the
query parser will just find a function parameter containing a graph name
but doesn&rsquo;t know it&rsquo;s a collection name.</p>

<p><code>
GRAPH_EDGES("myEdges", [ { type: "friend" } ])
</code></p>

<p>The <code>"myEdges"</code> graph name will look like any other string to the parser.
It does not know about the contexts in which strings may have special meanings.</p>

<p>Note that even if this would be fixed, the problem won&rsquo;t go away entirely:
a function call parameter in a query isn&rsquo;t necessarily a constant but can
be an arbitrary expression:</p>

<p><code>
FOR doc IN collection
  RETURN GRAPH_EDGES(CONCAT(doc.graphName, '-test'), [ doc.example ])
</code></p>

<p>At least in this case the AQL query parser won&rsquo;t find a collection name,
so when the AQL query starts it is yet unknown which collections will be
accessed. Only at runtime when the function is actually executed, the
collection names will be looked up by finding the graph description in the
<code>_graphs</code>system collection. Then the edge collections participating in
the graph will be added to the query dynamically. Only this dynamic addition
adds the potential for deadlock.</p>

<p>This dynamic addition of collections in unavoidable for conveniently
querying data from collections whose names are unknown when the query starts.</p>

<h2>Deadlock detection</h2>

<p>Whenever transaction manager detects a deadlock in ArangoDB 2.8, it will
automatically abort one of the blocking transactions. The transaction will
be rolled back and all modifications it has made will be reverted. The
operation will fail with error code 29 (<em>deadlock detected</em>) and raise an
exception that the user can handle in the calling code.</p>

<p>Deadlocks will be found if two transactions mutually lock each other as
seen in the screenshot above, but also for more complex setups. The following
screenshot shows four parallel transactions that block each other indirectly.</p>

<p><img src="/downloads/screenshots/threeway-deadlock.png"></p>

<p>The top left window (transaction 1) will block the one in the top right
(transaction 2), and is itself blocked by the transaction in the bottom left
(transaction 3).</p>

<p>The transaction in the top right window (transaction 2) blocks the one in the
bottom left (transaction 3), and is itself blocked by the one in the top left
(transaction 1).</p>

<p>Transaction 3 (bottom left) is blocked by transaction 2 (top right).
Transaction 4 (bottom right) does exactly the same as transaction 3.</p>

<p>With these transactions, we end up in this waiting state:</p>

<ul>
<li>T1 waits for T3 and T4</li>
<li>T2 waits for T1</li>
<li>T3 waits for T2</li>
<li>T4 waits for T2</li>
</ul>


<p>This waiting state is cyclic (T1 &lt; T3 &lt; T2 &lt; T1) and therefore no progress
can be made. This is exactly a situation in which the transaction manager
will abort one of the transactions.</p>

<p>No configuration is required for the deadlock detection mechanism. It will
always be active and cannot be configured or turned off.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Bind Parameters in the AQL Editor]]></title>
    <link href="http://jsteemann.github.io/blog/2015/11/18/bind-parameters-in-aql-editor/"/>
    <updated>2015-11-18T19:24:24+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/11/18/bind-parameters-in-aql-editor</id>
    <content type="html"><![CDATA[<p>The AQL editor in the web interface is useful for running ad hoc AQL
queries and trying things out. It provides a feature to <em>explain</em> the
query and inspect its execution plan. This can be used to check if the
query uses indexes, and which.</p>

<p>So far the AQL editor only supported using query string literals, but <strong>it
lacked support for bind parameters</strong>. Queries issued by application code
however often <strong>will use bind parameters</strong> for security reasons. Often
enough this prevented copying &amp; pasting queries from the application code into
the AQL editor and vice versa without making manual adjustments.</p>

<!-- more -->


<p>This has been fixed in the upcoming ArangoDB version 2.8 (currently in
development). Bind parameters can now be used in the AQL editor as well.
Bind parameters can be entered as JSON values, the same format that is
used for bind parameters in the HTTP REST API and in (JavaScript) application
code.</p>

<p>The queries can also be saved in the AQL editor along with their bind parameter
values for later reuse.</p>

<p>Screenshot from the feature in 2.8:</p>

<p><img src="/downloads/screenshots/bind-parameters.png"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Building AQL Query Strings]]></title>
    <link href="http://jsteemann.github.io/blog/2015/08/30/on-building-aql-query-strings/"/>
    <updated>2015-08-30T23:14:42+02:00</updated>
    <id>http://jsteemann.github.io/blog/2015/08/30/on-building-aql-query-strings</id>
    <content type="html"><![CDATA[<p>I recently wrote two recipes about generating AQL query
strings. They are contained in the ArangoDB cookbook by now:</p>

<ul>
<li><a href="https://docs.arangodb.com/cookbook/AvoidingInjection.html">Avoiding parameter injection in AQL</a></li>
<li><a href="https://docs.arangodb.com/cookbook/MultilineQueryStrings.html">Writing multi-line AQL queries</a></li>
</ul>


<p>After that, Github user <em>tracker1</em> suggested in <a href="https://github.com/arangodb/arangodb/issues/1457">Github issue 1457</a>
to take the ES6 template string variant even further, using a generator function for
string building, and also using promises and ES7 async/await.</p>

<p>We can&rsquo;t use ES7 async/await in ArangoDB at the moment due to lacking support
in V8, but the suggested template string generator function seemed to be an
obvious improvement that deserved inclusion in ArangoDB.</p>

<!-- more -->


<p>Basically, the suggestion is to use regular JavaScript variables/expressions in
the template string and have them substituted <em>safely</em>.</p>

<p>With regular AQL bind parameters, a query looks like this:</p>

<p><code>``js
var bindVars = { name: "test" };
var query =</code>FOR doc IN collection</p>

<pre><code>         FILTER doc.name == @name 
         RETURN doc._key`;
</code></pre>

<p>db._query(query, bindVars);
```</p>

<p>This is immune to parameter injection, because the query string and the bind parameter
value are passed in separately. But it&rsquo;s <strong>not very ES6-y</strong>.</p>

<p>Now, after partly implementing <em>tracker1</em>&rsquo;s suggestion, JavaScript values
and expressions can be used much more <em>naturally</em> when building AQL query strings:</p>

<p><code>``js
var name = "test";
var query = aqlQuery</code>FOR doc IN collection</p>

<pre><code>                 FILTER doc.name == ${name} 
                 RETURN doc._key`;
</code></pre>

<p>db._query(query);
```</p>

<p><code>${name}</code> is regular ES template string syntax and would normally be substituted
with the value of JavaScript variable <code>name</code>. Such simple substitution would be unsafe,
because it would make the query vulnerable to parameter injection. So we&rsquo;re also
using a template string generator function named <code>aqlQuery</code>. This function comes
bundled with ArangoDB 2.7.</p>

<p>Under the hood, <code>aqlQuery</code> will create regular AQL bind parameters for each occurrence
of a template string parameter. It will keep the query string and the actual bind
parameter values separate, so it is safe to use.</p>

<p>The function will return an object with that can directly be passed on to the
<code>db._query()</code> function. Here&rsquo;s what <code>aqlQuery</code> will generate for the above example
(note: some whitespace was removed from the output):</p>

<p>```js
{
  &ldquo;query&rdquo; : &ldquo;FOR doc IN collection FILTER doc.name == @value0 RETURN doc._key&rdquo;,
  &ldquo;bindVars&rdquo; : {</p>

<pre><code>"value0" : "test" 
</code></pre>

<p>  }
}
```</p>

<p>The <code>aqlQuery</code> template string generator function is available in 2.7, which is
currently in development. The changes are contained in the <code>devel</code> branch only
at the moment, but will become available in following 2.7 release. A pull request
has been issued to have the cookbook recipes updated to include <code>aqlQuery</code>, too.</p>

<p><code>aqlQuery</code> can be used in 2.7 from the ArangoShell, inside arangod (e.g. from inside
Foxx actions) and from ArangoDB&rsquo;s web interface.</p>

<p>All other variants for building AQL queries are still fully supported.</p>
]]></content>
  </entry>
  
</feed>
