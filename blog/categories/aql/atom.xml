<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: AQL | J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/blog/categories/aql/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2015-03-30T09:19:11+02:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Improvements for Data-modification Queries]]></title>
    <link href="http://jsteemann.github.io/blog/2015/03/27/improvements-for-data-modification-queries/"/>
    <updated>2015-03-27T23:29:19+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/03/27/improvements-for-data-modification-queries</id>
    <content type="html"><![CDATA[<p>Data-modification queries were enhanced in ArangoDB 2.4 to be able to also return
the inserted, update or removed documents.</p>

<p>For example, the following statement inserted a few documents and also returned
them with all their attributes:</p>

<p><code>plain AQL insert query returning documents
FOR i IN 1..10
  INSERT { value: i } IN test
  LET inserted = NEW
  RETURN inserted
</code></p>

<p>The syntax for returning documents from data-modification queries only supported
the exact above format. Using a <code>LET</code> clause was required, and the <code>RETURN</code> clause
was limited to returning the variable introduced by the <code>LET</code>.</p>

<p>These syntax restrictions have been lifted in the <code>devel</code> branch, which will become
release 2.6 eventually. The changes make returning values from data-modification
statements easier and also more flexible.</p>

<!-- more -->


<h2>Simpler syntax</h2>

<p>For example, specifying a <code>LET</code> clause is not required anymore (though still fully
supported). Instead, the <code>RETURN</code> clause can directly refer to the <code>NEW</code> pseudo-value,
making the query shorter and easier to write:</p>

<p><code>plain AQL insert query returning documents
FOR i IN 1..10
  INSERT { value: i } IN test
  RETURN NEW
</code></p>

<h2>Projections</h2>

<p>It is now also possible to return a projection instead of returning the entire documents.
This can be used to reduce the amount of data returned by queries.</p>

<p>For example, the following query will return just the keys of the inserted documents:</p>

<p><code>plain AQL insert query returning a projection
FOR i IN 1..10
  INSERT { value: i } IN test
  RETURN NEW._key
</code></p>

<h2>Using OLD and NEW in the same query</h2>

<p>In previous versions, <code>UPDATE</code> and <code>REPLACE</code> statements could refer to <strong>either</strong>
the <code>OLD</code> or the <code>NEW</code> pseudo-value, but not to both. 2.6 lifts that restriction, so
now these queries can refer to both. One can utilize that to return both the previous
and the updated revision:</p>

<p><code>plain AQL update query returning old and new revisions
FOR doc IN test
  UPDATE doc WITH { value: 42 } IN test
  RETURN { old: OLD, new: NEW }
</code></p>

<h2>Calculations with OLD or NEW</h2>

<p>It is now also possible to run additional calculations with <code>LET</code> statements between
the data-modification part and the final <code>RETURN</code>:</p>

<p><code>plain AQL upsert query with some extra calculations
UPSERT { name: 'test' } INSERT { name: 'test' } UPDATE { } IN test
LET previousRevisionExisted = ! IS_NULL(OLD)
LET type = previousRevisionExisted ? 'update' : 'insert'
RETURN { _key: NEW._key, type: type }
</code></p>

<h2>Restrictions</h2>

<p>Still the following restrictions remain:</p>

<ul>
<li><p>a data-modification operation can optionally be followed by any number of <code>LET</code> clauses,
and a final <code>RETURN</code> clause. No other operations (e.g. <code>FOR</code>, <code>SORT</code>, <code>COLLECT</code>) can be
used after a data-modification operation</p></li>
<li><p>calculations following a data-modification operation must not access data in collections,
so using functions such as <code>GRAPH_TRAVERSAL</code> etc. is disallowed.</p></li>
</ul>


<p>The improvements are present in the <code>devel</code> branch and can be tested in there from now on.
As usual, feedback is welcome!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Preview of the UPSERT Command]]></title>
    <link href="http://jsteemann.github.io/blog/2015/03/27/preview-of-the-upsert-command/"/>
    <updated>2015-03-27T21:37:09+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/03/27/preview-of-the-upsert-command</id>
    <content type="html"><![CDATA[<p>This week saw the completion of the AQL <code>UPSERT</code> command.</p>

<p>This command will be very helpful in a lot of use cases, including the following:</p>

<ul>
<li>ensure that a document exists</li>
<li>update a document if it exists, otherwise create it</li>
<li>replace a document if it exists, otherwise create it</li>
</ul>


<p>The <code>UPSERT</code> command is executed on the server side and so delivers client
applications from issuing a fetch command followed by a separate, conditional <code>UPDATE</code>
or <code>INSERT</code> command.</p>

<!-- more -->


<p>The general format of an <code>UPSERT</code> statement is:</p>

<p><code>plain UPSERT format
UPSERT search-document
INSERT insert-expression
UPDATE update-expression
IN collection-name
</code></p>

<p>Following are a few example invocations of <code>UPSERT</code>.</p>

<h2>Ensure a document exists</h2>

<p>A simple use case of <code>UPSERT</code> is to ensure that a specific document exists.
For example, the following query will ensure that that there will be a document
with attribute <code>ip</code> equal to <code>192.168.173.13</code> in collection <code>hosts</code>:</p>

<p><code>plain ensuring a document exists
UPSERT { ip: '192.168.173.13' }
INSERT { ip: '192.168.173.13', name: 'flittard' }
UPDATE { }
IN hosts
</code></p>

<p>If the document does not yet exist, the <code>INSERT</code> part will be carried out. If the
document is already there, the empty <code>UPDATE</code> part will be run, which will not
modify the document.</p>

<p>After the query has finished, there will be a document with the specified <code>ip</code> value.</p>

<p>There is no need for client applications to check for document existence first,
and then to conditionally insert or update, or to try insert first and catch errors.</p>

<p>Note: this is the same as ActiveRecord&rsquo;s <code>find_or_create</code>.</p>

<h2>Update a document if it exists, otherwise create it</h2>

<p>Another common use case is to check whether a specific document exists, and then update it.
If it does not yet exist, the document shall be created.</p>

<p>Counters are a good example for this, so let&rsquo;s demo this pattern with a counter, too:</p>

<p><code>plain UPSERT example
UPSERT { ip: '192.168.173.13' }
INSERT { ip: '192.168.173.13', name: 'flittard', counter: 1 }
UPDATE { counter : OLD.counter + 1 }
IN hosts
</code></p>

<p>The above query will again look for a document with the specified <code>ip</code> attribute. If the
document exists, its <code>counter</code> attribute will be increased by one. This is achieved by
referring to the pseudo-value <code>OLD</code>, which in the <code>UPDATE</code> case contains the previous revision
of the document.</p>

<p>If the search document does not yet exist, the <code>INSERT</code>part will be carried out, inserting
the document and setting the initial value of <code>counter</code> to 1.</p>

<p>Assuming the collection was empty before, running the above query once will make the collection
contain this data:</p>

<p>```json collection contents after running query once
[
  {</p>

<pre><code>"counter": 1,
"ip": "192.168.173.13",
"name": "flittard"
</code></pre>

<p>  }
]
```</p>

<p>When running the <code>UPSERT</code> statement again, the collection will contain the updated document:</p>

<p>```json collection contents after running the UPSERT command again:
[
  {</p>

<pre><code>"counter": 2,
"ip": "192.168.173.13",
"name": "flittard"
</code></pre>

<p>  }
]
```</p>

<p>Now let&rsquo;s run the query with adjusted <code>ip</code> and <code>name</code> values:</p>

<p><code>plain UPSERT with different ip and name
UPSERT { ip: '192.168.173.73' }
INSERT { ip: '192.168.173.73', name: 'brueck', counter: 1 }
UPDATE { counter : OLD.counter + 1 }
IN hosts
</code></p>

<p>After that, the collection will contain two documents:</p>

<p>```json collection contents
[
  {</p>

<pre><code>"counter": 2,
"ip": "192.168.173.13",
"name": "flittard"
</code></pre>

<p>  },
  {</p>

<pre><code>"counter": 1,
"name": "brueck",
"ip": "192.168.173.73"
</code></pre>

<p>  }
]
```</p>

<h2>Replace a document if it exists, otherwise create it</h2>

<p>We&rsquo;ve seen <code>UPSERT</code> with an <code>INSERT</code> and an <code>UPDATE</code> clause so far.</p>

<p><code>UPDATE</code> will partially update the previous revision of the document if present.
Only those attributes specified in the <code>update-expression</code> will be updated, and
all non-specified attributes of the original document revision will remain
unchanged.</p>

<p>If instead a full replacement of the original document is required, the <code>REPLACE</code>
clause should be used instead of <code>UPDATE</code>. <code>REPLACE</code> will overwrite the previous
revision completely with what&rsquo;s in <code>update-expression</code>.</p>

<p><code>plain UPSERT replacing a document entirely
UPSERT { ip: '192.168.173.73' }
INSERT { ip: '192.168.173.73', name: 'brueck', counter: 1 }
REPLACE { location: 'dc1' }
IN hosts
</code></p>

<p><em>note</em>: an older version of this blog post contained a wrong example here. Thanks
Andy for pointing this out!</p>

<h2>Returning documents</h2>

<p><code>UPSERT</code> can be combined with a <code>RETURN</code> statement to return either the previous
document revision (in case of <code>UPDATE</code> or <code>REPLACE</code>) or the new version of the
document.</p>

<p>Client applications can use this to check whether the <code>UPSERT</code> statement has
inserted or updated the document. In case no previous revision was present, the
pseudo-value <code>OLD</code> will be <code>null</code>.</p>

<p><code>UPSERT</code> also provides a pseudo-value named <code>NEW</code> containing the insert, updated or
replaced version of the document:</p>

<p><code>plain UPSERT with a RETURN value
UPSERT { ip: '192.168.173.187' }
INSERT { ip: '192.168.173.187', name: 'kalk', counter: 1 }
UPDATE { counter : OLD.counter + 1 }
IN hosts
RETURN { old: OLD, new: NEW }
</code></p>

<p>In the <code>INSERT</code> case, we&rsquo;ll get:</p>

<p>```json query return value for INSERT case
[
  {</p>

<pre><code>"old": null,
"new": {
  "counter": 1,
  "name": "kalk",
  "ip": "192.168.173.187"
}
</code></pre>

<p>  }
]
```</p>

<p>When running the query again, we&rsquo;ll get into the <code>UPDATE</code> case, and the same query
will now return:</p>

<p>```json query return value for the UPDATE case
[
  {</p>

<pre><code>"old": {
  "counter": 1,
  "name": "kalk",
  "ip": "192.168.173.187"
},
"new": {
  "counter": 2,
  "name": "kalk",
  "ip": "192.168.173.187"
}
</code></pre>

<p>  }
]
```</p>

<h2>Complex updates</h2>

<p>Updating and returning <code>OLD</code> and <code>NEW</code> will work with arbitrary calculations.
For example, the following query adds a value <code>development</code> to the <code>tag</code> attribute
only if not yet present in the search document:</p>

<p><code>plain adding a value to an array if not yet present
UPSERT { ip: '192.168.173.94' }                                                                              
INSERT { ip: '192.168.173.94', name: 'chorweiler', tags: [ "development" ] }                                                    
UPDATE { tags: PUSH(OLD.tags, "development", true) }                                                                          
IN hosts                                                                                                      
RETURN { old: OLD, new: NEW }
</code></p>

<p>Running the query multiple times will ensure that <code>tags</code> will contain the value
<code>development</code> only once.</p>

<p>Note: <code>PUSH</code> is a regular <a href="https://docs.arangodb.com/Aql/ArrayFunctions.html">AQL array function</a>.</p>

<h2>Restrictions</h2>

<p>The <code>search-value</code> needs to be an object literal, with attribute names being inspectable
at query compile time. This means that neither variables nor bind parameters can be used
for <code>search-value</code>.</p>

<p>However, bind parameters and variables can be used <strong>inside</strong> <code>search-value</code>.
Dynamic attribute names cannot be used for specifying attribute names in search-value`.</p>

<p><code>UPSERT</code> does not require an index to be present on the attributes of <code>search-value</code>,
but in reality queries will benefit from indexes to find matching documents.</p>

<p>When more than one document in the collection matches <code>search-value</code>, one arbitrary match
will be used for executing the <code>UPDATE</code> clause. It is therefore recommended to use
<code>UPSERT</code> commands together with a unique index or to make sure from the client application
that at most one document will match the <code>search-value</code>. Ironically, one way to achieve this is
to use the <code>UPSERT</code> command for inserts&hellip;</p>

<h2>Availability</h2>

<p><code>UPSERT</code> is currently available in the <code>devel</code> branch of ArangoDB. This branch
will eventually become release 2.6. Until then, everyone is welcome to try it out and
provide feedback.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Analyzing Git Commits With ArangoDB]]></title>
    <link href="http://jsteemann.github.io/blog/2015/03/11/analyzing-git-commits-with-arangodb/"/>
    <updated>2015-03-11T12:37:58+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/03/11/analyzing-git-commits-with-arangodb</id>
    <content type="html"><![CDATA[<p>I often find myself searching for certain commits using <code>git log</code> and friends. While I really love
the power and flexibility that come with the git and other Unix command-line tools, sometimes it can be more
convenient to use a database to filter and aggregate commit data.</p>

<p>I gave it a quick try yesterday and imported the commit history of ArangoDB&rsquo;s Git repository into ArangoDB
and ran some queries on the data. While the query results for our repository may not be interesting for everyone,
I think it is still worth sharing what I did. Even though I didn&rsquo;t try it, I think the overall procedure is
applicable with any other Git repository.</p>

<!-- more -->


<h2>Converting the Git history to JSON</h2>

<p>The way to extract history and commit data from a local repository is to use <code>git log</code>. Though its output
is greatly customizable, it does not provide an out-of-the-box solution for producing JSON. So I wrote a simple
wrapper script (in PHP) around it. The script can be found <a href="https://gist.github.com/jsteemann/65ef221646449713b2c5">here</a>.</p>

<p>Here&rsquo;s how to run it:
<code>bash converting the git history to JSON
cd path/to/local/git-repository
wget https://gist.githubusercontent.com/jsteemann/65ef221646449713b2c5/raw/fef22c729e01dd0777b378ac1e17e951ea47c7dd/git-log-to-json.php
php git-log-to-json.php &gt; arango-commits-master-201503.json
</code></p>

<p>The script may run a few minutes on bigger repositories such as ours. In the end, it should produce a JSON
file named <code>arango-commits-master-201503.json</code>.</p>

<p>I have also uploaded the JSON file <a href="/downloads/code/arango-commits-master-201503.json">here</a>. Note that the
file only contains commits from the <code>master</code> branch and not all commits done in ArangoDB in total.</p>

<h2>Importing the commits into ArangoDB</h2>

<p>The simplest way to get the commits into ArangoDB is to use <code>arangoimp</code>:</p>

<p><code>bash importing the commits into ArangoDB
arangoimp                                   \
  --collection commits                      \
  --create-collection true                  \
  --file arango-commits-master-201503.json  \
  --overwrite true                          \
  --batch-size 32000000
</code></p>

<p>This should have imported all the commits into a collection <code>commits</code> in the default database.</p>

<h2>Querying the commit logs</h2>

<p>Following are a few example queries that I ran on the data from the ArangoShell.
As mentioned before, it should be possible to run the queries for other repositories' data.</p>

<p><code>js getting all contributors
query = 'FOR commit IN commits COLLECT author = commit.author.name RETURN author';
db._query(query).toArray();
</code></p>

<p><code>js retrieving the total number of commits
query = 'FOR commit IN commits COLLECT WITH COUNT INTO count RETURN count';
db._query(query).toArray();
</code></p>

<p><code>js retrieving the number of commits by contributor
query = 'FOR commit IN commits COLLECT author = commit.author.name WITH COUNT INTO count RETURN { author: author, count: count }';
db._query(query).toArray();
</code></p>

<p><code>js retrieving the tagged commits
query = 'FOR commit IN commits FILTER commit.tag != null SORT commit.date RETURN KEEP(commit, [ "date", "message", "tag" ])';
db._query(query).toArray();
</code></p>

<p><code>js retrieving number of commits per year
query = 'FOR commit IN commits COLLECT year = DATE_YEAR(commit.date) WITH COUNT INTO count RETURN { year: year, count: count }';
db._query(query).toArray();
</code></p>

<p><code>js retrieving number of commits per month / year
query = 'FOR commit IN commits COLLECT year = DATE_YEAR(commit.date), month = DATE_MONTH(commit.date)  WITH COUNT INTO count RETURN { month: CONCAT(year, "/", month), count: count }';
db._query(query).toArray();
</code></p>

<p><code>js retrieving number of commits per weekday
query = 'FOR commit IN commits COLLECT day = DATE_DAYOFWEEK(commit.date) WITH COUNT INTO count RETURN { day: TRANSLATE(day, { "0": "Sunday", "1": "Monday", "2": "Tuesday", "3": "Wednesday", "4": "Thursday", "5": "Friday", "6": "Saturday" }), count: count }';
db._query(query).toArray();
</code></p>

<p><code>js retrieving commits with string "issue #" in commit message
query = 'FOR commit IN commits FILTER LIKE(commit.message, "%issue #%") SORT commit.date DESC LIMIT 10 RETURN UNSET(commit, "files")';
db._query(query).toArray();
</code></p>

<p><code>js retrieving number of commits related to Foxx
query = 'FOR commit IN commits FILTER LIKE(LOWER(commit.message), "%foxx%") COLLECT year = DATE_YEAR(commit.date), month = DATE_MONTH(commit.date) WITH COUNT INTO count RETURN { month: CONCAT(year, "/", month), count: count }';
db._query(query).toArray();
</code></p>

<p><code>js retrieving commits that touched the most files
query = 'FOR commit IN commits LET count = LENGTH(commit.files || []) SORT count DESC LIMIT 10 RETURN MERGE(UNSET(commit, "files"), { files: count })';
db._query(query).toArray();
</code></p>

<p><code>js retrieving files modified most often
query = 'FOR commit IN commits FOR filename IN commit.files || [] COLLECT file = filename WITH COUNT INTO count SORT count DESC LIMIT 10 RETURN { file: file, count: count }';
db._query(query).toArray();
</code></p>

<p>Enjoy!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AQL Improvements in 2.5]]></title>
    <link href="http://jsteemann.github.io/blog/2015/02/26/aql-improvements-in-25/"/>
    <updated>2015-02-26T10:35:31+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/02/26/aql-improvements-in-25</id>
    <content type="html"><![CDATA[<p>Contained in 2.5 are some small but useful AQL language improvements plus several AQL optimizer improvements.</p>

<p>We are working on further AQL improvements for 2.5, but work is still ongoing.
This post summarizes the improvements that are already completed and will be shipped with the initial ArangoDB
2.5 release.</p>

<!-- more -->


<h1>Language improvements</h1>

<h2>Dynamic attribute names</h2>

<p>Often the need arises to dynamically name object attributes in return values.
In AQL this was not directly possible so far, though there were some workarounds available to achieve about
the same result. <a href="https://docs.arangodb.com/cookbook/UsingDynamicAttributeNames.html">This recipe</a> summarizes
the options that are available to pre-ArangoDB 2.5 users.</p>

<p>With ArangoDB 2.5, dynamic attribute names can be constructed much more easily and flexibly. Object
attribute names in ArangoDB 2.5 can be specified using static string literals, bind parameters,
and dynamic expressions.</p>

<p>Dynamic expressions are most interesting, and to disambiguate them from other regular string literal attribute
names, dynamic attribute names need to be enclosed in square brackets (<code>[</code> and <code>]</code>). I have written about
that before in <a href="http://jsteemann.github.io/blog/2015/02/03/using-dynamic-attribute-names-in-aql/">this blog</a>.</p>

<p>Here is an example query that uses the new syntax:</p>

<p><code>plain example query using dynamic attribute names
FOR i IN [ 17, 23, 42, 83 ]
  RETURN { [ CONCAT('value-of-', i, ' * ', i) ] : i * i }
</code></p>

<p>This will produce:</p>

<p>```json query result
[
  {</p>

<pre><code>"value-of-17 * 17" : 289 
</code></pre>

<p>  },
  {</p>

<pre><code>"value-of-23 * 23" : 529 
</code></pre>

<p>  },
  {</p>

<pre><code>"value-of-42 * 42" : 1764 
</code></pre>

<p>  },
  {</p>

<pre><code>"value-of-83 * 83" : 6889 
</code></pre>

<p>  }
]
```</p>

<h2>Functions added</h2>

<p>The following AQL functions have been added in 2.5:</p>

<ul>
<li><code>MD5(value)</code>: produces the MD5 hash of <code>value</code></li>
<li><code>SHA1(value)</code>: produces the SHA1 hash of <code>value</code></li>
<li><code>RANDOM_TOKEN(length)</code>: produces a pseudo-random string of the specified length.
 Such strings can be used for id or token generation. Tokens consist only of letters
 (lower and upper case) plus digits, so they are also URL-safe</li>
</ul>


<h1>Optimizer improvements</h1>

<h2>Optimizer rules</h2>

<p>The following AQL optimizer rules have been added in ArangoDB 2.5:</p>

<ul>
<li><p><code>propagate-constant-attributes</code></p>

<p>This rule will look inside <code>FILTER</code> conditions for constant value equality comparisons,
and insert the constant values in other places in <code>FILTER</code>s. For example, the rule will
insert <code>42</code> instead of <code>i.value</code> in the second <code>FILTER</code> of the following query:</p>

<pre><code>FOR i IN c1 
  FOR j IN c2 
    FILTER i.value == 42 
    FILTER j.value == i.value 
    RETURN 1
</code></pre></li>
<li><p><code>move-calculations-down</code></p>

<p>This rule moves calculations down in the execution plan as far as possible. The intention
is to move calculations beyond filters, in order to avoid calculations and computations
for documents that will be filtered away anyway.</p>

<p>If a query contains a lot of computations and a lot of documents will be skipped because
of filters, this rule might provide a big benefit.</p>

<p>A more detailed example is provided in
<a href="http://jsteemann.github.io/blog/2015/01/31/yaor-yet-another-optimizer-rule/">this post</a>.</p></li>
</ul>


<p>The already existing optimizer rule <code>use-index-for-sort</code> was also improved in the following way:</p>

<ul>
<li><p>the rule can now remove <code>SORT</code>s also in case a non-sorted index (i.e. a hash index) is used
for an equality lookup and all sort attributes are covered by the index.</p></li>
<li><p>the rule can also remove <code>SORT</code>s in case the sort critieria excludes the left-most index attributes,
but the left-most index attributes are used in a <code>FILTER</code> for equality-only lookups.</p>

<p>Here is an example that will use an existing skiplist index on [ <code>value1</code>, <code>value2</code> ] for sorting,
removing the extra <code>SORT</code>:</p>

<pre><code>FOR doc IN collection 
  FILTER doc.value1 == 1 
  SORT doc.value2 
  RETURN doc
</code></pre></li>
</ul>


<h2>Index usage</h2>

<p>The AQL optimizer now supports <a href="https://www.arangodb.com/2015/02/24/sparse-indexes-in-arangodb">sparse indexes</a>,
a feature added in 2.5.</p>

<p>It will use them automatically in queries when appropriate and when safe. Sparse indexes do exclude certain
documents purposely, so the optimizer always has to figure out whether it can use a sparse index to satisfy
a given <code>FILTER</code> condition.</p>

<p>The optimizer will also take into account index selectivity estimates when there are multiple index candidates.</p>

<h2>Estimates</h2>

<p>The optimizer estimates for the number of documents to be returned by a query or a subquery are more accurate
now for several types of queries. For example, if the optimizer can use a primary key, an edge index, or a hash
index in a given query part, it will use the index selectivity estimates for calculating the number of return
documents.</p>

<p>These estimates will be a lot more accurate than the previoulsy hard-coded filtering factors, and can lead to
better optimizer decisions and reporting (because estimates are returned in <code>explain</code> results, too).</p>

<h2>Memory savings</h2>

<p>Finally, the optimizer will now detect if the data-modification part in a data-modification query
can be executed in lockstep with the data-retrieval part of the same query. Previously, a data-modification
query always executed its data-retrieval part first, and then executed its data-modification part.
This could have resulted in big intermediate result sets which to retrieval part constructed in order
to pass them to the modification part of the query.</p>

<p>Here&rsquo;s an example query:</p>

<p><code>plain data-modification query
FOR doc IN test
  INSERT doc INTO backup
</code></p>

<p>In the above query, the <code>FOR</code> loop is the retrieval part, and the <code>INSERT</code> is the modification part.
The optimizer in 2.5 will check if the two parts of the query are independent, and if it turns out they are,
will execute them in lockstep instead of sequentially.</p>

<p>The execution in lockstep is not necessarily faster than sequential execution, but it can save lots of
memory if the data-retrieval part constructed big intermediate result sets.</p>

<h1>Miscellaneous changes</h1>

<p>The AQL query execution statistics now also provide an attribute <code>filtered</code>. Its value indicates how many
documents were filtered by <code>FilterNode</code>s in the AQL query. This can be used as an indicator for whether
indexes should be added, and for how effective indexes are used for filtering.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Dynamic Attribute Names in AQL]]></title>
    <link href="http://jsteemann.github.io/blog/2015/02/03/using-dynamic-attribute-names-in-aql/"/>
    <updated>2015-02-03T00:12:39+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/02/03/using-dynamic-attribute-names-in-aql</id>
    <content type="html"><![CDATA[<p>On our mailing list, there is quite often the question whether attribute names in objects
returned from AQL queries can be made dynamic.</p>

<p>Here&rsquo;s a (non-working) example query for this:</p>

<p><code>plain example query that does not work
FOR doc IN collection
  RETURN { doc.type : doc.value }
</code></p>

<p>The intention in the above query obviously is to use the dynamic value from <code>doc.type</code> as
an attribute name in the result object and not to have an attribute named <code>"doc.type"</code>. This
feature is probably in the top 20 of the most-often wished features.</p>

<!-- more -->


<p>However, the above query won&rsquo;t even parse. The AQL grammar only allows string values
left of the colon in an object definition. Non-quoted strings are allowed there too, and are
implicitly turned into quoted strings. It works similar to how object literals are defined
in JavaScript:</p>

<p><code>plain using unquoted and quoted string attribute names
RETURN {
  foo : "bar",
  "baz" : "qux"
}
</code></p>

<p>Why not allow arbitrary expression left of the colon? The reason is simple: this would cause
ambiguity and probably have side-effects. For an example, have a look at the following query:</p>

<p><code>plain which attribute name to use here?
FOR doc IN collection
  LET type = doc.type;
  RETURN { type : doc.value }
</code></p>

<p>If the <code>type</code> attribute name inside the object definition is interpreted as a string literal
as it currently is an AQL (and always was), then the resulting attribute name is just <code>"type"</code>.</p>

<p>If the <code>type</code> attribute name would now be intepreted as an expression, it would get the value
that was assigned to the variable <code>type</code> by the <code>LET</code> statement. Removing the <code>LET</code> from the
query would change the attribute name in the result back to the string literal <code>"type"</code>.</p>

<p>The ambiguity could be solved by telling the parser what to do in such cases. While technically
this could be working, I think it may have too many unintended side-effects. I already mentioned
that introducing a <code>LET</code> statement into the query would change the attribute name in the result.
The same could also happen if a collection named <code>type</code> was added to the query. And it would
break compatibility with existing queries.</p>

<p>JavaScript has the same problem, and it wasn&rsquo;t solved portably yet. However, there is a proposal
for ES6 that suggests enclosing attribute name expressions in <code>[</code> and <code>]</code>.</p>

<p>To me, this looks like a good solution for the problem. It&rsquo;s two bytes more when keying in
queries, but the syntax is easy and explicit. There are no ambiguities.</p>

<p>I prototyped this solution for AQL, so I could write:</p>

<p>```plain query using dynamic attribute names
FOR i IN 1..5
  RETURN {</p>

<pre><code>[ CONCAT('test', i) ] : i, 
[ SUBSTITUTE(CONCAT('i is ', (i &lt;= 3 ? 'small' : 'not small')), { ' ' :  '_' } ) ] : i 
</code></pre>

<p>  }</p>

<p>[
  {</p>

<pre><code>"test1" : 1, 
"i_is_small" : 1 
</code></pre>

<p>  },
  {</p>

<pre><code>"test2" : 2, 
"i_is_small" : 2 
</code></pre>

<p>  },
  {</p>

<pre><code>"test3" : 3, 
"i_is_small" : 3 
</code></pre>

<p>  },
  {</p>

<pre><code>"test4" : 4, 
"i_is_not_small" : 4 
</code></pre>

<p>  },
  {</p>

<pre><code>"test5" : 5, 
"i_is_not_small" : 5 
</code></pre>

<p>  }
]
```</p>

<p>I ran a few queries with this, and they seemed to work. <del>However, I haven&rsquo;t
committed the feature yet. There might still be cases in which it doesn&rsquo;t work. Tests
for the feature are also still missing. I hope I can finalize the implementation soon
so it becomes available in some release.</del></p>

<p><strong>UPDATE</strong>: tests have been added, and the feature has been committed in devel. It is
included in ArangoDB since version 2.5.</p>

<p>Everyone is welcome to try it out already!</p>
]]></content>
  </entry>
  
</feed>
