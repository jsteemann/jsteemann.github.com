<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: AQL | J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/blog/categories/aql/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2016-01-26T23:49:30+01:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Killing a Long-running Query]]></title>
    <link href="http://jsteemann.github.io/blog/2016/01/26/killing-a-long-running-query/"/>
    <updated>2016-01-26T23:13:33+01:00</updated>
    <id>http://jsteemann.github.io/blog/2016/01/26/killing-a-long-running-query</id>
    <content type="html"><![CDATA[<p>Suppose there is an AQL query that&rsquo;s executing in the server
for a long time already and you want to get rid of it. What can
be done to abort that query?</p>

<p>If a connection to the server can still be established, the easiest
is to use the ArangoShell to fetch the list of currently executing
AQL queries and send a <em>kill</em> command to the server for the correct query.</p>

<!-- more -->


<p>To start, we can fetch the list of all running queries and print
their ids, query strings and runtimes. This is only inspection and does
not abort any query:</p>

<p><code>js printing all currently running queries
var queries = require("org/arangodb/aql/queries");
queries.current();
</code></p>

<p>Here&rsquo;s an example result for the list of running queries:</p>

<p>```json example list of currently running queries
[
  {</p>

<pre><code>"id" : "190", 
"query" : "RETURN SLEEP(1000)", 
"started" : "2016-01-26T22:41:24Z", 
"runTime" : 218.49146389961243 
</code></pre>

<p>  }
]
```</p>

<p>To now kill a query from the list, we can pass the query&rsquo;s id to <em>kill</em>:</p>

<p><code>js killing a specific query
var queries = require("org/arangodb/aql/queries");
queries.kill("190");  /* insert actual query id here */
</code></p>

<p>If a query was actually killed on the server, that call should return without
an error, and the server should have logged a warning in addition.</p>

<p>If we wanted to abort one or many queries from the list solely by
looking at query string patterns or query runtime, we could iterate
over the list of current queries and kill each one that matches
a predicate.</p>

<p>For example, the following snippet will abort all currently running
queries that contain the string <code>SLEEP</code> anywhere inside their query string:</p>

<p>```js aborting all queries containing the word SLEEP inside the query string
var queries = require(&ldquo;org/arangodb/aql/queries&rdquo;);</p>

<p>queries.current().filter(function(query) {
  return query.query.match(/SLEEP/);  /<em> predicate based on query string </em>/
}).forEach(function(query) {
  print(&ldquo;killing query: &rdquo;, query);    /<em> print what we&rsquo;re killing </em>/
  queries.kill(query.id);             /<em> actually kill query </em>/
});
```</p>

<p>Filtering based on current query runtime is also simple, by adjusting the
predicate. To abort all queries that ran longer than 30 seconds use:</p>

<p>```js aborting all queries running at least 30 seconds
var queries = require(&ldquo;org/arangodb/aql/queries&rdquo;);</p>

<p>queries.current().filter(function(query) {
  return query.runTime > 30;          /<em> predicate based on query runtime </em>/
}).forEach(function(query) {
  print(&ldquo;killing query: &rdquo;, query);    /<em> print what we&rsquo;re killing </em>/
  queries.kill(query.id);             /<em> actually kill query </em>/
});
```</p>

<p>Please make sure the predicates are correct so only the actually intended
queries get aborted!</p>

<p>To test a predicate without killing a query, use the above code without the
<code>forEach</code> part that did the killing.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Small Things in 2.8: Explain Improvements]]></title>
    <link href="http://jsteemann.github.io/blog/2016/01/26/small-things-in-28-explain-improvements/"/>
    <updated>2016-01-26T22:08:11+01:00</updated>
    <id>http://jsteemann.github.io/blog/2016/01/26/small-things-in-28-explain-improvements</id>
    <content type="html"><![CDATA[<p>Explaining AQL queries becomes even easier in ArangoDB 2.8.</p>

<p>While previous versions required writing a hard-to-memoize command like</p>

<p><code>js explaining a query in 2.7
require("org/arangodb/aql/explainer").explain(query);
</code></p>

<p>to explain an AQL query from the ArangoShell, 2.8 reduces this task to
a mere</p>

<p><code>js explaining a query in 2.8
db._explain(query);
</code></p>

<p>Apart from that, explain in 2.8 is smarter when confronted with very lengthy
query strings, and with queries that contain huge hard-coded string, array,
or object values.</p>

<!-- more -->


<p>For example, when creating an array bind variable with 1,000 values and
using them in an explained query, 2.7 would print the entire 1,000 array values
in the explain output:</p>

<p>```js explaining a query with 1000 array values
var keys = [];
for (var i = 0; i &lt; 1000; ++i) {
  keys.push(&ldquo;test&rdquo; + i);
}</p>

<p>var query = &ldquo;FOR i IN @keys RETURN i&rdquo;;
require(&ldquo;org/arangodb/aql/explainer&rdquo;).explain({
  query: query,
  bindVars: {</p>

<pre><code>keys: keys 
</code></pre>

<p>  }
});
```</p>

<p><img src="/downloads/screenshots/explain-27.png"></p>

<p>2.8 will instead truncate longer arrays and objects in the explain output for
much improved readability:</p>

<p><img src="/downloads/screenshots/explain-28.png"></p>

<p>Automatic value truncation will occur for array and object values with
more than 20 elements or for string values longer than 1,024 characters. The
truncation for explain will occur if these values are hard-coded into the
query or are passed via bind parameters.</p>

<p>Truncation only happens inside the explain results processing and thus
cannot affect the actual query results.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Small Things in 2.8: POW]]></title>
    <link href="http://jsteemann.github.io/blog/2016/01/26/small-things-in-28-pow/"/>
    <updated>2016-01-26T21:59:17+01:00</updated>
    <id>http://jsteemann.github.io/blog/2016/01/26/small-things-in-28-pow</id>
    <content type="html"><![CDATA[<p>ArangoDB 2.8 now provides a dedicated AQL function for exponentiation.
This will save users a lot of trouble in case exponentiation is needed
inside an AQL query, which up to 2.7 required writing and registering an
AQL user-defined function.</p>

<p>With 2.8 it becomes as simple as <code>RETURN POW(2, 16)</code> to raise <em>2</em>
to the power of <em>16</em> from inside AQL.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AQL Optimizer Improvements for 2.8]]></title>
    <link href="http://jsteemann.github.io/blog/2015/12/22/aql-optimizer-improvements-for-28/"/>
    <updated>2015-12-22T22:39:30+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/12/22/aql-optimizer-improvements-for-28</id>
    <content type="html"><![CDATA[<p>With the 2.8 beta phase coming to an end it&rsquo;s time to shed some light
on the improvements in the 2.8 AQL optimizer. This blog post summarizes
a few of them, focusing on the query optimizer. There&rsquo;ll be a follow-up
post that will explain dedicated new AQL features soon.</p>

<!-- more -->


<h2>Array indexes</h2>

<p>2.8 allows creating hash and skiplist indexes on attributes which are arrays.
Creating such index works similar to creating a non-array index, with the
exception that the name of the array attribute needs to be followed by a <code>[*]</code>
in the index fields definition:</p>

<p><code>js creating an array index
db._create("posts");
db.posts.ensureIndex({ type: "hash", fields: [ "tags[*]" ] });
</code></p>

<p>Now if the <code>tags</code> attribute of a document in the <code>posts</code> collection is an array,
each array member will be inserted into the index:</p>

<p><code>js storing an array value
db.posts.insert({ tags: [ "arangodb", "database", "aql" ] });
db.posts.insert({ tags: [ "arangodb", "v8", "javascript" ] });
db.posts.insert({ tags: [ "javascript", "v8", "nodejs" ] });
</code></p>

<p>The index on <code>tags[*]</code> will now contain the values <code>arangodb</code>, <code>database</code>, <code>aql</code> and
<code>nosql</code> for the first document, <code>arangodb</code>, <code>v8</code> and <code>javascript</code> for the second, and
<code>javascript</code>, <code>v8</code> and <code>nodejs</code> for the third.</p>

<p>The following AQL will find any documents that have a value of <code>javascript</code> contained
in their <code>tags</code> value:</p>

<p><code>plain array index query
FOR doc IN posts
  FILTER 'javascript' IN doc.tags[*]
  RETURN doc
</code></p>

<p>This will use the array index on <code>tags[*]</code>.</p>

<p>The array index works by inserting all members from an array into the index
separately. Duplicates are removed automatically when populating the index.</p>

<p>An array index can also be created on a sub-attribute of array members. For
example, the following definition will make sure the <code>name</code> sub-attributes of
the <code>tags</code> array values will make it into the index:</p>

<p><code>js creating an array index on a sub-attribute
db.posts.ensureIndex({ type: "hash", fields: [ "tags[*].name" ] });
</code></p>

<p>That will allow storing data as follows:</p>

<p><code>js storing an array value
db.posts.insert({ tags: [ { name: "arangodb" }, { name: "database" }, { name: "aql" } ] });
db.posts.insert({ tags: [ { name: "arangodb" }, { name: "v8" }, { name: "javascript" } ] });
db.posts.insert({ tags: [ { name: "javascript" }, { name: "v8" }, { name: "nodejs" } ] });
</code></p>

<p>The (index-based) selection query for this data structure then becomes</p>

<p><code>plain array index query using sub-attributes
FOR doc IN posts
  FILTER 'javascript' IN doc.tags[*].name
  RETURN doc
</code></p>

<p>Contrary to MongoDB, there is no automatic conversion to array values when
inserting non-array values in ArangoDB. For example, the following plain strings
will not be inserted into an array index, simply because the value of the index
attribute is not an array:</p>

<p><code>js storing non array values without indexing
db.posts.insert({ tags: "arangodb" });
db.posts.insert({ tags: "javascript" });
db.posts.insert({ tags: "nodejs" });
</code></p>

<p>Note that in this case a non-array index can still be used.</p>

<h2>Use of multiple indexes per collection</h2>

<p>The query optimizer can now make use of multiple indexes if multiple filter
conditions are combined with logical ORs, and all of them are covered by
indexes of the same collection.</p>

<p>Provided there are separate indexes present on <code>name</code> and <code>status</code>, the
following query can make use of index scans in 2.8, as opposed to full
collection scans in 2.7:</p>

<p><code>plain using multiple indexes
FOR doc IN users
  FILTER doc.name == 'root' || doc.status == 'active'
  RETURN doc
</code></p>

<p><img src="/downloads/screenshots/multiple-indexes.png"></p>

<p>If multiple filter conditions match for the same document, the result will
automatically be deduplicated, so each document is still returned at most once.</p>

<h2>Sorted IN comparison</h2>

<p>Another improvement for the optimizer is to pre-sort comparison values for <code>IN</code> and
<code>NOT IN</code> so these operators can use a (much faster) binary search instead of a linear search.</p>

<p>The optimization will be applied automatically for <code>IN</code> / <code>NOT IN</code> comparison values used
in filters, which are used inside of a <code>FOR</code> loop, and depend on runtime values. For example,
the optimization will be applied for the following query:</p>

<p><code>
LET values = /* some runtime expression here */
FOR doc IN collection
  FILTER doc.value IN values
  RETURN doc
</code></p>

<p>The optimization will not be applied for <code>IN</code> comparison values that are value
literals and those that are used in index lookups. For these cases the comparison values
were already deduplicated and sorted.</p>

<p>&ldquo;sort-in-values&rdquo; will appear in the list of applied optimizer rules if the optimizer
could apply the optimization:</p>

<p><img src="/downloads/screenshots/sorted-in.png"></p>

<h2>Optimization for LENGTH(collection)</h2>

<p>There are multiple ways for counting the total number of documents in a collection from
inside an AQL query. One obvious way is to use <code>RETURN LENGTH(collection)</code>.</p>

<p>That variant however was inefficient as it fully materialized the documents before
counting them. In 2.8 calling <code>LENGTH()</code> for a collection will get automatically replaced
by a call to a special function that can efficiently determine the number of documents.
For larger collections, this can be several thousand times faster than the naive 2.7
solution.</p>

<h2>C++ implementation for many AQL functions</h2>

<p>Many existing AQL functions have been backed with a C++ implementation that removes
the need for some data conversion that would otherwise happen if the function were
implemented in V8/JavaScript only. More than 30+ functions have been changed, including
several that may produce bigger result sets (such as <code>EDGES()</code>, <code>FULLTEXT()</code>, <code>WITHIN()</code>,
<code>NEAR()</code>) and that will hugely benefit from this.</p>

<h2>Improved skip performance</h2>

<p>2.8 improves the performance of skipping over many documents in case no indexes and no
filters are used. This might sound like an edge case, but it is quite common when the
task is to fetch documents from a big collection in chunks and there is certainty that
there will be no parallel modifications.</p>

<p>For example, the following query runs about 3 to 5 times faster in 2.8, and this
improvements can easily sum up to notable speedups if the query is called repeatedly
with increasing offset values for <code>LIMIT</code>:</p>

<p><code>plain query with huge skip
FOR doc IN collection
  LIMIT 1000000, 10
  RETURN doc
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AQL Function Speedups]]></title>
    <link href="http://jsteemann.github.io/blog/2015/11/20/aql-function-speedups/"/>
    <updated>2015-11-20T16:55:34+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/11/20/aql-function-speedups</id>
    <content type="html"><![CDATA[<p>While working on the upcoming ArangoDB 2.8, we have reimplemented some AQL
functions in C++ for improved performance. AQL queries using these functions
may benefit from using the new implementation of the function.</p>

<p>The following list shows the AQL functions for which a C++ implementation has
been added in 2.8. The other C++-based AQL function implementations added since
ArangoDB 2.5 are also still available. Here&rsquo;s the list of functions added in 2.8:</p>

<!-- more -->


<ul>
<li>document-related functions: DOCUMENT, EDGES, PARSE_IDENTIFIER</li>
<li>numerical functions: ABS, FLOOR, RAND, ROUND, SQRT</li>
<li>statistical functions: MEDIAN, PERCENTILE, STDDEV_POPULATION, STDDEV_SAMPLE, VARIANCE_POPULATION, VARIANCE_SAMPLE</li>
<li>geo functions: NEAR, WITHIN</li>
<li>array functions: APPEND, FIRST, FLATTEN, LAST, MINUS, NTH, POP, POSITION, PUSH, REMOVE_NTH, REMOVE_VALUE, REMOVE_VALUES, SHIFT, UNSHIFT</li>
<li>informational functions: COLLECTIONS, CURRENT_DATABASE, FIRST_DOCUMENT, FIRST_LIST, NOT_NULL</li>
<li>object-related functions: MERGE_RECURSIVE, ZIP</li>
</ul>


<p>Following are a few example queries that benefit from using the C++ variants of some
of the above functions:</p>

<h3>Fetching documents programmatically using the <code>DOCUMENT</code> function:</h3>

<ul>
<li>query: <code>FOR i IN 1..10000 RETURN DOCUMENT(test, CONCAT('test', i))</code></li>
<li>2.7: 0.3005 s</li>
<li>2.8: 0.1050 s</li>
</ul>


<h3>Fetching edges programmatically using the <code>EDGES</code> function:</h3>

<ul>
<li>query: <code>FOR i IN 1..100000 RETURN EDGES(edges, CONCAT('test/test', i), 'outbound')</code>:</li>
<li>2.7: 4.3590 s</li>
<li>2.8: 1.4469 s</li>
</ul>


<h3>Fetching many documents from a geo index, post-filtering most of them:</h3>

<ul>
<li>query: <code>FOR doc IN WITHIN(locations, 0, 0, 100000) FILTER doc.value2 == 'test1001' LIMIT 1 RETURN doc</code></li>
<li>2.7: 2.9876 s</li>
<li>2.8: 0.4087 s</li>
</ul>


<h3>Generating random numbers:</h3>

<ul>
<li>query: <code>FOR value IN 1..100000 RETURN RAND() * 50</code></li>
<li>2.7: 0.1743 s</li>
<li>2.8: 0.1364 s</li>
</ul>


<p>Please note that not in every case there will be a tremendous speedup. As usual,
it depends on how often a function is called inside a query and what other constructs
are used. Your mileage may vary.</p>
]]></content>
  </entry>
  
</feed>
