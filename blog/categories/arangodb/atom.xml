<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ArangoDB | J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/blog/categories/arangodb/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2015-04-01T19:32:51+02:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Improvements for the Cursor API]]></title>
    <link href="http://jsteemann.github.io/blog/2015/04/01/improvements-for-the-cursor-api/"/>
    <updated>2015-04-01T13:59:22+02:00</updated>
    <id>http://jsteemann.github.io/blog/2015/04/01/improvements-for-the-cursor-api</id>
    <content type="html"><![CDATA[<p>This week we pushed some modifications for ArangoDB&rsquo;s cursor API into the <code>devel</code> branch.
The change will result in less copying of AQL query results between the AQL and the HTTP layers.
As a positive side effect, this will reduce the amount of garbage collection the built-in V8
has to do.</p>

<p>These modifications should improve the cursor API performance significantly for many cases,
while at the same time keeping its REST API stable.</p>

<p>This blog post shows some first unscientific performance tests comparing the old cursor API with
its new, improved implementation.</p>

<!-- more -->


<p>A good way to test the cursor API performance is to issue lots of queries from the
ArangoShell. The ArangoShell will send the query to the server for execution. The server
will respond with the first 1,000 results for the query.</p>

<p>Additionally the server will create a server-side cursor if the result set is bigger than
1,000 documents. In this case, the ArangoShell will issue subsequent HTTP requests that fetch
the outstanding documents from the server.</p>

<p>The above behavior is triggered automatically when <code>db._query(query).toArray()</code> is run in
the ArangoShell.</p>

<p>Here is a test function that executes a query <em>n</em> times and measures the total execution time.
It will issue <em>n</em> HTTP requests to the server&rsquo;s cursor API for executing the query. It will
also issue further HTTP requests if the total result set size is bigger than 1,000 documents.
What is getting measured is thus the total execution time from the ArangoShell&rsquo;s point of view,
including time spent in the server-side cursor functions as well as in HTTP traffic.</p>

<p>```js function for testing the cursor API
var test = function(query, n) {
  var time = require(&ldquo;internal&rdquo;).time;
  var s = time();
  for (var i = 0; i &lt; n; ++i) {</p>

<pre><code>db._query(query).toArray(); 
</code></pre>

<p>  }
  return time() &ndash; s;
};
```</p>

<p>The test function was run with different queries to check which types of queries will benefit
from the cursor API change.</p>

<p>Note that the ArangoShell will issue all its requests to the cursor API sequentially. This is
ok for the purpose of this test, as the purpose was to measure the relative performance change
between the old and the new API implementation.</p>

<p>The ArangoShell and ArangoDB server were running on the same physical machine during the tests,
so this is a <strong>localhost</strong> benchmark.</p>

<h2>Detailed test results</h2>

<p>Here are the results from my local machine.</p>

<p>The first query was about the simplest one I could come up with. The query was sent to the
server 10,000 times. The result set size per query ws 1, resulting in 10,000 calls to the cursor
API with not much data to be transferred per call:</p>

<p><code>js test query
test("RETURN 1", 10000);
</code></p>

<p>Execution took 7.225 s with the old API, and 5.195 s with the new API (<strong>28 % improvement</strong>).</p>

<p>A query returning a slightly more complex result value:</p>

<p><code>js test query
test("RETURN { one: 'test', two: 'another-value', three: [ 1, 2, 3 ] }", 10000);
</code></p>

<p>This took 8.046 s with the old API, and 5.829 s with the new one (<strong>27 % improvement</strong>).</p>

<p>Another simple query, again executed 10,000 times, but now returning 10 values per query:</p>

<p><code>js test query
test("FOR i IN 1..10 RETURN i", 10000);
</code></p>

<p>Execution of this query took 7.951 s with the old, and 5.779 s with the new API (<strong>27 % improvement</strong>).</p>

<p>Now raising the number of return values per query from 10 to 1,000:</p>

<p><code>js test query
test("FOR i IN 1..1000 RETURN i", 10000);
</code></p>

<p>This took 31.650 s with the old, and 28.504 s with the new API (<strong>10 % improvement</strong>).</p>

<p>So far all query results contained 1,000 or less values. In this case the server is able to
send the whole query result in response in one go, so there were only as many calls to the
cursor API as there were queries. Even though the ArangoShell called the cursor API, the
cursor only existed temporarily on the server but directly vanished when the server sent its
response.</p>

<p>Now let&rsquo;s run a query that returns more than 1,000 values each. The first call to the
cursor API will then only return the first 1,000 results and additionally establish a
server-side cursor so the client can fetch more results. This will mean that for each client
query, there will be multiple HTTP requests.</p>

<p>The following run issues 100,000 calls to the cursor API (10,000 queries times 10 batches per
query):</p>

<p><code>js test query
test("FOR i IN 1..10000 RETURN i", 10000);
</code></p>

<p>This took 307.108 s with the old API, in contrast to 232.322 s with the new API (<strong>24 % improvement</strong>).</p>

<p>The next queries I tested were collection-based. They returned data from a collection named
<code>docs</code>. The collection contained 10,000 documents, and each document in the collection had
5 attributes.</p>

<p>The first query returned only a single one (random) document from the collection per query.</p>

<p><code>js test query
test("FOR i IN docs LIMIT 1 RETURN i", 10000);
</code></p>

<p>This took 8.689 s with the old API and 6.245 s with the new API (<strong>28 % improvement</strong>).</p>

<p>The next query returned all the documents from the collection. The query was executed
only 1,000 times because the result sets already got quite big. The combined size of all
result sets was 1,000,000 documents (10,000 documents, 1,000 queries).</p>

<p><code>js test query
test("FOR i IN docs RETURN i", 1000);
</code></p>

<p>This took 453.736 s with the old, and 197.543 s with the new API (<strong>56 % improvement</strong>).</p>

<p>The final query returned all document keys from the collection. The combined size of all result
sets was 10,000,000 values (10,000 documents, 10,000 queries):</p>

<p><code>js test query
test("FOR i IN docs RETURN i._key", 10000);
</code></p>

<p>With the old API, this took 529.765 s, and with the new API it took 348.243 s (<strong>34 % improvement</strong>).</p>

<h2>Summary</h2>

<p>The new cursor API was faster than its old counterpart for all queries tested here. Total execution
time as measured by the ArangoShell (representative for any other client program sending queries to
ArangoDB) was consistenly lower than it was with the old API implementation.</p>

<p>The improvements measured were varying. For the queries tested, the improvements fell into a range
of 10 % to even more than 50 % improvement.</p>

<p>How much gain can be achieved in reality obviously depends on the type of query executed. There will
also be queries that do not benefit from the new API implementation. For example, queries that do not
return any results will not benefit much. This is because most of the optimizations done affect
the buffering and the data transport internals of the cursor API. Furthermore, queries that run for
a very long time but return only small amounts of data may not benefit considerably for the same reason.
However, there should not be any queries which are negatively affected by the change.</p>

<p>All in all, this looks quite promising, especially as the change will come <strong>for free</strong> for client
applications. Client programs do not need to be adjusted to reap the benefits. This is because all
that has changed were the <em>internals</em> of the cursor API. Its public REST interface remains unchanged.</p>

<p>The changes are included in the <code>devel</code> branch and can be tested there.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improvements for Data-modification Queries]]></title>
    <link href="http://jsteemann.github.io/blog/2015/03/27/improvements-for-data-modification-queries/"/>
    <updated>2015-03-27T23:29:19+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/03/27/improvements-for-data-modification-queries</id>
    <content type="html"><![CDATA[<p>Data-modification queries were enhanced in ArangoDB 2.4 to be able to also return
the inserted, update or removed documents.</p>

<p>For example, the following statement inserted a few documents and also returned
them with all their attributes:</p>

<p><code>plain AQL insert query returning documents
FOR i IN 1..10
  INSERT { value: i } IN test
  LET inserted = NEW
  RETURN inserted
</code></p>

<p>The syntax for returning documents from data-modification queries only supported
the exact above format. Using a <code>LET</code> clause was required, and the <code>RETURN</code> clause
was limited to returning the variable introduced by the <code>LET</code>.</p>

<p>These syntax restrictions have been lifted in the <code>devel</code> branch, which will become
release 2.6 eventually. The changes make returning values from data-modification
statements easier and also more flexible.</p>

<!-- more -->


<h2>Simpler syntax</h2>

<p>For example, specifying a <code>LET</code> clause is not required anymore (though still fully
supported). Instead, the <code>RETURN</code> clause can directly refer to the <code>NEW</code> pseudo-value,
making the query shorter and easier to write:</p>

<p><code>plain AQL insert query returning documents
FOR i IN 1..10
  INSERT { value: i } IN test
  RETURN NEW
</code></p>

<h2>Projections</h2>

<p>It is now also possible to return a projection instead of returning the entire documents.
This can be used to reduce the amount of data returned by queries.</p>

<p>For example, the following query will return just the keys of the inserted documents:</p>

<p><code>plain AQL insert query returning a projection
FOR i IN 1..10
  INSERT { value: i } IN test
  RETURN NEW._key
</code></p>

<h2>Using OLD and NEW in the same query</h2>

<p>In previous versions, <code>UPDATE</code> and <code>REPLACE</code> statements could refer to <strong>either</strong>
the <code>OLD</code> or the <code>NEW</code> pseudo-value, but not to both. 2.6 lifts that restriction, so
now these queries can refer to both. One can utilize that to return both the previous
and the updated revision:</p>

<p><code>plain AQL update query returning old and new revisions
FOR doc IN test
  UPDATE doc WITH { value: 42 } IN test
  RETURN { old: OLD, new: NEW }
</code></p>

<h2>Calculations with OLD or NEW</h2>

<p>It is now also possible to run additional calculations with <code>LET</code> statements between
the data-modification part and the final <code>RETURN</code>:</p>

<p><code>plain AQL upsert query with some extra calculations
UPSERT { name: 'test' } INSERT { name: 'test' } UPDATE { } IN test
LET previousRevisionExisted = ! IS_NULL(OLD)
LET type = previousRevisionExisted ? 'update' : 'insert'
RETURN { _key: NEW._key, type: type }
</code></p>

<h2>Restrictions</h2>

<p>Still the following restrictions remain:</p>

<ul>
<li><p>a data-modification operation can optionally be followed by any number of <code>LET</code> clauses,
and a final <code>RETURN</code> clause. No other operations (e.g. <code>FOR</code>, <code>SORT</code>, <code>COLLECT</code>) can be
used after a data-modification operation</p></li>
<li><p>calculations following a data-modification operation must not access data in collections,
so using functions such as <code>GRAPH_TRAVERSAL</code> etc. is disallowed.</p></li>
</ul>


<p>The improvements are present in the <code>devel</code> branch and can be tested in there from now on.
As usual, feedback is welcome!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Preview of the UPSERT Command]]></title>
    <link href="http://jsteemann.github.io/blog/2015/03/27/preview-of-the-upsert-command/"/>
    <updated>2015-03-27T21:37:09+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/03/27/preview-of-the-upsert-command</id>
    <content type="html"><![CDATA[<p>This week saw the completion of the AQL <code>UPSERT</code> command.</p>

<p>This command will be very helpful in a lot of use cases, including the following:</p>

<ul>
<li>ensure that a document exists</li>
<li>update a document if it exists, otherwise create it</li>
<li>replace a document if it exists, otherwise create it</li>
</ul>


<p>The <code>UPSERT</code> command is executed on the server side and so delivers client
applications from issuing a fetch command followed by a separate, conditional <code>UPDATE</code>
or <code>INSERT</code> command.</p>

<!-- more -->


<p>The general format of an <code>UPSERT</code> statement is:</p>

<p><code>plain UPSERT format
UPSERT search-document
INSERT insert-expression
UPDATE update-expression
IN collection-name
</code></p>

<p>Following are a few example invocations of <code>UPSERT</code>.</p>

<h2>Ensure a document exists</h2>

<p>A simple use case of <code>UPSERT</code> is to ensure that a specific document exists.
For example, the following query will ensure that that there will be a document
with attribute <code>ip</code> equal to <code>192.168.173.13</code> in collection <code>hosts</code>:</p>

<p><code>plain ensuring a document exists
UPSERT { ip: '192.168.173.13' }
INSERT { ip: '192.168.173.13', name: 'flittard' }
UPDATE { }
IN hosts
</code></p>

<p>If the document does not yet exist, the <code>INSERT</code> part will be carried out. If the
document is already there, the empty <code>UPDATE</code> part will be run, which will not
modify the document.</p>

<p>After the query has finished, there will be a document with the specified <code>ip</code> value.</p>

<p>There is no need for client applications to check for document existence first,
and then to conditionally insert or update, or to try insert first and catch errors.</p>

<p>Note: this is the same as ActiveRecord&rsquo;s <code>find_or_create</code>.</p>

<h2>Update a document if it exists, otherwise create it</h2>

<p>Another common use case is to check whether a specific document exists, and then update it.
If it does not yet exist, the document shall be created.</p>

<p>Counters are a good example for this, so let&rsquo;s demo this pattern with a counter, too:</p>

<p><code>plain UPSERT example
UPSERT { ip: '192.168.173.13' }
INSERT { ip: '192.168.173.13', name: 'flittard', counter: 1 }
UPDATE { counter : OLD.counter + 1 }
IN hosts
</code></p>

<p>The above query will again look for a document with the specified <code>ip</code> attribute. If the
document exists, its <code>counter</code> attribute will be increased by one. This is achieved by
referring to the pseudo-value <code>OLD</code>, which in the <code>UPDATE</code> case contains the previous revision
of the document.</p>

<p>If the search document does not yet exist, the <code>INSERT</code>part will be carried out, inserting
the document and setting the initial value of <code>counter</code> to 1.</p>

<p>Assuming the collection was empty before, running the above query once will make the collection
contain this data:</p>

<p>```json collection contents after running query once
[
  {</p>

<pre><code>"counter": 1,
"ip": "192.168.173.13",
"name": "flittard"
</code></pre>

<p>  }
]
```</p>

<p>When running the <code>UPSERT</code> statement again, the collection will contain the updated document:</p>

<p>```json collection contents after running the UPSERT command again:
[
  {</p>

<pre><code>"counter": 2,
"ip": "192.168.173.13",
"name": "flittard"
</code></pre>

<p>  }
]
```</p>

<p>Now let&rsquo;s run the query with adjusted <code>ip</code> and <code>name</code> values:</p>

<p><code>plain UPSERT with different ip and name
UPSERT { ip: '192.168.173.73' }
INSERT { ip: '192.168.173.73', name: 'brueck', counter: 1 }
UPDATE { counter : OLD.counter + 1 }
IN hosts
</code></p>

<p>After that, the collection will contain two documents:</p>

<p>```json collection contents
[
  {</p>

<pre><code>"counter": 2,
"ip": "192.168.173.13",
"name": "flittard"
</code></pre>

<p>  },
  {</p>

<pre><code>"counter": 1,
"name": "brueck",
"ip": "192.168.173.73"
</code></pre>

<p>  }
]
```</p>

<h2>Replace a document if it exists, otherwise create it</h2>

<p>We&rsquo;ve seen <code>UPSERT</code> with an <code>INSERT</code> and an <code>UPDATE</code> clause so far.</p>

<p><code>UPDATE</code> will partially update the previous revision of the document if present.
Only those attributes specified in the <code>update-expression</code> will be updated, and
all non-specified attributes of the original document revision will remain
unchanged.</p>

<p>If instead a full replacement of the original document is required, the <code>REPLACE</code>
clause should be used instead of <code>UPDATE</code>. <code>REPLACE</code> will overwrite the previous
revision completely with what&rsquo;s in <code>update-expression</code>.</p>

<p><code>plain UPSERT replacing a document entirely
UPSERT { ip: '192.168.173.73' }
INSERT { ip: '192.168.173.73', name: 'brueck', counter: 1 }
REPLACE { location: 'dc1' }
IN hosts
</code></p>

<p><em>note</em>: an older version of this blog post contained a wrong example here. Thanks
Andy for pointing this out!</p>

<h2>Returning documents</h2>

<p><code>UPSERT</code> can be combined with a <code>RETURN</code> statement to return either the previous
document revision (in case of <code>UPDATE</code> or <code>REPLACE</code>) or the new version of the
document.</p>

<p>Client applications can use this to check whether the <code>UPSERT</code> statement has
inserted or updated the document. In case no previous revision was present, the
pseudo-value <code>OLD</code> will be <code>null</code>.</p>

<p><code>UPSERT</code> also provides a pseudo-value named <code>NEW</code> containing the insert, updated or
replaced version of the document:</p>

<p><code>plain UPSERT with a RETURN value
UPSERT { ip: '192.168.173.187' }
INSERT { ip: '192.168.173.187', name: 'kalk', counter: 1 }
UPDATE { counter : OLD.counter + 1 }
IN hosts
RETURN { old: OLD, new: NEW }
</code></p>

<p>In the <code>INSERT</code> case, we&rsquo;ll get:</p>

<p>```json query return value for INSERT case
[
  {</p>

<pre><code>"old": null,
"new": {
  "counter": 1,
  "name": "kalk",
  "ip": "192.168.173.187"
}
</code></pre>

<p>  }
]
```</p>

<p>When running the query again, we&rsquo;ll get into the <code>UPDATE</code> case, and the same query
will now return:</p>

<p>```json query return value for the UPDATE case
[
  {</p>

<pre><code>"old": {
  "counter": 1,
  "name": "kalk",
  "ip": "192.168.173.187"
},
"new": {
  "counter": 2,
  "name": "kalk",
  "ip": "192.168.173.187"
}
</code></pre>

<p>  }
]
```</p>

<h2>Complex updates</h2>

<p>Updating and returning <code>OLD</code> and <code>NEW</code> will work with arbitrary calculations.
For example, the following query adds a value <code>development</code> to the <code>tag</code> attribute
only if not yet present in the search document:</p>

<p><code>plain adding a value to an array if not yet present
UPSERT { ip: '192.168.173.94' }                                                                              
INSERT { ip: '192.168.173.94', name: 'chorweiler', tags: [ "development" ] }                                                    
UPDATE { tags: PUSH(OLD.tags, "development", true) }                                                                          
IN hosts                                                                                                      
RETURN { old: OLD, new: NEW }
</code></p>

<p>Running the query multiple times will ensure that <code>tags</code> will contain the value
<code>development</code> only once.</p>

<p>Note: <code>PUSH</code> is a regular <a href="https://docs.arangodb.com/Aql/ArrayFunctions.html">AQL array function</a>.</p>

<h2>Restrictions</h2>

<p>The <code>search-value</code> needs to be an object literal, with attribute names being inspectable
at query compile time. This means that neither variables nor bind parameters can be used
for <code>search-value</code>.</p>

<p>However, bind parameters and variables can be used <strong>inside</strong> <code>search-value</code>.
Dynamic attribute names cannot be used for specifying attribute names in search-value`.</p>

<p><code>UPSERT</code> does not require an index to be present on the attributes of <code>search-value</code>,
but in reality queries will benefit from indexes to find matching documents.</p>

<p>When more than one document in the collection matches <code>search-value</code>, one arbitrary match
will be used for executing the <code>UPDATE</code> clause. It is therefore recommended to use
<code>UPSERT</code> commands together with a unique index or to make sure from the client application
that at most one document will match the <code>search-value</code>. Ironically, one way to achieve this is
to use the <code>UPSERT</code> command for inserts&hellip;</p>

<h2>Availability</h2>

<p><code>UPSERT</code> is currently available in the <code>devel</code> branch of ArangoDB. This branch
will eventually become release 2.6. Until then, everyone is welcome to try it out and
provide feedback.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Analyzing Git Commits With ArangoDB]]></title>
    <link href="http://jsteemann.github.io/blog/2015/03/11/analyzing-git-commits-with-arangodb/"/>
    <updated>2015-03-11T12:37:58+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/03/11/analyzing-git-commits-with-arangodb</id>
    <content type="html"><![CDATA[<p>I often find myself searching for certain commits using <code>git log</code> and friends. While I really love
the power and flexibility that come with the git and other Unix command-line tools, sometimes it can be more
convenient to use a database to filter and aggregate commit data.</p>

<p>I gave it a quick try yesterday and imported the commit history of ArangoDB&rsquo;s Git repository into ArangoDB
and ran some queries on the data. While the query results for our repository may not be interesting for everyone,
I think it is still worth sharing what I did. Even though I didn&rsquo;t try it, I think the overall procedure is
applicable with any other Git repository.</p>

<!-- more -->


<h2>Converting the Git history to JSON</h2>

<p>The way to extract history and commit data from a local repository is to use <code>git log</code>. Though its output
is greatly customizable, it does not provide an out-of-the-box solution for producing JSON. So I wrote a simple
wrapper script (in PHP) around it. The script can be found <a href="https://gist.github.com/jsteemann/65ef221646449713b2c5">here</a>.</p>

<p>Here&rsquo;s how to run it:
<code>bash converting the git history to JSON
cd path/to/local/git-repository
wget https://gist.githubusercontent.com/jsteemann/65ef221646449713b2c5/raw/fef22c729e01dd0777b378ac1e17e951ea47c7dd/git-log-to-json.php
php git-log-to-json.php &gt; arango-commits-master-201503.json
</code></p>

<p>The script may run a few minutes on bigger repositories such as ours. In the end, it should produce a JSON
file named <code>arango-commits-master-201503.json</code>.</p>

<p>I have also uploaded the JSON file <a href="/downloads/code/arango-commits-master-201503.json">here</a>. Note that the
file only contains commits from the <code>master</code> branch and not all commits done in ArangoDB in total.</p>

<h2>Importing the commits into ArangoDB</h2>

<p>The simplest way to get the commits into ArangoDB is to use <code>arangoimp</code>:</p>

<p><code>bash importing the commits into ArangoDB
arangoimp                                   \
  --collection commits                      \
  --create-collection true                  \
  --file arango-commits-master-201503.json  \
  --overwrite true                          \
  --batch-size 32000000
</code></p>

<p>This should have imported all the commits into a collection <code>commits</code> in the default database.</p>

<h2>Querying the commit logs</h2>

<p>Following are a few example queries that I ran on the data from the ArangoShell.
As mentioned before, it should be possible to run the queries for other repositories' data.</p>

<p><code>js getting all contributors
query = 'FOR commit IN commits COLLECT author = commit.author.name RETURN author';
db._query(query).toArray();
</code></p>

<p><code>js retrieving the total number of commits
query = 'FOR commit IN commits COLLECT WITH COUNT INTO count RETURN count';
db._query(query).toArray();
</code></p>

<p><code>js retrieving the number of commits by contributor
query = 'FOR commit IN commits COLLECT author = commit.author.name WITH COUNT INTO count RETURN { author: author, count: count }';
db._query(query).toArray();
</code></p>

<p><code>js retrieving the tagged commits
query = 'FOR commit IN commits FILTER commit.tag != null SORT commit.date RETURN KEEP(commit, [ "date", "message", "tag" ])';
db._query(query).toArray();
</code></p>

<p><code>js retrieving number of commits per year
query = 'FOR commit IN commits COLLECT year = DATE_YEAR(commit.date) WITH COUNT INTO count RETURN { year: year, count: count }';
db._query(query).toArray();
</code></p>

<p><code>js retrieving number of commits per month / year
query = 'FOR commit IN commits COLLECT year = DATE_YEAR(commit.date), month = DATE_MONTH(commit.date)  WITH COUNT INTO count RETURN { month: CONCAT(year, "/", month), count: count }';
db._query(query).toArray();
</code></p>

<p><code>js retrieving number of commits per weekday
query = 'FOR commit IN commits COLLECT day = DATE_DAYOFWEEK(commit.date) WITH COUNT INTO count RETURN { day: TRANSLATE(day, { "0": "Sunday", "1": "Monday", "2": "Tuesday", "3": "Wednesday", "4": "Thursday", "5": "Friday", "6": "Saturday" }), count: count }';
db._query(query).toArray();
</code></p>

<p><code>js retrieving commits with string "issue #" in commit message
query = 'FOR commit IN commits FILTER LIKE(commit.message, "%issue #%") SORT commit.date DESC LIMIT 10 RETURN UNSET(commit, "files")';
db._query(query).toArray();
</code></p>

<p><code>js retrieving number of commits related to Foxx
query = 'FOR commit IN commits FILTER LIKE(LOWER(commit.message), "%foxx%") COLLECT year = DATE_YEAR(commit.date), month = DATE_MONTH(commit.date) WITH COUNT INTO count RETURN { month: CONCAT(year, "/", month), count: count }';
db._query(query).toArray();
</code></p>

<p><code>js retrieving commits that touched the most files
query = 'FOR commit IN commits LET count = LENGTH(commit.files || []) SORT count DESC LIMIT 10 RETURN MERGE(UNSET(commit, "files"), { files: count })';
db._query(query).toArray();
</code></p>

<p><code>js retrieving files modified most often
query = 'FOR commit IN commits FOR filename IN commit.files || [] COLLECT file = filename WITH COUNT INTO count SORT count DESC LIMIT 10 RETURN { file: file, count: count }';
db._query(query).toArray();
</code></p>

<p>Enjoy!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[More ES6 Features]]></title>
    <link href="http://jsteemann.github.io/blog/2015/02/26/more-es6-features/"/>
    <updated>2015-02-26T12:00:46+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/02/26/more-es6-features</id>
    <content type="html"><![CDATA[<p>ArangoDB 2.5 comes with an upgraded version of V8, Google&rsquo;s open source JavaScript engine.</p>

<p>The built-in version of V8 has been upgraded from 3.29.54 to 3.31.74.1.</p>

<p>In addition to several already usable ES6 features (detailed in
<a href="https://jsteemann.github.io/blog/2014/12/19/using-es6-features-in-arangodb/">this blog</a>,
the following ES6 features are activated in ArangoDB 2.5 by default:</p>

<ul>
<li>iterators and generators</li>
<li>template strings</li>
<li>enhanced object literals</li>
<li>enhanced numeric literals</li>
<li>block scoping with <code>let</code> and constant variables using <code>const</code></li>
<li>additional String methods (such as <code>startsWith</code>, <code>repeat</code> etc.)</li>
</ul>


<p>The above features are available in ArangoDB 2.5, and can now be used for scripting purposes
in the ArangoShell and in server-side Foxx actions inside the database.</p>

<p>This blog post briefly explains the features provides some quick examples for using them.</p>

<!-- more -->


<h2>Iterators and generators</h2>

<p>Iterator and generator support was optional in 2.4, but is turned on by default since 2.5.</p>

<p>For everyone who is not familiar with generators in JavaScript, here&rsquo;s how they work:</p>

<p>Generators are special functions tagged with an asterisk (<code>*</code>). Values are returned to the
caller using the <code>yield</code> keyword:</p>

<p><code>js a simple generator that generates two values                                                            
function* generate () {                                                                                       
  yield 23;                                                                                                   
  yield 42;                                                                                                   
}                                                                                                            
</code></p>

<p>Calling the function with initialize/reset the generator. Calling the <code>next()</code> method on
the generator&rsquo;s initial call return value produces the next sequence element. The element
is returned in a <code>value</code> attribute. The <code>done</code> attribute indicates whether the sequence
has come to an end:</p>

<p><code>js invoking the generator
var generator = generate();                                                                                   
console.log(generator.next());  /* { "value" : 23, "done" : false } */                                        
console.log(generator.next());  /* { "value" : 42, "done" : false } */                                        
console.log(generator.next());  /* { "value" : undefined, "done" : true } */                                  
</code></p>

<p>Sequences produced by generators can also be consumed via a <code>for...of</code> loop:</p>

<p>```js consuming all values from a generator function
var generator = generate();</p>

<p>for (var value of generator) {
  console.log(value);
}
```</p>

<p>In general, every object that is iteratable can be consumed using the <code>of</code> operator.
Some built-in objects provide pre-defined iterators (e.g. <code>Map.keys()</code> or <code>Map.values()</code>),
but you can also create iterators for your own objects:</p>

<p>```js creating an iterator for an object
function Sentence (text) {
  this.text = text;
}</p>

<p>Sentence.prototype[Symbol.iterator] = function*() {
  var regex = /\S+/g;
  var text = this.text;
  var match;
  while (match = regex.exec(text)) {</p>

<pre><code>yield match[0]; 
</code></pre>

<p>  }
};</p>

<p>var sentence = new Sentence(&ldquo;The quick brown fox jumped over the lazy dog&rdquo;);
for (var word of sentence) {
  console.log(word);
}
```</p>

<h2>Template strings</h2>

<p>I know there are query string generators and such, but for the sake of the example, let&rsquo;s assume you
wanted to write a query string in JavaScript. You might end up with something like this:</p>

<p><code>js multi-line query string
var query =
  'FOR doc IN users\n' +
  '  FILTER doc.name == @name\n' +
  '  RETURN doc\n';
</code></p>

<p>This is hardly legible, and it is also very prone to errors.</p>

<p>ES6 template strings provide a way to define multi-line string literals in a much easier and simpler way.
Here&rsquo;s how to do it (note the backticks instead of the regular string quotes):</p>

<p><code>js using a multi-line template string
var query = `
FOR doc IN users
  FILTER doc.name == @name
  RETURN doc
`;
</code></p>

<p>Template strings also support value substitution, so you could even write something like this, too:
```js value substitution in template strings
var name = &ldquo;AQL injection attempt \&rdquo; OR true OR \&ldquo;&rdquo;;</p>

<p>var query = <code>
FOR doc IN users
  FILTER doc.name == ${JSON.stringify(name)}
  RETURN doc
</code>;
```</p>

<p>Note that while value substitution in template strings in convenient, you still have to be careful with
user-generated values. Otherwise you might be subject to value injection attacks, as you would be with
every other form of improper user value handling.</p>

<h2>Enhanced object literals</h2>

<p>Save some time when definining objects:</p>

<p>```js using enhanced object literals
var name = &ldquo;foobar&rdquo;;</p>

<p>myObject = {
  type : &ldquo;myType&rdquo;,   /<em> always worked </em>/
  name,              /<em> same as &ldquo;name&rdquo; : name </em>/
  save () {          /<em> same as &ldquo;save&rdquo; : function () &hellip; </em>/</p>

<pre><code>console.log("save called!"); 
</code></pre>

<p>  }
};</p>

<p>{
  &ldquo;type&rdquo; : &ldquo;myType&rdquo;,
  &ldquo;name&rdquo; : &ldquo;foobar&rdquo;,
  &ldquo;save&rdquo; : [Function &ldquo;console.log("save called!&rdquo;);&ldquo; &hellip;]
}
```</p>

<p>As can be seen above, enhanced object literal declarations can save some typing and reduce redundancies
in the code. Unfortunately we still cannot use object key names generated from expressions:</p>

<p><code>js does not work yet
myObject = {
  [ "foo" + bar" ] : "foobar"
};
</code></p>

<h2>Enhanced numeric literals</h2>

<p>Numeric values can now be specified in binary or octal if required:</p>

<p><code>js numeric literals                                                                                        
var life = 0b101010;          /* binary, 42 in decimal */                                                     
var filePermissions = 0o777;  /* octal, 511 in decimal */                                                     
</code></p>

<h2>Block scoping</h2>

<p>As a mostly C++ programmer, I am always puzzled about the scoping of JavaScript variables.
In the following example, variable <code>x</code> does not only live inside the curly brackets block in which
it was declared, but also afterwards:</p>

<p>```
function work () {
  {</p>

<pre><code>var x = 1;
</code></pre>

<p>  }
  return x;
}
```</p>

<p>The reason is that the curly brackets around <code>var x = 1;</code> are not a scope at all in traditional
JavaScript. This sucks, because variables can linger around in programs longer than necessary,
leading to unwanted side-effects.</p>

<p>With block-level scopes, this can be fixed. To use it, introduce variables not with the <code>var</code>
keyword, but with <code>let</code>. <code>let</code> only works in strict mode, so make sure your function or module
uses it.</p>

<p>Now, with block-level scoping, the above snippet looks like this:
```
function work () {
  &ldquo;use strict&rdquo;;
  {</p>

<pre><code>let x = 1; 
</code></pre>

<p>  }
  return x;
};
```</p>

<p>And it will actually produce an error when trying to access variable <code>x</code> in the <code>return</code> statement.
The reason is that the life of <code>x</code> was over as soon as its scope was left. The scope of variable <code>x</code> is
now only the one with the <code>let</code> declaration inside the curly brackets.</p>

<p>Someone else said &ldquo;<em>let is the new var</em>&rdquo;, and I think there&rsquo;s not much to add.</p>

<p>Additionally, the <code>const</code> keyword can be used to define a read-only variables. Trying to re-define a
constant will produce an error in strict mode (the desired behavior), and do nothing in non-strict mode.
Another reason to use the strict mode.</p>

<h2>Additional String methods</h2>

<p><code>String</code> objects now provide extra built-in methods:</p>

<ul>
<li><code>string.startsWith(what)</code></li>
<li><code>string.endsWith(what)</code></li>
<li><code>string.includes(what)</code></li>
<li><code>string.repeat(count)</code></li>
<li><code>string.normalize(method)</code></li>
<li><code>string.codePointAt(position)</code></li>
</ul>


<p>There is also an extra &ldquo;static&rdquo; method:</p>

<ul>
<li><code>String.fromCodePoint(codePoint)</code></li>
</ul>

]]></content>
  </entry>
  
</feed>
