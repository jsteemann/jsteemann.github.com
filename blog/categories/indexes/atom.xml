<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Indexes | J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/blog/categories/indexes/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2015-03-10T16:44:11+01:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AQL Improvements in 2.5]]></title>
    <link href="http://jsteemann.github.io/blog/2015/02/26/aql-improvements-in-25/"/>
    <updated>2015-02-26T10:35:31+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/02/26/aql-improvements-in-25</id>
    <content type="html"><![CDATA[<p>Contained in 2.5 are some small but useful AQL language improvements plus several AQL optimizer improvements.</p>

<p>We are working on further AQL improvements for 2.5, but work is still ongoing.
This post summarizes the improvements that are already completed and will be shipped with the initial ArangoDB
2.5 release.</p>

<!-- more -->


<h1>Language improvements</h1>

<h2>Dynamic attribute names</h2>

<p>Often the need arises to dynamically name object attributes in return values.
In AQL this was not directly possible so far, though there were some workarounds available to achieve about
the same result. <a href="https://docs.arangodb.com/cookbook/UsingDynamicAttributeNames.html">This recipe</a> summarizes
the options that are available to pre-ArangoDB 2.5 users.</p>

<p>With ArangoDB 2.5, dynamic attribute names can be constructed much more easily and flexibly. Object
attribute names in ArangoDB 2.5 can be specified using static string literals, bind parameters,
and dynamic expressions.</p>

<p>Dynamic expressions are most interesting, and to disambiguate them from other regular string literal attribute
names, dynamic attribute names need to be enclosed in square brackets (<code>[</code> and <code>]</code>). I have written about
that before in <a href="http://jsteemann.github.io/blog/2015/02/03/using-dynamic-attribute-names-in-aql/">this blog</a>.</p>

<p>Here is an example query that uses the new syntax:</p>

<p><code>plain example query using dynamic attribute names
FOR i IN [ 17, 23, 42, 83 ]
  RETURN { [ CONCAT('value-of-', i, ' * ', i) ] : i * i }
</code></p>

<p>This will produce:</p>

<p>```json query result
[
  {</p>

<pre><code>"value-of-17 * 17" : 289 
</code></pre>

<p>  },
  {</p>

<pre><code>"value-of-23 * 23" : 529 
</code></pre>

<p>  },
  {</p>

<pre><code>"value-of-42 * 42" : 1764 
</code></pre>

<p>  },
  {</p>

<pre><code>"value-of-83 * 83" : 6889 
</code></pre>

<p>  }
]
```</p>

<h2>Functions added</h2>

<p>The following AQL functions have been added in 2.5:</p>

<ul>
<li><code>MD5(value)</code>: produces the MD5 hash of <code>value</code></li>
<li><code>SHA1(value)</code>: produces the SHA1 hash of <code>value</code></li>
<li><code>RANDOM_TOKEN(length)</code>: produces a pseudo-random string of the specified length.
 Such strings can be used for id or token generation. Tokens consist only of letters
 (lower and upper case) plus digits, so they are also URL-safe</li>
</ul>


<h1>Optimizer improvements</h1>

<h2>Optimizer rules</h2>

<p>The following AQL optimizer rules have been added in ArangoDB 2.5:</p>

<ul>
<li><p><code>propagate-constant-attributes</code></p>

<p>This rule will look inside <code>FILTER</code> conditions for constant value equality comparisons,
and insert the constant values in other places in <code>FILTER</code>s. For example, the rule will
insert <code>42</code> instead of <code>i.value</code> in the second <code>FILTER</code> of the following query:</p>

<pre><code>FOR i IN c1 
  FOR j IN c2 
    FILTER i.value == 42 
    FILTER j.value == i.value 
    RETURN 1
</code></pre></li>
<li><p><code>move-calculations-down</code></p>

<p>This rule moves calculations down in the execution plan as far as possible. The intention
is to move calculations beyond filters, in order to avoid calculations and computations
for documents that will be filtered away anyway.</p>

<p>If a query contains a lot of computations and a lot of documents will be skipped because
of filters, this rule might provide a big benefit.</p>

<p>A more detailed example is provided in
<a href="http://jsteemann.github.io/blog/2015/01/31/yaor-yet-another-optimizer-rule/">this post</a>.</p></li>
</ul>


<p>The already existing optimizer rule <code>use-index-for-sort</code> was also improved in the following way:</p>

<ul>
<li><p>the rule can now remove <code>SORT</code>s also in case a non-sorted index (i.e. a hash index) is used
for an equality lookup and all sort attributes are covered by the index.</p></li>
<li><p>the rule can also remove <code>SORT</code>s in case the sort critieria excludes the left-most index attributes,
but the left-most index attributes are used in a <code>FILTER</code> for equality-only lookups.</p>

<p>Here is an example that will use an existing skiplist index on [ <code>value1</code>, <code>value2</code> ] for sorting,
removing the extra <code>SORT</code>:</p>

<pre><code>FOR doc IN collection 
  FILTER doc.value1 == 1 
  SORT doc.value2 
  RETURN doc
</code></pre></li>
</ul>


<h2>Index usage</h2>

<p>The AQL optimizer now supports <a href="https://www.arangodb.com/2015/02/24/sparse-indexes-in-arangodb">sparse indexes</a>,
a feature added in 2.5.</p>

<p>It will use them automatically in queries when appropriate and when safe. Sparse indexes do exclude certain
documents purposely, so the optimizer always has to figure out whether it can use a sparse index to satisfy
a given <code>FILTER</code> condition.</p>

<p>The optimizer will also take into account index selectivity estimates when there are multiple index candidates.</p>

<h2>Estimates</h2>

<p>The optimizer estimates for the number of documents to be returned by a query or a subquery are more accurate
now for several types of queries. For example, if the optimizer can use a primary key, an edge index, or a hash
index in a given query part, it will use the index selectivity estimates for calculating the number of return
documents.</p>

<p>These estimates will be a lot more accurate than the previoulsy hard-coded filtering factors, and can lead to
better optimizer decisions and reporting (because estimates are returned in <code>explain</code> results, too).</p>

<h2>Memory savings</h2>

<p>Finally, the optimizer will now detect if the data-modification part in a data-modification query
can be executed in lockstep with the data-retrieval part of the same query. Previously, a data-modification
query always executed its data-retrieval part first, and then executed its data-modification part.
This could have resulted in big intermediate result sets which to retrieval part constructed in order
to pass them to the modification part of the query.</p>

<p>Here&rsquo;s an example query:</p>

<p><code>plain data-modification query
FOR doc IN test
  INSERT doc INTO backup
</code></p>

<p>In the above query, the <code>FOR</code> loop is the retrieval part, and the <code>INSERT</code> is the modification part.
The optimizer in 2.5 will check if the two parts of the query are independent, and if it turns out they are,
will execute them in lockstep instead of sequentially.</p>

<p>The execution in lockstep is not necessarily faster than sequential execution, but it can save lots of
memory if the data-retrieval part constructed big intermediate result sets.</p>

<h1>Miscellaneous changes</h1>

<p>The AQL query execution statistics now also provide an attribute <code>filtered</code>. Its value indicates how many
documents were filtered by <code>FilterNode</code>s in the AQL query. This can be used as an indicator for whether
indexes should be added, and for how effective indexes are used for filtering.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improved Non-unique Hash Indexes in 2.3]]></title>
    <link href="http://jsteemann.github.io/blog/2014/11/07/improved-non-unique-hash-indexes/"/>
    <updated>2014-11-07T20:51:12+01:00</updated>
    <id>http://jsteemann.github.io/blog/2014/11/07/improved-non-unique-hash-indexes</id>
    <content type="html"><![CDATA[<p>With ArangoDB 2.3 now getting into the <a href="https://www.arangodb.com/install-beta-version">beta stage</a>,
it&rsquo;s time to spread the word about new features and improvements.</p>

<p>Today&rsquo;s post will be about the changes made to non-unique hash
indexes.</p>

<!-- more -->


<p>Hash indexes allow looking up documents quickly if the indexed
attributes are all provided in a search query. They are not
suitable for range queries, but are the perfect choice if equality
comparisons are all that&rsquo;s needed.</p>

<p>Hash indexes have been available in ArangoDB ever since. There
have always been two variants of them:</p>

<ul>
<li>unique hash indexes</li>
<li>non-unique hash indexes</li>
</ul>


<p>There wasn&rsquo;t much to be done for unique hash indexes, and so there
haven&rsquo;t been any changes to them in 2.3. However, the non-unique
hash indexes were improved significantly in the new version.</p>

<p>The non-unique indexes already performed quite well if most of the
indexed values were unique and only few repetitions occurred. But their
performance suffered severly if the indexed attribute values repeated
a lot &ndash; that is, when the indexed value had a <strong>low cardinality</strong> and thus
the index had a <strong>low selectivity</strong>.</p>

<p>This was a problem because it slowed down inserting new documents into
a collection with such an index. And it also slowed down loading collections
with low cardinality hash indexes.</p>

<p>I am happy to state that in ArangoDB 2.3 this has been fixed, and the insert
performance of non-unique hash indexes has been improved significantly.
The index insertion time now scales quite well with the number
of indexed documents regardless of the cardinality of the indexed
attribute.</p>

<p>Following are a few measurements of non-unique hash index insertion
times from ArangoDB 2.3, for different cardinalities of the indexed
attribute.</p>

<p>The times reported are the net non-unique hash index
insertion times (the documents were present already, just the index
was created on them and index creation time was measured).</p>

<p>Let&rsquo;s start with a not too challenging case: indexing documents in
a collection with 100,000 different index values (<em>cardinality 100,000</em>):</p>

<p><code>text index insertion times for cardinality 100,000
number of documents:    128,000    =&gt;    time:   0.144 s
number of documents:    256,000    =&gt;    time:   0.231 s
number of documents:    512,000    =&gt;    time:   0.347 s
number of documents:  1,024,000    =&gt;    time:   0.694 s
number of documents:  2,048,000    =&gt;    time:   1.379 s
</code></p>

<p>The picture doesn&rsquo;t change much when reducing the cardinality
by a factor or 10 (i.e. <em>cardinality 10,000</em>):</p>

<p><code>text index insertion times for cardinality 10,000
number of documents:    128,000    =&gt;    time:   0.169 s
number of documents:    256,000    =&gt;    time:   0.194 s
number of documents:    512,000    =&gt;    time:   0.355 s
number of documents:  1,024,000    =&gt;    time:   0.668 s
number of documents:  2,048,000    =&gt;    time:   1.325 s
</code></p>

<p>Let&rsquo;s again divide cardinality by 10 (now <em>cardinality 1,000</em>):</p>

<p><code>text index insertion times for cardinality 1,000
number of documents:    128,000    =&gt;    time:   0.130 s
number of documents:    256,000    =&gt;    time:   0.152 s
number of documents:    512,000    =&gt;    time:   0.261 s
number of documents:  1,024,000    =&gt;    time:   0.524 s
number of documents:  2,048,000    =&gt;    time:   0.934 s
</code></p>

<p><em>Cardinality 100</em>:</p>

<p><code>text index insertion times for cardinality 100
number of documents:    128,000    =&gt;    time:   0.114 s
number of documents:    256,000    =&gt;    time:   0.148 s
number of documents:    512,000    =&gt;    time:   0.337 s
number of documents:  1,024,000    =&gt;    time:   0.452 s
number of documents:  2,048,000    =&gt;    time:   0.907 s
</code></p>

<p><em>Cardinality 10</em>:</p>

<p><code>text index insertion times for cardinality 10
number of documents:    128,000    =&gt;    time:   0.130 s
number of documents:    256,000    =&gt;    time:   0.327 s
number of documents:    512,000    =&gt;    time:   0.239 s
number of documents:  1,024,000    =&gt;    time:   0.442 s
number of documents:  2,048,000    =&gt;    time:   0.827 s
</code></p>

<p>Finally we get to <em>cardinality 1</em>, the definitive indicator
for the index being absolutely useless. Let&rsquo;s create it anyway,
for the sake of completeness of this post:</p>

<p><code>text index insertion times for cardinality 1
number of documents:    128,000    =&gt;    time:   0.130 s
number of documents:    128,000    =&gt;    time:   0.095 s
number of documents:    256,000    =&gt;    time:   0.146 s
number of documents:    512,000    =&gt;    time:   0.246 s
number of documents:  1,024,000    =&gt;    time:   0.445 s
number of documents:  2,048,000    =&gt;    time:   0.925 s
</code></p>

<p>On a side note: all indexed values were numeric. In absolute terms,
indexing string values will be slower than indexing numbers, but insertion
should still scale nicely with the number of documents as long as everything
fits in RAM.</p>
]]></content>
  </entry>
  
</feed>
