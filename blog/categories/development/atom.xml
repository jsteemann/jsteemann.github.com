<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Development | J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/blog/categories/development/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2015-09-10T14:56:22+02:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Less Intrusive Linking]]></title>
    <link href="http://jsteemann.github.io/blog/2015/05/07/less-intrusive-linking/"/>
    <updated>2015-05-07T19:52:53+02:00</updated>
    <id>http://jsteemann.github.io/blog/2015/05/07/less-intrusive-linking</id>
    <content type="html"><![CDATA[<p>A while ago our continuous integration builds on <a href="http://travis-ci.org">TravisCI</a>
began to fail seemingly randomly because the build worker was killed without
an apparent reason. Obviously the build process reached some resource limits
though we couldn&rsquo;t find any documented limit that the build obviously violated.</p>

<p>Some builds still succeeded without issues, but those builds that were killed
had one thing in common: they were all stuck waiting the linker to finish.</p>

<p>The default linker used on TravisCI is <em>GNU ld</em>. After some research, it turned
out that replacing <em>GNU ld</em> with <em>GNU gold</em> not only made the linking much
faster, but also less resource-intensive. Linking ArangoDB on my local machine
is almost twice as fast with <em>gold</em> as with <em>ld</em>. Even better, after reconfiguring
our TravisCI builds to also use <em>gold</em>, our builds weren&rsquo;t killed anymore by
TravisCI&rsquo;s build scheduling system.</p>

<p>To make TravisCI use <em>gold</em> instead of <em>ld</em>, add the following to your project&rsquo;s
<code>.travis.yml</code> in the <code>install</code> section (so it gets execute before the actual build
steps):</p>

<p><code>bash commands for wrapping gold
sudo apt-get -y install binutils-gold
mkdir -p ~/bin/gold
echo '#!/bin/bash' &gt; ~/bin/gold/ld
echo 'gold "$@"' &gt;&gt; ~/bin/gold/ld
chmod a+x ~/bin/gold/ld
export CFLAGS="-B$HOME/bin/gold $CFLAGS"
export CXXFLAGS="-B$HOME/bin/gold $CXXFLAGS"
</code></p>

<p>The script downloads and installs <em>gold</em> and creates a tiny wrapper script in a
file named <code>ld</code> in the user&rsquo;s home directory. The wrapper simply calls <em>gold</em>
with all the arguments passed to the wrapper. Finally, the script modifies the
environments <code>CFLAGS</code> and <code>CXXFLAGS</code> by setting the <code>-B</code> parameter to the
wrapper script&rsquo;s directory.</p>

<p><code>-B</code> is the option for the compiler&rsquo;s search path. The compiler (g++) at least
will look in this path for any helper tools it invokes. As we have a file named
<code>ld</code> in this directory, g++ will use our wrapper script instead of the original
<code>ld</code> binary. This way we can keep the original version of <code>ld</code> in <code>/usr/bin</code>,
and only override it using environment variables. This is also helpful in
other contexts, e.g. when <code>ld</code> shall remain as the system&rsquo;s default linker but
<code>gold</code>shall only be used for linking a few selected components.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Ccache When Working With Different Branches]]></title>
    <link href="http://jsteemann.github.io/blog/2015/02/07/using-ccache-when-working-with-different-branches/"/>
    <updated>2015-02-07T17:00:15+01:00</updated>
    <id>http://jsteemann.github.io/blog/2015/02/07/using-ccache-when-working-with-different-branches</id>
    <content type="html"><![CDATA[<p>Git makes working with many different branches in the same local repository easy and efficient.</p>

<p>In a C/C++ project, the code must be re-compiled after switching into another branch.
If the branches only differ minimally, running <code>make</code> will only re-compile the parts that are
actually different, and after that re-link them. That won&rsquo;t take too long, though especially
link times can be annoying.</p>

<p>However, if there are differences in central header files that are included from every file,
then <code>make</code> has no option but to <strong>re-compile everything</strong>. This can take significant amounts of
time (and coffee).</p>

<p>I just realized that there is a solution to speed up re-compilation in this situation:
<a href="http://linux.die.net/man/1/ccache">ccache</a>!</p>

<!-- more -->


<h2>Why ccache can help</h2>

<p>ccache is a wrapper for the actual compiler command. It will call the compiler with the specified
arguments, and capture the compiler output. When called again with the same arguments, it will
look in its internal cache for a ready-to-serve result. If one is present, it will return it
without invoking the compiler again. Otherwise, or if it detects some changes that forbid serving
outdated results from the cache, it will transparently invoke the compiler.</p>

<p>When switching back to another branch that you had already compiled before, running <code>make</code>
may re-build <em>everything</em> due to changes in headers. But it is not unlikely that you had built
the branch before already. If so, and ccache was involved in the previous build, it may still
have all the info required for re-compilation in its cache.</p>

<p>And everyone will be happy: <code>make</code> will run its full rebuild, but most operations won&rsquo;t be handed
to the compiler because ccache is sitting in between, serving results from its cache.
And you as a developer won&rsquo;t lose that much time.</p>

<h2>Some figures</h2>

<p>Following are some figures demonstrating its potential when running a <code>make</code> in the devel branch
after having returned from a different branch with significant changes.</p>

<h3>With ccache, but cache empty</h3>

<p><code>plain time make
real  12m43.501s
user  11m52.550s
sys 0m44.110s
</code></p>

<h3>With ccache, everything in cache</h3>

<p><code>plain time make
real  0m55.572s
user  0m26.346s
sys 0m7.551s
</code></p>

<p>That&rsquo;s a <strong>build time reduction of more than 90 %</strong>!</p>

<p>This is already the optimal result, as everything was already present in the cache.
However, the situation was not unrealistic. I often switch into another branch, try something
out or commit a small change, and the return to the original branch. I already started having
many separate directories for the different branches to avoid frequent recompilation.
ccache can be relief here.</p>

<p>By the way, timing results are from my laptop. I did not bother to run <code>make</code> with parallel
jobs as this has limited effect on my laptop, though on more decent hardware it may be beneficial
both with and without ccache, though I guess, with many parallel jobs and a full cache, linking
will become the most expensive part.</p>

<h2>How to use ccache</h2>

<p>For Ubuntu, ccache is available in package <code>ccache</code>. You can easily install it with:
<code>bash Installing ccache on Ubuntu
sudo apt-get install ccache
</code></p>

<p>The most convenient way to use ccache in your build is to change your <code>CC</code> and <code>CXX</code>
environment variables as follows:
<code>bash setting compilers environment variables
export CC="ccache gcc"
export CXX="ccache g++"
</code></p>

<p>I suggest putting that into <code>.bashrc</code> so the variables will be set in every session and not
just once. After that, running <code>configure</code> will write a <code>Makefile</code> that will use ccache for
building object files.</p>

<p>Note: that will change these environment variables globally, so ccache may be used for other
projects, too.</p>

<h3>What ccache cannot do</h3>

<p>I already forgot about ccache because when working in a single branch it does not provide that
many benefits. When making changes to your code, you can be pretty sure the new code won&rsquo;t be
in the cache yet. Running <code>make</code> then will invoke ccache, but this will result in a cache miss.
It cannot help here, because the new code was never compiled before and thus in no cache.</p>

<p>Additionally, <code>make</code> is smart enough on its own to only re-build the parts of the program that
have actually changed or depend on the changes you made.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Core Dumps of Failed TravisCI Builds]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/30/getting-core-dumps-of-failed-travisci-builds/"/>
    <updated>2014-10-30T23:05:48+01:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/30/getting-core-dumps-of-failed-travisci-builds</id>
    <content type="html"><![CDATA[<p>I recently wrote about <a href="/blog/2014/10/17/using-travis-ci-for-a-c-plus-plus-11-project/">using TravisCI for continuously testing C++11 projects</a>.</p>

<p><strong>Now, what if a build fails?</strong></p>

<p>Especially for C and C++ projects, build failures may mean crashed
programs. In a local setup, the usual way to analyze program crashes
is to manually inspect the core files that are written on crash.</p>

<p>With TravisCI, there is no way to log in to a build machine and
inspect a core dump interactively. There is no SSH access to
the build machines. TravisCI does not even persist any state of
builds but the result and the log output.</p>

<p>There is a way to get to the core dumps, but it was fiddly to find
out and set up.</p>

<!-- more -->


<p>The basic idea is to run <code>gdb</code> on the TravisCI build machine
automatically when a build fails. <code>gdb</code> can be scripted, so all
we need to do is to make it print a backtrace in all threads at
the time of the crash.</p>

<p>By default, no core dumps will be produced on TravisCI. To turn them
on, an appropriate ulimit value must be set. We also need to install
<code>gdb</code> so we can actually run it. Here is the <code>.travis.yml</code> adjustment
for these prerequisites:</p>

<p>```yaml adjustments for install and before_script hooks
install:
&ndash; sudo apt-get install -y gdb  # install gdb</p>

<p>before_script:
&ndash; ulimit -c unlimited -S       # enable core dumps
```</p>

<p>To get an idea of where the program crashed, we can finally install
an <code>after_failure</code> hook. This hook can check for a core file and use
<code>gdb</code> to print a nice backtrace.</p>

<p>The core file pattern on TravisCI seems to be <code>core-%p</code>, so core
filenames will include the executable&rsquo;s process id and change on
every run. We can use <code>find</code> to look for files named <code>core*</code> in the
cwd and pick the first one as there should only be at most one core
file per build:</p>

<p><code>yaml adjustments for after_failure hook
after_failure:
- COREFILE=$(find . -maxdepth 1 -name "core*" | head -n 1) # find core file
- if [[ -f "$COREFILE" ]]; then gdb -c "$COREFILE" example -ex "thread apply all bt" -ex "set pagination 0" -batch; fi
</code></p>

<p>A failed build might produce output like this:</p>

<p><img src="/downloads/screenshots/travis-ci-gdb.png"></p>

<p>I recommend compiling the executable to test with debug symbols on and
with all optimizations turned off (i.e. compiler options <code>-g -O0</code>).
Otherwise backtraces might reveal less useful information for debugging.</p>

<p>On a side note: the <a href="http://lint.travis-ci.org/">Travis WebLint</a> is a
handy tool for validating <code>.travis.yml</code> files <em>before</em> pushing them.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What I Most Like About C++11]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/23/what-i-most-like-about-c-plus-plus-11/"/>
    <updated>2014-10-23T23:02:12+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/23/what-i-most-like-about-c-plus-plus-11</id>
    <content type="html"><![CDATA[<p>About half a year ago we started compiling our code with <code>-std=c++11</code>.</p>

<p>We had to fix a few, but not too many code parts for this. That was
the easy part.</p>

<p>Getting C++11 to work on all supported platforms, build and testing
environments was a bit more challenging, but we finally managed to do it.</p>

<p>Having used C++11 for some time now, I think it&rsquo;s time to share a few
of improvements in C++11 that solve common problems.</p>

<!-- more -->


<p>First of all, I don&rsquo;t regret we changed to it. In my opinion,
<strong>C++11 makes coding easier and safer.</strong> I will try to demonstrate that
with a few examples in a second.</p>

<p>Before I go into details, just let me state that I will only show a few
of my personal favorites here. There are so many more improvements in C++11
that are all worth having a look. If you haven&rsquo;t looked into C++11 much,
I recommend getting started at the <a href="http://en.wikipedia.org/wiki/C%2B%2B11">Wikipedia page about C++11</a>.</p>

<h2>Auto</h2>

<p>From a developer perspective, one of the most compelling features of
C++11 is the revamped <code>auto</code> keyword. Consider the following C++98/C++03 code:</p>

<p><code>c++ C++03 version
std::map&lt;std::string, std::string&gt;::iterator it = resultHeaders.find(value);
if (it != resultHeaders.end()) {
  // do something with value
}
</code></p>

<p>In C++11 this code can be simplified to:
<code>c++ C++11 version with auto
auto it = resultHeaders.find(value);
if (it != resultHeaders.end()) {
  // do something with value
}
</code>
In the C++11 version of the code, the compiler can figure out the type of
variable <code>it</code> all by itself. This allows writing less (i.e. better) code.</p>

<p>The more complex the types are, the more helpful this gets. Compare the
following two lines and check for yourself which one you prefer:</p>

<p><code>c++ C++03 version
std::map&lt;CollectionID, std::shared_ptr&lt;std::vector&lt;std::string&gt; &gt; &gt;::iterator it = shards.find(collectionID);
</code></p>

<p><code>c++ C++11 version with auto
auto it = shards.find(collectionID);
</code></p>

<p><code>auto</code> provides an <em>extra benefit</em>:
when using <code>auto</code> it is not necessary to repeat the type information
throughout the code. This is helpful when types need to be changed and the
change needs to be reflected everywhere. With <code>auto</code>, chances are that less
code needs to be adjusted. And it is not necessary to set up extra
typedefs for this.</p>

<p>If you think <code>auto</code> obfuscates the meaning too much, you can be a bit more
expressive, e.g.</p>

<p><code>c++ C++11 version with auto, const reference
auto const&amp; it = resultHeaders.find(value);
if (it != resultHeaders.end()) {
  // do something with value
}
</code></p>

<h2>Range-based loops</h2>

<p>We all have written a lot of code that iterates over a ranges, like this:</p>

<p><code>c++ C++03: iterating over a range
std::map&lt;string, AgencyCommResultEntry&gt;::iterator it;
for (it = result.values.begin(); it != result.values.end(); ++it) {
  // do something with it
}
</code></p>

<p>C++11 provides a special range-based syntax for <code>for</code> loops, which makes
this a lot easier and compact:
<code>c++ C++11: iterating over a range
for (auto it : result.values) {
  // do something with it
}
</code></p>

<h2>Decltype</h2>

<p>As we have seen, the compiler can deduce the type of expressions
automatically. C++11 also allows using this type information with the
<code>decltype</code> keyword. This allows to write more generic and maintainable code.</p>

<p>In the following code, the type of variable <code>document</code> is a pointer to a
<code>Document</code>. Variable <code>myDocument</code> has the same type:</p>

<p><code>c++ C++03 explicit type specification
Document* document = res-&gt;getDocumentCollection(registerId);
Document* myDocument = document;
</code></p>

<p>In C++03, we couldn&rsquo;t tell the compiler that the two variables should
always have the same types. In C++11, we can explicitly give <code>myDocument</code>
the same type as <code>document</code>, without any typedefs:</p>

<p><code>c++ C++11 automatic type deduction
</code>c++ C++11 automatic type deduction
auto* document = res->getDocumentCollection(registerId);
decltype(document) myDocument = document;  // myDocument has same type as document
```</p>

<p><code>decltype</code> can also be used to deduce the type of expressions.</p>

<h2>Lambdas / Closures</h2>

<p>Lambdas are available in most other mainstream languages today, and they
are available in C++11, too.</p>

<p>Probably one of the most common use cases for a lambda is a custom
comparator function for sorting:</p>

<p>```c++ custom comparator function using a lambda
std::sort(operations.begin(),</p>

<pre><code>      operations.end(), 
      [] (Operation const* left, Operation const* right) {
</code></pre>

<p>  return (left->id &lt; right->id);
});
```</p>

<p>In the above example, the lambda has two input parameters and produces a
boolean result. Note that the type of the result was not explicitly specified.
Again the compiler is able to figure it out automatically.</p>

<p>A lambda can be assigned to a variable, and it can be passed as a parameter
to another function/method. Lambdas can optionally have access to the
variables of the scope they were created in.</p>

<p>The following code defines a struct <code>ScopeGuard</code> that executes a lambda
in its constructor and another lambda in its destructor:</p>

<p>```c++ lambdas as function parameters
// define ScopeGuard struct
struct ScopeGuard {
  ScopeGuard (std::function&lt;void()> onEnter,</p>

<pre><code>          std::function&lt;void()&gt; onExit) 
: onExit(onExit) {
  onEnter();
</code></pre>

<p>  }</p>

<p>  ~ScopeGuard () {</p>

<pre><code>onExit();
</code></pre>

<p>  }</p>

<p>  std::function&lt;void()> onExit;
};</p>

<p>// lambda to be executed in constructor
auto onEnter = <a href="">&amp;engine</a> &ndash;> void {
  engine->getQuery()&ndash;>enterContext();
};</p>

<p>// lambda to be executed in destructor
auto onExit = <a href="">&amp;</a> &ndash;> void {
  for (auto expression : allVariableBoundExpressions) {</p>

<pre><code>expression-&gt;invalidate();
</code></pre>

<p>  }
  engine->getQuery()&ndash;>exitContext();
}</p>

<p>// create guard object with the lambdas
// this will instantly execute <code>onEnter</code>
ScopeGuard guard(onEnter, onExit);</p>

<p>// do something&hellip;</p>

<p>// when scope is left, <code>onExit</code> will be executed
```</p>

<p>As mentioned before, <code>decltype</code> can be used to determine the
return type of a function automatically. Here&rsquo;s an example:</p>

<p><code>c++ function with automatic return type deduction
auto add = [](int a, int b) -&gt; decltype(a + b) {
  return a + b;
};
</code></p>

<p>As can be seen in the examples above, C++11 has introduced an
alternative function declaration syntax, with the type of the
function result following a <code>-&gt;</code>. The return type can be omitted
if it can be unambiguously determined by the compiler. The new
function declaration syntax is mainly useful for lambdas, but
it can be used for regular functions, too.</p>

<h2>Enum class</h2>

<p>Enums in C++ are useful but just <em>don&rsquo;t feel right</em>: persisting a
struct that contains an enum value is not portable as the
underlying data type for the enum is implementation-dependent.</p>

<p>Additionally, enum values can be compared to almost any other values,
which in most cases doesn&rsquo;t make sense but obfuscates coding errors.
There were also <em>scoping issues</em> with enum values.</p>

<p>C++11 enum classes fix these problems. First of all, the underlying
data type for an enum can be specified. For example, this creates
an enum based with its value stored in an <code>std::uint8_t</code>:</p>

<p>```c++ enum class with specified data type
enum class StatusType : std::uint8_t {
  UNINITIALIZED = 0,
  STARTING,
  RUNNING,
  STOPPING,
  STOPPED
};</p>

<p>StatusType status;
```</p>

<p>Regarding the comparison of enum values to other values, C++11
enum classes are much stronger typed than regular enums.
Comparing the <code>status</code> variable from the above example to anything
but a value from its enum class won&rsquo;t even compile.</p>

<p>This provides much greater type safety than when using the old,
implicitly converting enums:</p>

<p><code>c++ invalid usage of enums
if (status == 0) {  // won't compile in C++11
  // ...
}
if (status == StatusType::UNINITIALIZED) {  // this would work
  // ...
}
</code></p>

<p>Finally, enum classes fix the scoping problems of regular enums.
In C++03, the following code did not complile because two enums
contained the same member name:</p>

<p>```c++ two enums with same member name
enum DirectionType {
  LEFT,
  RIGHT
};</p>

<p>enum AnswerType {
  RIGHT,  // won&rsquo;t compile in C++03 and C++11
  WRONG
};
```</p>

<p>With C++11 enum classes, the following code is all fine:
```c++ two enums class with same member name
enum class DirectionType {
  LEFT,
  RIGHT
};</p>

<p>enum class AnswerType {
  RIGHT,  // works!
  WRONG
};
```</p>

<h2>Additional containers</h2>

<p>C++11 provides the hash-based containers <code>std::unordered_map</code>
and <code>std::unordered_set</code> (plus their non-unique counterparts).
These containers are not sorted, so they can be more efficient
than <code>std::map</code> and <code>std::set</code>.</p>

<p>Turning an <code>std::map</code> into an <code>std::unordered_map</code> is simple as
the APIs are more or less identical.</p>

<p>There is now also a singly-linked list container, named
<code>std::forward_list</code>. This obviously allows forward iteration
only, but is more space efficient than the already existing
doubly-linked list container.</p>

<h2>More</h2>

<p>Other improvements include move semantics, atomic variables and
operations, a dedicated type for NULL pointers, STL support for
threads and mutexes, regular expressions, more Unicode support,
override, final &ndash; to name only a few&hellip;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Travis CI for a C++11 Project]]></title>
    <link href="http://jsteemann.github.io/blog/2014/10/17/using-travis-ci-for-a-c-plus-plus-11-project/"/>
    <updated>2014-10-17T19:36:57+02:00</updated>
    <id>http://jsteemann.github.io/blog/2014/10/17/using-travis-ci-for-a-c-plus-plus-11-project</id>
    <content type="html"><![CDATA[<p><a href="http://travis-ci.com">TravisCI</a> is a very useful cloud service
for continous integration. It can be integrated with Github, with each
commit triggering a new build and reporting back when it broke something.</p>

<p>Travis has support for many programming languages, among them C++.
But it lacks support for C++11 features.</p>

<!-- more -->


<p>Travis provides basic support for C++ projects. <a href="http://docs.travis-ci.com/user/languages/cpp/">It comes with gcc, clang,
the autotools, make, cmake and scons</a>.</p>

<p>While writing this post, Travis CI build machines run on Ubuntu 12.04
LTS 64 bit. This version of Ubuntu is rather old already, and does not bring
too many packages for C++11 development. For example, the default
C++ compiler installed on TravisCI is g++-4.6.3. This version
doesn&rsquo;t even understand the compile option <code>-std=c++11</code>.</p>

<p>Official C++11 support <a href="https://gcc.gnu.org/projects/cxx0x.html">started in g++ 4.7</a>,
though C++0x features were supported way earlier. But to get decent C++11 support
in g++, it is best to use g++4.8 or higher.</p>

<p>Fortunately TravisCI allows installing other software. To get
a more recent C++ compiler, it can simply be added from a PPA.
This can be achieved by putting the PPA in the <code>.travis.yml</code> file of your
Github repository, e.g.</p>

<p>```yaml
language: cpp
compiler: g++</p>

<p>before_install:
&ndash; sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test
&ndash; sudo apt-get update -qq</p>

<p>install:
&ndash; sudo apt-get install -qq g++-4.8
&ndash; export CXX=&ldquo;g++-4.8&rdquo;
```</p>

<p>I have set up an <a href="https://github.com/jsteemann/travis-cxx11">example project on Github</a>
that demonstrates how to use it.</p>
]]></content>
  </entry>
  
</feed>
