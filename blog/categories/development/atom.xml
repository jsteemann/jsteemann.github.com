<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Development | J@ArangoDB]]></title>
  <link href="http://jsteemann.github.io/blog/categories/development/atom.xml" rel="self"/>
  <link href="http://jsteemann.github.io/"/>
  <updated>2016-06-22T18:19:35+02:00</updated>
  <id>http://jsteemann.github.io/</id>
  <author>
    <name><![CDATA[jsteemann]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How Much Memory Does an STL Container Use?]]></title>
    <link href="http://jsteemann.github.io/blog/2016/06/14/how-much-memory-does-an-stl-container-use/"/>
    <updated>2016-06-14T00:35:29+02:00</updated>
    <id>http://jsteemann.github.io/blog/2016/06/14/how-much-memory-does-an-stl-container-use</id>
    <content type="html"><![CDATA[<p>Ever wondered how much heap memory will be used by STL containers, and
in what chunks they will allocate it?</p>

<p>Here is the answer for some frequently used containers types containing
uint64_t values (an 8 byte type). For the associative containers I also
used uint64_t as the key type.</p>

<!-- more -->


<p>All results are for the STL implementation I had ready at hand (g++5.3 on
Ubuntu 16.04, x86_64, libstdc++.so.6.0.22, with default allocator).
The results may be completely different for other platforms and/or other
data types.</p>

<p>The following containers are compared:</p>

<ul>
<li>std::vector&lt;uint64_t></li>
<li>std::map&lt;uint64, uint64_t></li>
<li>std::set&lt;uint64_t></li>
<li>std::unordered_map&lt;uint64, uint64_t></li>
<li>std::unordered_set&lt;uint64_t></li>
<li>std::deque&lt;uint64_t></li>
</ul>


<p>The containers themselves are creared on the stack. To store the elements,
the containers will need to use heap memory. The number of elements in the
containers (<em>n</em>) is increased exponentially from 0 (empty) to 512 in the
tests. The memory usage pattern should be quite clear by then.</p>

<p>Reported are the amount of heap memory allocated by the container after all
elements have been inserted, the total number of heap memory allocated by
the container during its whole lifetime (i.e. the sum of all its <code>malloc</code>s),
plus the number of calls to <code>malloc</code> and <code>free</code> the container issued.</p>

<p>```plain heap allocation results</p>

<h2>n =     0</h2>

<p>vector         =>     0 bytes allocd at end,  total:     0 bytes mallocd,    0 malloc(s), 0 free(s)
map            =>     0 bytes allocd at end,  total:     0 bytes mallocd,    0 malloc(s), 0 free(s)
set            =>     0 bytes allocd at end,  total:     0 bytes mallocd,    0 malloc(s), 0 free(s)
unordered_map  =>     0 bytes allocd at end,  total:     0 bytes mallocd,    0 malloc(s), 0 free(s)
unordered_set  =>     0 bytes allocd at end,  total:     0 bytes mallocd,    0 malloc(s), 0 free(s)
deque          =>   576 bytes allocd at end,  total:   576 bytes mallocd,    2 malloc(s), 0 free(s)</p>

<h2>n =     1</h2>

<p>vector         =>     8 bytes allocd at end,  total:     8 bytes mallocd,    1 malloc(s), 0 free(s)
map            =>    48 bytes allocd at end,  total:    48 bytes mallocd,    1 malloc(s), 0 free(s)
set            =>    40 bytes allocd at end,  total:    40 bytes mallocd,    1 malloc(s), 0 free(s)
unordered_map  =>    40 bytes allocd at end,  total:    40 bytes mallocd,    2 malloc(s), 0 free(s)
unordered_set  =>    32 bytes allocd at end,  total:    32 bytes mallocd,    2 malloc(s), 0 free(s)
deque          =>   576 bytes allocd at end,  total:   576 bytes mallocd,    2 malloc(s), 0 free(s)</p>

<h2>n =     2</h2>

<p>vector         =>    16 bytes allocd at end,  total:    24 bytes mallocd,    2 malloc(s), 1 free(s)
map            =>    96 bytes allocd at end,  total:    96 bytes mallocd,    2 malloc(s), 0 free(s)
set            =>    80 bytes allocd at end,  total:    80 bytes mallocd,    2 malloc(s), 0 free(s)
unordered_map  =>    88 bytes allocd at end,  total:   104 bytes mallocd,    4 malloc(s), 1 free(s)
unordered_set  =>    72 bytes allocd at end,  total:    88 bytes mallocd,    4 malloc(s), 1 free(s)
deque          =>   576 bytes allocd at end,  total:   576 bytes mallocd,    2 malloc(s), 0 free(s)</p>

<h2>n =     4</h2>

<p>vector         =>    32 bytes allocd at end,  total:    56 bytes mallocd,    3 malloc(s), 2 free(s)
map            =>   192 bytes allocd at end,  total:   192 bytes mallocd,    4 malloc(s), 0 free(s)
set            =>   160 bytes allocd at end,  total:   160 bytes mallocd,    4 malloc(s), 0 free(s)
unordered_map  =>   136 bytes allocd at end,  total:   152 bytes mallocd,    6 malloc(s), 1 free(s)
unordered_set  =>   104 bytes allocd at end,  total:   120 bytes mallocd,    6 malloc(s), 1 free(s)
deque          =>   576 bytes allocd at end,  total:   576 bytes mallocd,    2 malloc(s), 0 free(s)</p>

<h2>n =     8</h2>

<p>vector         =>    64 bytes allocd at end,  total:   120 bytes mallocd,    4 malloc(s), 3 free(s)
map            =>   384 bytes allocd at end,  total:   384 bytes mallocd,    8 malloc(s), 0 free(s)
set            =>   320 bytes allocd at end,  total:   320 bytes mallocd,    8 malloc(s), 0 free(s)
unordered_map  =>   280 bytes allocd at end,  total:   336 bytes mallocd,   11 malloc(s), 2 free(s)
unordered_set  =>   216 bytes allocd at end,  total:   272 bytes mallocd,   11 malloc(s), 2 free(s)
deque          =>   576 bytes allocd at end,  total:   576 bytes mallocd,    2 malloc(s), 0 free(s)</p>

<h2>n =    16</h2>

<p>vector         =>   128 bytes allocd at end,  total:   248 bytes mallocd,    5 malloc(s), 4 free(s)
map            =>   768 bytes allocd at end,  total:   768 bytes mallocd,   16 malloc(s), 0 free(s)
set            =>   640 bytes allocd at end,  total:   640 bytes mallocd,   16 malloc(s), 0 free(s)
unordered_map  =>   568 bytes allocd at end,  total:   712 bytes mallocd,   20 malloc(s), 3 free(s)
unordered_set  =>   440 bytes allocd at end,  total:   584 bytes mallocd,   20 malloc(s), 3 free(s)
deque          =>   576 bytes allocd at end,  total:   576 bytes mallocd,    2 malloc(s), 0 free(s)</p>

<h2>n =    32</h2>

<p>vector         =>   256 bytes allocd at end,  total:   504 bytes mallocd,    6 malloc(s), 5 free(s)
map            =>  1536 bytes allocd at end,  total:  1536 bytes mallocd,   32 malloc(s), 0 free(s)
set            =>  1280 bytes allocd at end,  total:  1280 bytes mallocd,   32 malloc(s), 0 free(s)
unordered_map  =>  1144 bytes allocd at end,  total:  1472 bytes mallocd,   37 malloc(s), 4 free(s)
unordered_set  =>   888 bytes allocd at end,  total:  1216 bytes mallocd,   37 malloc(s), 4 free(s)
deque          =>   576 bytes allocd at end,  total:   576 bytes mallocd,    2 malloc(s), 0 free(s)</p>

<h2>n =    64</h2>

<p>vector         =>   512 bytes allocd at end,  total:  1016 bytes mallocd,    7 malloc(s), 6 free(s)
map            =>  3072 bytes allocd at end,  total:  3072 bytes mallocd,   64 malloc(s), 0 free(s)
set            =>  2560 bytes allocd at end,  total:  2560 bytes mallocd,   64 malloc(s), 0 free(s)
unordered_map  =>  2312 bytes allocd at end,  total:  3016 bytes mallocd,   70 malloc(s), 5 free(s)
unordered_set  =>  1800 bytes allocd at end,  total:  2504 bytes mallocd,   70 malloc(s), 5 free(s)
deque          =>  1088 bytes allocd at end,  total:  1088 bytes mallocd,    3 malloc(s), 0 free(s)</p>

<h2>n =   128</h2>

<p>vector         =>  1024 bytes allocd at end,  total:  2040 bytes mallocd,    8 malloc(s), 7 free(s)
map            =>  6144 bytes allocd at end,  total:  6144 bytes mallocd,  128 malloc(s), 0 free(s)
set            =>  5120 bytes allocd at end,  total:  5120 bytes mallocd,  128 malloc(s), 0 free(s)
unordered_map  =>  4664 bytes allocd at end,  total:  6144 bytes mallocd,  135 malloc(s), 6 free(s)
unordered_set  =>  3640 bytes allocd at end,  total:  5120 bytes mallocd,  135 malloc(s), 6 free(s)
deque          =>  1600 bytes allocd at end,  total:  1600 bytes mallocd,    4 malloc(s), 0 free(s)</p>

<h2>n =   256</h2>

<p>vector         =>  2048 bytes allocd at end,  total:  4088 bytes mallocd,    9 malloc(s), 8 free(s)
map            => 12288 bytes allocd at end,  total: 12288 bytes mallocd,  256 malloc(s), 0 free(s)
set            => 10240 bytes allocd at end,  total: 10240 bytes mallocd,  256 malloc(s), 0 free(s)
unordered_map  =>  9416 bytes allocd at end,  total: 12488 bytes mallocd,  264 malloc(s), 7 free(s)
unordered_set  =>  7368 bytes allocd at end,  total: 10440 bytes mallocd,  264 malloc(s), 7 free(s)
deque          =>  2624 bytes allocd at end,  total:  2624 bytes mallocd,    6 malloc(s), 0 free(s)</p>

<h2>n =   512</h2>

<p>vector         =>  4096 bytes allocd at end,  total:  8184 bytes mallocd,   10 malloc(s), 9 free(s)
map            => 24576 bytes allocd at end,  total: 24576 bytes mallocd,  512 malloc(s), 0 free(s)
set            => 20480 bytes allocd at end,  total: 20480 bytes mallocd,  512 malloc(s), 0 free(s)
unordered_map  => 18872 bytes allocd at end,  total: 25216 bytes mallocd,  521 malloc(s), 8 free(s)
unordered_set  => 14776 bytes allocd at end,  total: 21120 bytes mallocd,  521 malloc(s), 8 free(s)
deque          =>  4752 bytes allocd at end,  total:  4816 bytes mallocd,   11 malloc(s), 1 free(s)
```</p>

<p>I have intentionally not done any optimizations such as calling <code>reserve()</code>
on the containers before inserting the individual elements, in order to
reflect some real-word scenarios in which it is unclear how much elements
will be added to the containers during program execution.</p>

<p>The test program for reproduction is <a href="/downloads/code/containers.cpp">here</a>. Compile and run it with:</p>

<p><code>bash compiling and executing the test program
g++ -std=c++11 -O0 containers.cpp -o containers
for i in 0 1 2 4 8 16 32 64 128 256 512; do ./containers "$i"; done
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Compiling an Optimized Version of ArangoDB]]></title>
    <link href="http://jsteemann.github.io/blog/2016/06/09/compiling-an-optimized-version-of-arangodb/"/>
    <updated>2016-06-09T20:31:31+02:00</updated>
    <id>http://jsteemann.github.io/blog/2016/06/09/compiling-an-optimized-version-of-arangodb</id>
    <content type="html"><![CDATA[<p>Why should you care about compiling ArangoDB on your own when there are
official release packages that are ready to use?</p>

<!--more -->


<p>There are three main reasons for compiling on your own:</p>

<ul>
<li><p>as a developer you want to <em>make changes to the ArangoDB C++ source code</em>.
Then your only option obviously is to compile on your own. Please consult
the <a href="/blog/2016/06/09/compiling-a-debug-version-of-arangodb/">compiling a debug version of ArangoDB</a>
page for more information.</p></li>
<li><p>you are trying to <em>get meaningful stack traces from core dumps</em> produced
by ArangoDB and need an ArangoDB binary that comes with enough debug
information (debug symbols, probably also assertions turned on). In this
case, please also consult the <a href="/blog/2016/06/09/compiling-a-debug-version-of-arangodb/">compiling a debug version of ArangoDB</a>
blog post for how to get this done.</p></li>
<li><p>you want to use an ArangoDB binary that is <em>optimized for your specific
target architecture</em>.</p></li>
</ul>


<p>The latter reason is relevant because the official release packages that
are provided by ArangoDB cannot make too many assumptions about the environment
in which they will be used. In the general release packages there is not so
much room for platform-specific optimizations as there would be if you are
compiling just for the local machine.</p>

<p>For example, all relevant CPU offer <a href="https://en.wikipedia.org/wiki/SIMD">SIMD</a>
instructions that a compiler can exploit when generating code. But different
generations of CPUs offer different levels of SIMD instructions. Not every CPU
in use today provides SSE4, not to talk about AVX.</p>

<p>To make our release packages compatible with most environments, we have had
to make some conservative assumptions about the CPU abilities, which effectively
disables many optimizations that would have been possible when creating a
build that only needs to run on a specific architecture.</p>

<p>To fully exploit the capabilities of a specific target environment, it&rsquo;s required
to build executables for that specific architecture. Most compilers offer an option
<code>-march</code> for that. You normally want to set this to <code>native</code> when compiling an
optimized version. There are also lots of compiler options for enabling or disabling
specific CPU features such as <code>-msse</code>, <code>-msse2</code>, <code>-msse3</code>, <code>-mssse3</code>,
<code>-msse4.1</code>, <code>-msse4.2</code>, <code>-msse4</code>, <code>-mavx</code>, <code>-mavx2</code>, to name just a few.</p>

<p>The good news is that there is no need to deal with such compiler-specific optimization
options in order to get an optimized build. The cmake-based ArangoDB 3.0 builds will
automatically test the local environment&rsquo;s capabilities and set the compiler options
based on which CPU abilities were detected.</p>

<p>For example, a mere <code>(cd build &amp;&amp; cmake -DCMAKE_BUILD_TYPE=Release ..)</code> will run the
CPU ability detection and configure the build to use the features supported by the
local architecture:</p>

<p><code>bash configuring a release build
(mkdir -p build; cd build &amp;&amp; cmake -DCMAKE_BUILD_TYPE=Release ..)
</code></p>

<p>For example, on my laptop this prints:
<code>plain cmake output
-- The CXX compiler identification is GNU 5.3.1
-- The C compiler identification is GNU 5.3.1
...
-- target changed from "" to "auto"
-- Detected CPU: haswell
-- Performing Test check_cxx_compiler_flag__march_core_avx2
-- Performing Test check_cxx_compiler_flag__march_core_avx2 - Success
-- Performing Test check_cxx_compiler_flag__msse2
-- Performing Test check_cxx_compiler_flag__msse2 - Success
-- Performing Test check_cxx_compiler_flag__msse3
-- Performing Test check_cxx_compiler_flag__msse3 - Success
-- Looking for pmmintrin.h
-- Looking for pmmintrin.h - found
-- Performing Test check_cxx_compiler_flag__mssse3
-- Performing Test check_cxx_compiler_flag__mssse3 - Success
-- Looking for tmmintrin.h
-- Looking for tmmintrin.h - found
-- Performing Test check_cxx_compiler_flag__msse4_1
-- Performing Test check_cxx_compiler_flag__msse4_1 - Success
-- Looking for smmintrin.h
-- Looking for smmintrin.h - found
-- Performing Test check_cxx_compiler_flag__msse4_2
-- Performing Test check_cxx_compiler_flag__msse4_2 - Success
-- Performing Test check_cxx_compiler_flag__mavx
-- Performing Test check_cxx_compiler_flag__mavx - Success
-- Looking for immintrin.h
-- Looking for immintrin.h - found
-- Performing Test check_cxx_compiler_flag__msse2avx
-- Performing Test check_cxx_compiler_flag__msse2avx - Success
-- Performing Test check_cxx_compiler_flag__mavx2
-- Performing Test check_cxx_compiler_flag__mavx2 - Success
-- Performing Test check_cxx_compiler_flag__mno_sse4a
-- Performing Test check_cxx_compiler_flag__mno_sse4a - Success
-- Performing Test check_cxx_compiler_flag__mno_xop
-- Performing Test check_cxx_compiler_flag__mno_xop - Success
-- Performing Test check_cxx_compiler_flag__mno_fma4
-- Performing Test check_cxx_compiler_flag__mno_fma4 - Success
...
</code>
The detected options will end up in the CMakeCache.txt file in the build
directory. The Makefile generated by cmake will automatically make use of
these options when invoking the C++ compiler.</p>

<p>The compiler options are not shown by default, but they can be made visible
by compiling with the option <code>VERBOSE=1</code>, e.g.</p>

<p><code>bash configuring and compiling a build
(mkdir -p build; cd build &amp;&amp; cmake -DCMAKE_BUILD_TYPE=Release ..)
(cd build &amp;&amp; make -j4 VERBOSE=1)
</code></p>

<p>Note that this will be <em>very verbose</em>, so you only want to set the <code>VERBOSE=1</code>
option to check that the compiler options were picked correctly.</p>

<p>On my local laptop, the architecture-specific compiler options that were automatically
detected and used were</p>

<p><code>bash compiler architecture options used
-march=core-avx2 -msse2 -msse3 -mssse3 -msse4.1 -msse4.2 -mavx -msse2avx -mavx2 -mno-sse4a -mno-xop -mno-fma4
</code></p>

<p>The build has detected <code>core-avx2</code>, which in my case is good &ndash; and a lot more
specific than the official packages which for example cannot assume the presence
of either SSE4 or AVX instructions.</p>

<p>And now that we can rely on the presence of specific CPU instructions, some code
parts such as JSON parsing can make use of SSE4.2 instructions, or the compiler
can use some optimized SIMD variants for operations such as memcpy, strlen etc.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using the Address Sanitizer (ASAN) in ArangoDB Development]]></title>
    <link href="http://jsteemann.github.io/blog/2016/06/09/using-the-address-sanitizer-asan-in-arangodb-development/"/>
    <updated>2016-06-09T20:07:29+02:00</updated>
    <id>http://jsteemann.github.io/blog/2016/06/09/using-the-address-sanitizer-asan-in-arangodb-development</id>
    <content type="html"><![CDATA[<p>Once you have set up a <a href="/blog/2016/06/09/compiling-a-debug-version-of-arangodb/">debug version of ArangoDB</a>,
it is quite helpful to also enable the <a href="https://en.wikipedia.org/wiki/AddressSanitizer">Address Sanitizer</a>
and its companion tools.</p>

<p>These sanitizers provide runtime instrumentation for executables and check
for common C++ programming errors such as buffer overflows, use-after-free
bugs and memory leaks. The sanitizers supported natively by recent versions
of g++ and clang++.</p>

<p>The general runtime overhead of the sanitizers is neglectable compared to
other instrumentation tools such as Valgrind, so it can well be used in the
day-to-day development process.</p>

<!-- more -->


<h2>Configuring the build to use ASAN</h2>

<p>To build with ASAN (Address Sanitizer) and UBSAN (Undefined Behavior Sanitizer),
the following environment variables need to be set when invoking cmake:</p>

<p><code>bash environment variables for ASAN and UBSAN
CXXFLAGS="-fsanitize=address -fsanitize=undefined -fno-sanitize=alignment -fno-sanitize=vptr"
</code></p>

<p>The full command to configure a debug build with ASAN and UBSAN support is:</p>

<p><code>bash configuring the build to use the sanitizers
(cd build &amp;&amp; CXXFLAGS="-fsanitize=address -fsanitize=undefined -fno-sanitize=alignment -fno-sanitize=vptr cmake -DCMAKE_BUILD_TYPE=Debug -DUSE_MAINTAINER_MODE=On ..)
</code></p>

<p>This will configure the build so it will pass the sanitizer options to the C++
compiler. Note that you&rsquo;ll need a recent version of g++ or clang++ for this
to work.</p>

<p>After that, build arangod normally. The binaries produced will be instrumented
by the sanitizers, allowing many nasty memory errors to be detected very early.</p>

<h2>Checking if an arangod binary is using ASAN</h2>

<p>Whether or not an ArangoDB binary is instrumented can be found out at any
time by calling the binary with the <code>--version</code> option. This will print some
version information for ArangoDB itself and the other required libraries,
and it will also print in the line starting with <code>asan</code> whether the binary
was compiled with ASAN support or not:</p>

<p>```bash checking the ASAN support of an arangod binary</p>

<blockquote><p>build/bin/arangod &mdash;version</p></blockquote>

<p>3.0.x-devel</p>

<p>architecture: 64bit
asan: true                       # !!!!
asm-crc32: true
boost-version: 1.61.0b1
build-date: 2016-06-09 12:07:07
compiler: gcc
cplusplus: 201103
endianness: little
fd-client-event-handler: poll
fd-setsize: 1024
icu-version: 54.1
jemalloc: false
libev-version: 4.22
maintainer-mode: true
openssl-version: OpenSSL 1.0.2g-fips  1 Mar 2016
rocksdb-version: 4.8.0
server-version: 3.0.x-devel
sizeof int: 4
sizeof void*: 8
sse42: true
tcmalloc: false
v8-version: 5.0.71.39
vpack-version: 0.1.30
zlib-version: 1.2.8
```</p>

<h2>Controlling ASAN runtime behavior</h2>

<p>ASAN behavior can also be controlled at runtime, after the binaries have
been produced, by adjusting the environment variable <code>ASAN_OPTIONS</code>.
The setting I use for this is:</p>

<p><code>bash adjusting ASAN options
ASAN_OPTIONS="handle_ioctl=true:check_initialization_order=true:detect_container_overflow=1:detect_stack_use_after_return=false:detect_odr_violation=1:allow_addr2line=true:strict_init_order=true"
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Compiling a Debug Version of ArangoDB]]></title>
    <link href="http://jsteemann.github.io/blog/2016/06/09/compiling-a-debug-version-of-arangodb/"/>
    <updated>2016-06-09T20:07:29+02:00</updated>
    <id>http://jsteemann.github.io/blog/2016/06/09/compiling-a-debug-version-of-arangodb</id>
    <content type="html"><![CDATA[<p>Compiling a debug version of ArangoDB is a must for everyone that
wants to modify the C++ ArangoDB source code and test their changes
locally.</p>

<p>How to do this is different in the 2.8 and 3.0 branches of ArangoDB,
but luckily it&rsquo;s really easy to achieve in both branches.</p>

<!-- more -->


<h2>ArangoDB 2.8</h2>

<p>For the 2.8 branch of ArangoDB, clone the 2.8 version of the ArangoDB
repository first:</p>

<p><code>bash cloning the 2.8 repository
git clone -b 2.8 https://github.com/arangodb/arangodb
cd ArangoDB
</code></p>

<p>And in that directory execute the following commands:</p>

<p><code>bash compiling a debug version of 2.8
make setup
export CFLAGS="-g -Og"
export CXXFLAGS="-g -Og"
./configure --enable-relative --enable-maintainer-mode
make -j4
</code></p>

<p>(note that you&rsquo;ll need a working C++11 compiler and some prerequisites
such as the OpenSSL library, GNU Bison and Flex installed for this to work).</p>

<p>This will compile ArangoDB and all of its dependencies, and finally
make them available in the <code>bin</code> subdirectory of the current directory.
There is no need to install ArangoDB using <code>make install</code>. arangod and
the client tools can be run locally using the following commands:</p>

<p><code>bash running arangod and arangosh
bin/arangod --console mydb # start arangod in console mode
bin/arangosh # starts an ArangoShell
</code></p>

<p>Now, after any modification to the ArangoDB C++ source code you can re-compile
using <code>make</code>. This will only rebuild the things that need to be rebuilt. If the
build is successful, the changes you have made should be visible when restarting
the binaries.</p>

<p>As the <code>-g</code> option used above will have configured a build with debug
symbols, it&rsquo;s also possible to use a debugger such as gdb for stepping
through the executables, attach to the while they are running, or to
obtain stack traces in case any of the executables crashed.</p>

<h2>ArangoDB 3.0</h2>

<p>For the 3.0 branch of ArangoDB, it&rsquo;s required to once clone that version
of the ArangoDB repository into a local directory:</p>

<p><code>bash cloning the 3.0 repository
git clone -b 3.0 https://github.com/arangodb/arangodb
cd ArangoDB
</code></p>

<p>In that directory execute the following commands to configure the build
for debugging:</p>

<p><code>bash configuring a debug version of 3.0
(mkdir -p build; cd build &amp;&amp; cmake -DCMAKE_BUILD_TYPE=Debug -DUSE_MAINTAINER_MODE=On ..)
</code></p>

<p>(again you&rsquo;ll need a working C++11 compiler and some prerequisites
such as the OpenSSL library installed for this to work).</p>

<p>This will configure the build to be a debug build, with debug symbols
but most optimizations disabled. To build ArangoDB, just execute:</p>

<p><code>bash compiling a debug version of 3.0
(cd build &amp;&amp; make -j4)
</code></p>

<p>To execute one of the binaries, run them from the checkout directory
as follows:</p>

<p><code>bash running arangod and arangosh
build/bin/arangod --console mydb # start arangod in console mode
build/bin/arangosh # starts an ArangoShell
</code></p>

<p>After any modification to the ArangoDB C++ source code, build again
using <code>(cd build &amp;&amp; make -j4)</code> to see the changes in effect.
The build is a debug build, meaning you can use a debugger and get
meaningful stack traces for core dumps produced by the binaries.</p>

<p>If you got, then I strongly recommend to also enable the
<a href="https://en.wikipedia.org/wiki/AddressSanitizer">Address Sanitizer</a>
(ASAN) for your debug build. This can greatly help finding common memory usage
errors during development. There is another<br/>
<a href="/blog/2016/06/09/using-the-address-sanitizer-asan-in-arangodb-development/">blog post about using ASAN in ArangoDB development</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fastest String-to-uint64 Conversion Method?]]></title>
    <link href="http://jsteemann.github.io/blog/2016/06/02/fastest-string-to-uint64-conversion-method/"/>
    <updated>2016-06-02T20:15:27+02:00</updated>
    <id>http://jsteemann.github.io/blog/2016/06/02/fastest-string-to-uint64-conversion-method</id>
    <content type="html"><![CDATA[<p>While doing some optimization work for the upcoming ArangoDB 3.0 release,
we had to figure out what was the &ldquo;ideal&rdquo; way of converting a string
representation of a number into a C++ uint64_t (64 bit unsigned integer type).
This kind of operation is performed a lot during the lifetime of an ArangoDB
server process, so it seemed worthwhile making it as fast as possible.</p>

<!-- more -->


<h2>std::stoull and std::strtoull</h2>

<p>The natural solution for this kind of conversion is the standard library&rsquo;s
<a href="http://en.cppreference.com/w/cpp/string/basic_string/stoul">std::stoull</a>
function. On the one hand, that solution is potentially optimized and definitely
robust. It performs validation of the input characters and is also battle-tested
by millions of users.</p>

<p>On the other hand, std::stoull has a few &ldquo;features&rdquo; that some would consider
&ldquo;anti&rdquo;-features, and that sound like they could negatively influence performance:</p>

<ul>
<li>it may behave locale-dependent</li>
<li>it can parse and will let pass negative input values, which is often not desired
for a result of unsigned type</li>
<li>it can perform base conversion</li>
</ul>


<p>In C++11 there is also the alternative
<a href="http://en.cppreference.com/w/cpp/string/byte/strtoul">std::strtoull</a>.
It should behave about the same as std::stoull except in case of error.
std::stoull will throw and std::strtoull will not.</p>

<p>That&rsquo;s what we get from the standard library for long unsigned integer types.</p>

<h2>Alternative implementations (w/o error checking)</h2>

<p>Another alternative is to roll a string to number conversion function ourselves.
If we hard-code it to base 10 and do not care about error checking, a naive
implementation may look like this:</p>

<p>```cpp
inline uint64_t naive(std::string const&amp; value) {
  uint64_t result = 0;
  char const<em> p = value.c_str();
  char const</em> q = p + value.size();
  while (p &lt; q) {</p>

<pre><code>result *= 10;
result += *(p++) - '0';
</code></pre>

<p>  }
  return result;
}
```</p>

<p>Obviously the above will produce wrong results for invalid
input data, but for &ldquo;trusted&rdquo; (known to be valid) input it may
be just fine.</p>

<p>Here&rsquo;s just another implementation for the problem at hand. This one
doesn&rsquo;t perform the times 10 operation, but splits it into two bitshifting
operations:</p>

<p>```cpp
inline uint64_t bitshift(std::string const&amp; value) {
  uint64_t result = 0;</p>

<p>  char const<em> p = value.c_str();
  char const</em> q = p + value.size();
  while (p &lt; q) {</p>

<pre><code>result = (result &lt;&lt; 1) + (result &lt;&lt; 3) + *(p++) - '0';
</code></pre>

<p>  }
  return result;
}
```</p>

<p>Again no error checking is present in the above function, but it
should be ok for trusted inputs.</p>

<p>By manually unrolling the while loop and converting it into a switch
statement, we can also come up with a conversion function that has minimal
branching:</p>

<p>```cpp
inline uint64_t unrolled(std::string const&amp; value) {
  uint64_t result = 0;</p>

<p>  size_t const length = value.size();
  switch (length) {</p>

<pre><code>case 20:    result += (value[length - 20] - '0') * 10000000000000000000ULL;
case 19:    result += (value[length - 19] - '0') * 1000000000000000000ULL;
case 18:    result += (value[length - 18] - '0') * 100000000000000000ULL;
case 17:    result += (value[length - 17] - '0') * 10000000000000000ULL;
case 16:    result += (value[length - 16] - '0') * 1000000000000000ULL;
case 15:    result += (value[length - 15] - '0') * 100000000000000ULL;
case 14:    result += (value[length - 14] - '0') * 10000000000000ULL;
case 13:    result += (value[length - 13] - '0') * 1000000000000ULL;
case 12:    result += (value[length - 12] - '0') * 100000000000ULL;
case 11:    result += (value[length - 11] - '0') * 10000000000ULL;
case 10:    result += (value[length - 10] - '0') * 1000000000ULL;
case  9:    result += (value[length -  9] - '0') * 100000000ULL;
case  8:    result += (value[length -  8] - '0') * 10000000ULL;
case  7:    result += (value[length -  7] - '0') * 1000000ULL;
case  6:    result += (value[length -  6] - '0') * 100000ULL;
case  5:    result += (value[length -  5] - '0') * 10000ULL;
case  4:    result += (value[length -  4] - '0') * 1000ULL;
case  3:    result += (value[length -  3] - '0') * 100ULL;
case  2:    result += (value[length -  2] - '0') * 10ULL;
case  1:    result += (value[length -  1] - '0');
</code></pre>

<p>  }
  return result;
}
```</p>

<h2>Performance testing</h2>

<p>To check out how all these alternatives perform, I put them into a small
<a href="/downloads/code/stoull-test.cpp">test driver program</a>. To compile it with
g++ and run it, I used this command:</p>

<p><code>bash
g++ -Wall -Wextra -march=native -std=c++11 -O3 stdoull-test.cpp &amp;&amp; ./a.out
</code></p>

<p>The test program will convert input strings of different lengths to uint64_t
using the above (and some other) implementations, going up from 10,000 iterations
per string up to 100,000,000. It also prints the wall-clock time spent in each
run. The most interesting output it prints is in the &ldquo;ms&rdquo; column. The &ldquo;result&rdquo;
column can be fully ignored. It&rsquo;s only there so the compiler won&rsquo;t optimize away
the calls to the conversion functions.</p>

<p>The timings from my local laptop (Intel Core i7-4710HQ CPU @ 2.50GHz, Ubuntu 16.04,
g++ 5.3.1 &ndash; your mileage may vary!) for the 100,000,000 conversions are:</p>

<p>```plain execution times for various string-to-uint64 implementations
test &lsquo;std::stoull&rsquo;       string &lsquo;1&rsquo;                           1209 ms
test &lsquo;std::stoull&rsquo;       string &lsquo;99&rsquo;                          1382 ms
test &lsquo;std::stoull&rsquo;       string &lsquo;1234&rsquo;                        1725 ms
test &lsquo;std::stoull&rsquo;       string &lsquo;1234567&rsquo;                     2257 ms
test &lsquo;std::stoull&rsquo;       string &lsquo;1234567891&rsquo;                  2764 ms
test &lsquo;std::stoull&rsquo;       string &lsquo;12345678901234&rsquo;              3899 ms
test &lsquo;std::stoull&rsquo;       string &lsquo;12345678901234678901&rsquo;        7391 ms</p>

<p>test &lsquo;std::strtoull&rsquo;     string &lsquo;1&rsquo;                           1104 ms
test &lsquo;std::strtoull&rsquo;     string &lsquo;99&rsquo;                          1300 ms
test &lsquo;std::strtoull&rsquo;     string &lsquo;1234&rsquo;                        1628 ms
test &lsquo;std::strtoull&rsquo;     string &lsquo;1234567&rsquo;                     2428 ms
test &lsquo;std::strtoull&rsquo;     string &lsquo;1234567891&rsquo;                  2662 ms
test &lsquo;std::strtoull&rsquo;     string &lsquo;12345678901234&rsquo;              3705 ms
test &lsquo;std::strtoull&rsquo;     string &lsquo;12345678901234678901&rsquo;        6631 ms</p>

<p>test &lsquo;naive&rsquo;             string &lsquo;1&rsquo;                            202 ms
test &lsquo;naive&rsquo;             string &lsquo;99&rsquo;                           314 ms
test &lsquo;naive&rsquo;             string &lsquo;1234&rsquo;                         475 ms
test &lsquo;naive&rsquo;             string &lsquo;1234567&rsquo;                      732 ms
test &lsquo;naive&rsquo;             string &lsquo;1234567891&rsquo;                   987 ms
test &lsquo;naive&rsquo;             string &lsquo;12345678901234&rsquo;              1343 ms
test &lsquo;naive&rsquo;             string &lsquo;12345678901234678901&rsquo;        1862 ms</p>

<p>test &lsquo;bitshift&rsquo;          string &lsquo;1&rsquo;                            188 ms
test &lsquo;bitshift&rsquo;          string &lsquo;99&rsquo;                           245 ms
test &lsquo;bitshift&rsquo;          string &lsquo;1234&rsquo;                         397 ms
test &lsquo;bitshift&rsquo;          string &lsquo;1234567&rsquo;                      462 ms
test &lsquo;bitshift&rsquo;          string &lsquo;1234567891&rsquo;                   666 ms
test &lsquo;bitshift&rsquo;          string &lsquo;12345678901234&rsquo;               888 ms
test &lsquo;bitshift&rsquo;          string &lsquo;12345678901234678901&rsquo;        1277 ms</p>

<p>test &lsquo;unrolled&rsquo;          string &lsquo;1&rsquo;                            289 ms
test &lsquo;unrolled&rsquo;          string &lsquo;99&rsquo;                           289 ms
test &lsquo;unrolled&rsquo;          string &lsquo;1234&rsquo;                         351 ms
test &lsquo;unrolled&rsquo;          string &lsquo;1234567&rsquo;                      408 ms
test &lsquo;unrolled&rsquo;          string &lsquo;1234567891&rsquo;                   547 ms
test &lsquo;unrolled&rsquo;          string &lsquo;12345678901234&rsquo;               778 ms
test &lsquo;unrolled&rsquo;          string &lsquo;12345678901234678901&rsquo;        1068 ms
```</p>

<p>It&rsquo;s no surprise the standard library functions with their generality and
error checking features are slower than the specialized functions that took
the liberty to ignore all that.</p>

<p>Which method is fastest now?</p>

<p>As can be seen above, the &ldquo;bitshift&rdquo; variant was fastest for short and medium
length inputs in my environment. At some point when input values get longer,
the &ldquo;bitshift&rdquo; methods gets overtaken by the &ldquo;unrolled&rdquo; variant. The &ldquo;naive&rdquo;
variant was slower than the two in most cases, but still performs surprisingly
well.</p>

<h2>Conclusion</h2>

<p>The take-away: even though string-to-number conversion routines are
present in the standard library, it can still be beneficial to hand-craft
specialized variants of them for maximum performance. This is especially true
when most of the generality that the standard library routines provide is not
required in your use case.</p>

<p>For example, if you know that the conversion functions will only operate on
&ldquo;trusted&rdquo; input (only numeric digit input characters, length of input string
won&rsquo;t exceed the maximum length of a uint64_t number etc.) then error checking
is not required.</p>

<p>Additionally, if you can limit yourself to numbers of a specific base and
don&rsquo;t negative base conversion nor the handling of negative values, a lot of
the generality and safety overhead of std::stoull may be avoided.</p>
]]></content>
  </entry>
  
</feed>
